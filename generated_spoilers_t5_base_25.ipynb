{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-29T05:35:57.289831Z",
     "iopub.status.busy": "2023-07-29T05:35:57.286438Z",
     "iopub.status.idle": "2023-07-29T05:36:15.114963Z",
     "shell.execute_reply": "2023-07-29T05:36:15.113626Z",
     "shell.execute_reply.started": "2023-07-29T05:35:57.289785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.30.2)\n",
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.16.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.6.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.5.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24954 sha256=e4272fbe423db1981fbfd77bd15fbcb858fb21e92785d77190778dcdfb3dd7dd\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: rouge-score, evaluate\n",
      "Successfully installed evaluate-0.4.0 rouge-score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "! pip install datasets evaluate transformers rouge-score nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:36:15.118753Z",
     "iopub.status.busy": "2023-07-29T05:36:15.118086Z",
     "iopub.status.idle": "2023-07-29T05:36:56.554800Z",
     "shell.execute_reply": "2023-07-29T05:36:56.553603Z",
     "shell.execute_reply.started": "2023-07-29T05:36:15.118712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.30.2)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.30.2\n",
      "    Uninstalling transformers-4.30.2:\n",
      "      Successfully uninstalled transformers-4.30.2\n",
      "Successfully installed transformers-4.31.0\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.15.5)\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.15.7-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.3)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.31)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.27.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (59.8.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.5.7)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n",
      "Installing collected packages: wandb\n",
      "  Attempting uninstall: wandb\n",
      "    Found existing installation: wandb 0.15.5\n",
      "    Uninstalling wandb-0.15.5:\n",
      "      Successfully uninstalled wandb-0.15.5\n",
      "Successfully installed wandb-0.15.7\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers --upgrade\n",
    "!pip install wandb --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:36:56.556807Z",
     "iopub.status.busy": "2023-07-29T05:36:56.556422Z",
     "iopub.status.idle": "2023-07-29T05:36:58.979300Z",
     "shell.execute_reply": "2023-07-29T05:36:58.978276Z",
     "shell.execute_reply.started": "2023-07-29T05:36:56.556769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.31.0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:36:58.982593Z",
     "iopub.status.busy": "2023-07-29T05:36:58.981947Z",
     "iopub.status.idle": "2023-07-29T05:36:58.989071Z",
     "shell.execute_reply": "2023-07-29T05:36:58.988020Z",
     "shell.execute_reply.started": "2023-07-29T05:36:58.982555Z"
    }
   },
   "outputs": [],
   "source": [
    "model_checkpoint = \"t5-base\"    #\"t5-small\", \"t5-base\", \"t5-larg\", \"t5-3b\", \"t5-11b\"\n",
    "# model_checkpoint = \"facebook/bart-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:36:58.990763Z",
     "iopub.status.busy": "2023-07-29T05:36:58.990368Z",
     "iopub.status.idle": "2023-07-29T05:37:11.902311Z",
     "shell.execute_reply": "2023-07-29T05:37:11.901301Z",
     "shell.execute_reply.started": "2023-07-29T05:36:58.990729Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Masking, LSTM\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:37:11.904780Z",
     "iopub.status.busy": "2023-07-29T05:37:11.903981Z",
     "iopub.status.idle": "2023-07-29T05:37:12.558450Z",
     "shell.execute_reply": "2023-07-29T05:37:12.557384Z",
     "shell.execute_reply.started": "2023-07-29T05:37:11.904744Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset(file_name):\n",
    "    data = []\n",
    "    with open(file_name, encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            example = json.loads(line)\n",
    "            post_text = example['postText'][0]\n",
    "            title = example['targetTitle']\n",
    "            paragraphs = ' '.join(example['targetParagraphs'])\n",
    "            spoiler = example['spoiler'][0]\n",
    "            data.append({'text': post_text + ' - ' + title + paragraphs, 'spoiler': spoiler})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def load_dataset_test(file_name):\n",
    "    data = []\n",
    "    with open(file_name, encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            example = json.loads(line)\n",
    "            post_text = example['postText'][0]\n",
    "            title = example['targetTitle']\n",
    "            id = example['id']\n",
    "            paragraphs = ' '.join(example['targetParagraphs'])\n",
    "            # label = example['tags'][0] if 'tags' in example else None\n",
    "            # if label in ['phrase', 'multi', 'passage']:\n",
    "            data.append({'id': id, 'text': post_text + ' - ' + title + paragraphs})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "test_data = load_dataset_test('/kaggle/input/mscitask1-spoiler-generation/test.jsonl')\n",
    "train_data = load_dataset('/kaggle/input/mscitask1-spoiler-generation/train.jsonl')\n",
    "validation_data = load_dataset('/kaggle/input/mscitask1-spoiler-generation/val.jsonl')\n",
    "# test_data = load_dataset_test('/kaggle/input/clickbait-detection-msci641-s23/test.jsonl')\n",
    "# all_datasets = pd.concat([test_data, train_data, validation_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:37:12.560571Z",
     "iopub.status.busy": "2023-07-29T05:37:12.560170Z",
     "iopub.status.idle": "2023-07-29T05:37:12.577806Z",
     "shell.execute_reply": "2023-07-29T05:37:12.576038Z",
     "shell.execute_reply.started": "2023-07-29T05:37:12.560524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "                                                text  \\\n",
      "0  Wes Welker Wanted Dinner With Tom Brady, But P...   \n",
      "1  NASA sets date for full recovery of ozone hole...   \n",
      "\n",
      "                               spoiler  \n",
      "0  how about that morning we go throw?  \n",
      "1                                 2070  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   id                                               text\n",
      "0   0  He Tackles A Nurse At The Hospital. Then You S...\n",
      "1   1  Why you SHOULD be selfish at work - Why you SH...\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data))\n",
    "print(train_data[:2])\n",
    "print(type(test_data))\n",
    "print(test_data[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:37:12.581551Z",
     "iopub.status.busy": "2023-07-29T05:37:12.580657Z",
     "iopub.status.idle": "2023-07-29T05:37:12.599556Z",
     "shell.execute_reply": "2023-07-29T05:37:12.598371Z",
     "shell.execute_reply.started": "2023-07-29T05:37:12.581494Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = np.array(train_data)\n",
    "validation_data = np.array(validation_data)\n",
    "test_data = np.array(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:37:12.601569Z",
     "iopub.status.busy": "2023-07-29T05:37:12.600974Z",
     "iopub.status.idle": "2023-07-29T05:37:13.065249Z",
     "shell.execute_reply": "2023-07-29T05:37:13.063391Z",
     "shell.execute_reply.started": "2023-07-29T05:37:12.601382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200\n",
      "400\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "characters = ['!','\"','#','$','%','&','(',')','*','+','/',':',';','<','=','>','@','^','`','|','~','\\t','[',']','{','}','\\\\','.','-']\n",
    "for i in range(len(train_data)):\n",
    "    for j in characters:\n",
    "        train_data[i][0] = train_data[i][0].replace(j,\"\")\n",
    "        train_data[i][1] = train_data[i][1].replace(j,\"\")\n",
    "\n",
    "for i in range(len(validation_data)):\n",
    "    for j in characters:\n",
    "        validation_data[i][0] = validation_data[i][0].replace(j,\"\")\n",
    "        validation_data[i][1] = validation_data[i][1].replace(j,\"\")\n",
    "        \n",
    "for i in range(len(test_data)):\n",
    "    for j in characters:\n",
    "        test_data[i][1] = test_data[i][1].replace(j,\"\")\n",
    "\n",
    "        \n",
    "print(len(train_data))\n",
    "print(len(validation_data))\n",
    "print(len(test_data))\n",
    "\n",
    "train_data = pd.DataFrame(train_data, columns=[\"text\", \"spoiler\"])\n",
    "validation_data = pd.DataFrame(validation_data, columns=[\"text\", \"spoiler\"])\n",
    "test_data = pd.DataFrame(test_data, columns=[\"id\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:37:13.070483Z",
     "iopub.status.busy": "2023-07-29T05:37:13.070160Z",
     "iopub.status.idle": "2023-07-29T05:37:13.658545Z",
     "shell.execute_reply": "2023-07-29T05:37:13.657493Z",
     "shell.execute_reply.started": "2023-07-29T05:37:13.070457Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.to_csv('train_data.csv', index=False)\n",
    "validation_data.to_csv('validation_data.csv', index=False)\n",
    "test_data.to_csv('test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:37:13.660855Z",
     "iopub.status.busy": "2023-07-29T05:37:13.660456Z",
     "iopub.status.idle": "2023-07-29T05:37:15.781235Z",
     "shell.execute_reply": "2023-07-29T05:37:15.780379Z",
     "shell.execute_reply.started": "2023-07-29T05:37:13.660818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-d62f98377cb6b6c6/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be6d59fd31b4c1089ce1578cbaa6a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66342e37d6964fd8b05157016a4c681e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/datasets/packaged_modules/csv/csv.py:154: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n",
      "  csv_file_reader = pd.read_csv(file, iterator=True, dtype=dtype, **self.config.read_csv_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-d62f98377cb6b6c6/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a531400f3a4d839ce528d7faa84bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-cb0fea118882c7dd/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59e2c49a0844336b7c4437ff28478ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7028844e319e4f0faddcb652be74d9d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-cb0fea118882c7dd/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/datasets/packaged_modules/csv/csv.py:154: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n",
      "  csv_file_reader = pd.read_csv(file, iterator=True, dtype=dtype, **self.config.read_csv_kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc213ae890e340a2a083e096471a4fb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-4c105ecc9eb6bcfe/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b4514920444743a2236eb1e78a3d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c75d8d6cc742eabe41773c59a69044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-4c105ecc9eb6bcfe/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/datasets/packaged_modules/csv/csv.py:154: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n",
      "  csv_file_reader = pd.read_csv(file, iterator=True, dtype=dtype, **self.config.read_csv_kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "519d35fb965a4faf8d3e697bed90a30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import datasets\n",
    "\n",
    "dataset_file_train = '/kaggle/working/train_data.csv'\n",
    "dataset_file_valid = '/kaggle/working/validation_data.csv'\n",
    "data_file_test = '/kaggle/working/test_data.csv'\n",
    "\n",
    "train_data = load_dataset('csv', data_files=dataset_file_train)\n",
    "val_data = load_dataset('csv', data_files=dataset_file_valid)\n",
    "test_data = load_dataset('csv', data_files=data_file_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:37:15.783380Z",
     "iopub.status.busy": "2023-07-29T05:37:15.782708Z",
     "iopub.status.idle": "2023-07-29T05:37:15.791732Z",
     "shell.execute_reply": "2023-07-29T05:37:15.790906Z",
     "shell.execute_reply.started": "2023-07-29T05:37:15.783344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'spoiler'],\n",
      "        num_rows: 3200\n",
      "    })\n",
      "})\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'spoiler'],\n",
      "        num_rows: 400\n",
      "    })\n",
      "})\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'text'],\n",
      "        num_rows: 400\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_data)\n",
    "print(val_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:37:15.793496Z",
     "iopub.status.busy": "2023-07-29T05:37:15.793155Z",
     "iopub.status.idle": "2023-07-29T05:37:15.811080Z",
     "shell.execute_reply": "2023-07-29T05:37:15.810216Z",
     "shell.execute_reply.started": "2023-07-29T05:37:15.793465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Wes Welker Wanted Dinner With Tom Brady, But Patriots QB Had Better Idea  Wes Welker Wanted Dinner With Tom Brady, But Patriots QB Had A Better IdeaIt’ll be just like old times this weekend for Tom Brady and Wes Welker Welker revealed Friday morning on a Miami radio station that he contacted Brady because he’ll be in town for Sunday’s game between the New England Patriots and Miami Dolphins at Gillette Stadium It seemed like a perfect opportunity for the two to catch up But Brady’s definition of catching up involves far more than just a meal In fact, it involves some literal catching as the Patriots quarterback looks to stay sharp during his fourgame Deflategate suspension I hit him up to do dinner Saturday night He’s like, ‘I’m going to be flying in from Ann Arbor later after the MichiganColorado football game, but how about that morning we go throw?’  Welker said on WQAM, per The Boston Globe And I’m just sitting there, I’m like, ‘I was just thinking about dinner, but yeah, sure I’ll get over there early and we can throw a little bit’  Welker was one of Brady’s favorite targets for six seasons from 2007 to 2012 It’s understandable him and Brady want to meet with both being in the same area But Brady typically is all business during football season Welker probably should have known what he was getting into when reaching out to his buddy That’s the only thing we really have planned, Welker said of his upcoming workout with Brady It’s just funny I’m sitting there trying to have dinner ‘Hey, get your ass up here and let’s go throw’ I’m like, ‘Aw jeez, man’ He’s going to have me running like 2minute drills in his backyard or something Maybe Brady will put a good word in for Welker down in Foxboro if the former Patriots wide receiver impresses him enough',\n",
       " 'spoiler': 'how about that morning we go throw?'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:37:15.813207Z",
     "iopub.status.busy": "2023-07-29T05:37:15.812455Z",
     "iopub.status.idle": "2023-07-29T05:37:15.829221Z",
     "shell.execute_reply": "2023-07-29T05:37:15.828368Z",
     "shell.execute_reply.started": "2023-07-29T05:37:15.813175Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=5):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:37:15.831360Z",
     "iopub.status.busy": "2023-07-29T05:37:15.830640Z",
     "iopub.status.idle": "2023-07-29T05:37:15.857169Z",
     "shell.execute_reply": "2023-07-29T05:37:15.856213Z",
     "shell.execute_reply.started": "2023-07-29T05:37:15.831311Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spoiler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is 'Fargo' season three headed to St Cloud?  UV Is 'Fargo' season three headed to St Cloud?MINNEAPOLIS — In its first two seasons, the television show Fargo brought its Midwestern crime tales to Bemidji, Duluth and Luverne, Minn It also hopscotched over to the Dakotas — North and South — racking up body counts in Fargo and Sioux Falls Now, season three is likely heading to St Cloud I think we're going to be in St Cloud this year, Noah Hawley, the show's creator, told the Aw Jeez podcast And we're going to do a little Eden Valley — for reasons that will become apparent later on St Cloud, in central Minnesota, has a population of approximately 60,000 Eden Valley, a small town of just 1,000, is located 45 minutes southwest of St Cloud Earlier, Hawley said the new season would be set in 2010 It was announced last month that Ewan McGregor would star, playing a pair of brothers It always starts for some reason with a catalytic moment, Hawley said of the show The first year was two guys in an emergency room  The second year was a woman drives home with a guy sticking out of her windshield and makes dinner for her husband  The third year revolves around two brothers The older one is very successful — the parking lot king of Minnesota — and the younger one is less successful as a parole officer There's sort of an original sin between them that blows up at the start of the story and sends things on their way, Hawley said This season will revolve around the two Ewans, but it will very quickly escalate to a lot of other things Hawley said that the Minnesota he presents in the show isn't meant to be the real Minnesota The job that I've been given is not to recreate Minnesota as it exists, but to recreate it as it existed in the movie Fargo, which I saw as respectful portrait with a certain comic aspect to it Despite its St Cloud setting, the third season will be shot up north in Calgary, Canada Shooting will likely begin in November, and the show will premiere next April I wish we could shoot here That would make me happy, Hawley said But it's America, so we have to make our television in Canada</td>\n",
       "      <td>season three is likely heading to St Cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35 fucking infuriating things that happen in every romcom  35 Fucking Infuriating Things That Happen In Every RomComWe recently asked the BuzzFeed Community about the things that annoy them the most in romcom movies Here are some of the best results they submitted 1 Airport dash scenes Why do they always need to rush to the airport?  Why not just call them? Or book a plane ticket? They're not gonna drop off the face of the Earth 2 Also, let's be honest, airport security is a joke in romcom world  3 Single people can apparently afford to have really nice apartments in big cities  How is that possible? We can afford a box in a basement 4 And then there are the small details that just don't add up  For example, in Leap Year they go to an outdoor wedding, in Ireland, in February And then to top it off they sleep on a bench after said wedding The average temperature in Ireland in February is 5°C 41°F 5 There's always a guy who is an absolute jerk who somehow becomes the main love interest  He's a jerk No thank you 6 And what about the he's a fuckboy but there's something different about him clichè? Hmm?  7 Or a man who pursues a woman who isn't interested in him or even vehemently dislikes him  Is this OK? IS IT??? 8 In fact, the normalisation of the stalking that characters do to win or win back the ones they want is pretty worrying when you think about it  Is stalking OK? Let me think Nope 9 There's also always the message being sent out that guys are the beall and endall of EVERYTHING  What is with all these women who have wonderful lives, Nora Jonesbeautiful kitchens, and supportive friends, but somehow they are deeply unhappy because they are single? SINGLE GOD NO There's more to life than getting a guy, btw 10 And what about the cheating? SO MUCH CHEATING And it's condoned and always results in ultimate happiness  Please see The Notebook, Love Actually, You've Got Mail, Letters to Juliet, Something Borrowed, to name but a few 11 Apparently females only have one kind of job – being a writer or working in fashion  Every other profession must be run by men 12 There's always a friend who's unlucky in love because she's too outspoken and confident to get a man  What is wrong with confidence? 13 And what about the questionable relationships that are actually kinda creepy in romcoms?  Cher ends up dating her stepbrother in Clueless I KNOW, they're not bloodrelated, but that's still kind of weird, is it not? And the teacher falling for a pretend student in Never Been Kissed Don't tell me that's not odd as well 14 Makeovers So Many Makeovers Apparently you can only get a guy if you conform to society's beauty standards  15 Especially by just taking your glasses off Apparently glasses  ugly, no glasses  instant attraction</td>\n",
       "      <td>1 Airport dash scenes Why do they always need to rush to the airport?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>George Clooney's exgf will kick your ass in a sports bra thank you very much  Elisabetta Canalis Knows Krav Maga, Can Kick Your ButtMemo to everyone Do not mess with Elisabetta Canalis because she can kick your butt The model, who is best known for dating George Clooney for two years, is apparently trained in Krav Maga, a self defense system created in Israel, which combines techniques from boxing, Muay Thai, Wing Chun, Judo, jiujitsu, wrestling and grappling Canalis has been training every day according to the Daily Mail and her toned arms and chiseled abs are a result of her hard work The 35yearold recently showed off her superfit bod on her Instagram account Check out Canalis in action as she practices Krav Maga with her training partner, Mistress Gabriella, in Milan</td>\n",
       "      <td>Elisabetta Canalis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OfficialAdele is rumored for a MAJOR movie role  Adele  Dusty Springfield Singer Rumored To Play Late Musician In Upcoming BiopicAdele may be on her way to the big screen The Grammy awardwinning singer, who has yet to appear in a feature film, is rumored for the starring role in an upcoming biopic about late singer Dusty Springfield Born in England in the '30s, Springfield was a celebrated soul singer who nabbed a spot in the Grammy and Rock and Roll Halls of Fame After releasing multiple charttopping singles and albums, Springfield died in 1999 at the age of 59 Rumors about a Springfield biopic have been making the rounds for months In 2011 it was announced that Nick Hurran Little Black Book, would direct the project, with early reports speculating that Kristin Chenoweth would take the lead role Boardwalk Empire producer David Stenn is also reportedly attached to write the script While little progress has been made on the forthcoming film as of late, Adele's name is being tossed around for the part and may reinvigorate plans for the biopic An unnamed source told the Daily Star, Adele is attached to a project, but it’s in the early stages of development Adele, who hasn't commented on the possibility of playing Springfield, was rumored for another film role earlier this year The 25yearold singer is hyped to make an appearance as a villain in the upcoming film The Secret Service, which may also include cameos by David Beckham, Elton John, and Taylor Swift Adele's Style Evolution</td>\n",
       "      <td>Dusty Springfield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you want to end a relationship, this is how to do it  If you want to end a relationship, this is how to do it The listDushka Zapata is a writer and executive coach, she explained to Quora the ideal way to breakup with someone gracefully I know People do horrible things to each other and often we are better off without someone I will set these open and shut cases aside What about the times where the guy or woman we are breaking up with is not right for us but is a thoroughly decent human? What if people do the best they can? What if those we select to share our lives with were well chosen and as such happen to be splendid people? What if they know us better than anyone? What if aside from lovers they are friends? What if we can manage to change the terms of our relationship with them without losing them? Aren’t they worth rescuing? Shouldn’t we consider turning our backs on the colorless narrative that a breakup means war, that a person we loved must become an enemy? If you want to break up with someone, please don’t wait Don’t put it off because you don’t want to hurt him or because it’s not the right time You will hurt him It’s never the right time Don’t ack disappear or dwindle or attempt to fade into the horizon or send subtle signs or let the information trickle and speak for itself Please don’t break up via text or phone Break up in person, face to face Then, be as direct and as clear as you can While assembling these clear and direct words keep in mind that your priority is to preserve the other person’s dignity And yours The person in front of you is someone you used to love and spend time with Think of the day you met, about the times you were excited to see his name on your screen, instead of thinking of the fights or the last few weeks Who we are is not who we are at our worst Who we are is a collection of everything To do this moment justice, conjure the full picture Assume, in your conversation but also in your thoughts, that what went wrong was you Blame is a form of aggression towards the person you are talking to but mostly an aggression towards yourself Nothing is more disempowering than not being responsible Keep the entire process private This is the end of your relationship, painful and intimate It does not belong on Instagram Then, give it time My hope for you is that one day not too far into the future you will be having dinner with him and he’ll offer an insight into your life that clarifies something, illuminates something, untangles something You always know what to order within seconds of opening the menu It’s exactly how you make decisions about what you want he’ll say And you’ll know that you have before you a person who understands everything More These are the signs of a failing relationship  Keep scrolling for next article</td>\n",
       "      <td>Break up in person, face to face Then, be as direct and as clear as you can</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(train_data[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:37:15.859513Z",
     "iopub.status.busy": "2023-07-29T05:37:15.858532Z",
     "iopub.status.idle": "2023-07-29T05:37:32.684192Z",
     "shell.execute_reply": "2023-07-29T05:37:32.682938Z",
     "shell.execute_reply.started": "2023-07-29T05:37:15.859477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.65.0)\n",
      "Installing collected packages: nltk\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.2.4\n",
      "    Uninstalling nltk-3.2.4:\n",
      "      Successfully uninstalled nltk-3.2.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nltk-3.8.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77f232ff0f34acf91c241a933b67ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2552d582976c44b09942db96c4720543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "!pip install -U nltk\n",
    "metric = load_metric(\"rouge\")\n",
    "metric_meteor = load_metric(\"meteor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:37:32.688399Z",
     "iopub.status.busy": "2023-07-29T05:37:32.688041Z",
     "iopub.status.idle": "2023-07-29T05:37:32.986217Z",
     "shell.execute_reply": "2023-07-29T05:37:32.985215Z",
     "shell.execute_reply.started": "2023-07-29T05:37:32.688365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': AggregateScore(low=Score(precision=1.0, recall=1.0, fmeasure=1.0), mid=Score(precision=1.0, recall=1.0, fmeasure=1.0), high=Score(precision=1.0, recall=1.0, fmeasure=1.0)), 'rouge2': AggregateScore(low=Score(precision=1.0, recall=1.0, fmeasure=1.0), mid=Score(precision=1.0, recall=1.0, fmeasure=1.0), high=Score(precision=1.0, recall=1.0, fmeasure=1.0)), 'rougeL': AggregateScore(low=Score(precision=1.0, recall=1.0, fmeasure=1.0), mid=Score(precision=1.0, recall=1.0, fmeasure=1.0), high=Score(precision=1.0, recall=1.0, fmeasure=1.0)), 'rougeLsum': AggregateScore(low=Score(precision=1.0, recall=1.0, fmeasure=1.0), mid=Score(precision=1.0, recall=1.0, fmeasure=1.0), high=Score(precision=1.0, recall=1.0, fmeasure=1.0))}\n",
      "{'meteor': 0.9375}\n"
     ]
    }
   ],
   "source": [
    "fake_preds = [\"hello there\", \"general kenobi\"]\n",
    "fake_labels = [\"hello there\", \"general kenobi\"]\n",
    "print(metric.compute(predictions=fake_preds, references=fake_labels))\n",
    "print(metric_meteor.compute(predictions=fake_preds, references=fake_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:37:32.989559Z",
     "iopub.status.busy": "2023-07-29T05:37:32.988963Z",
     "iopub.status.idle": "2023-07-29T05:37:34.045128Z",
     "shell.execute_reply": "2023-07-29T05:37:34.043943Z",
     "shell.execute_reply.started": "2023-07-29T05:37:32.989531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28af3baa9caf42e890f4b111abc12410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4f5b6854f940fcb47b7b343042c691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0023f3374f0942f7a1e43c71645871b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:37:34.047222Z",
     "iopub.status.busy": "2023-07-29T05:37:34.046774Z",
     "iopub.status.idle": "2023-07-29T05:37:34.062675Z",
     "shell.execute_reply": "2023-07-29T05:37:34.061648Z",
     "shell.execute_reply.started": "2023-07-29T05:37:34.047187Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [8774, 6, 48, 80, 7142, 55, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Hello, this one sentence!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:37:34.065297Z",
     "iopub.status.busy": "2023-07-29T05:37:34.064210Z",
     "iopub.status.idle": "2023-07-29T05:37:34.073187Z",
     "shell.execute_reply": "2023-07-29T05:37:34.072132Z",
     "shell.execute_reply.started": "2023-07-29T05:37:34.065264Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[8774, 6, 48, 80, 7142, 55, 1], [100, 19, 430, 7142, 5, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer([\"Hello, this one sentence!\", \"This is another sentence.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:37:34.077732Z",
     "iopub.status.busy": "2023-07-29T05:37:34.075875Z",
     "iopub.status.idle": "2023-07-29T05:37:34.085394Z",
     "shell.execute_reply": "2023-07-29T05:37:34.084444Z",
     "shell.execute_reply.started": "2023-07-29T05:37:34.077698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[8774, 6, 48, 80, 7142, 55, 1], [100, 19, 430, 7142, 5, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer(text_target=[\"Hello, this one sentence!\", \"This is another sentence.\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:37:34.087262Z",
     "iopub.status.busy": "2023-07-29T05:37:34.086710Z",
     "iopub.status.idle": "2023-07-29T05:37:34.097290Z",
     "shell.execute_reply": "2023-07-29T05:37:34.096369Z",
     "shell.execute_reply.started": "2023-07-29T05:37:34.087228Z"
    }
   },
   "outputs": [],
   "source": [
    "if model_checkpoint in [\"t5-small\", \"t5-base\", \"t5-larg\", \"t5-3b\", \"t5-11b\"]:\n",
    "    prefix = \"summarize: \"\n",
    "else:\n",
    "    prefix = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:37:34.098695Z",
     "iopub.status.busy": "2023-07-29T05:37:34.098435Z",
     "iopub.status.idle": "2023-07-29T05:37:34.110394Z",
     "shell.execute_reply": "2023-07-29T05:37:34.109438Z",
     "shell.execute_reply.started": "2023-07-29T05:37:34.098671Z"
    }
   },
   "outputs": [],
   "source": [
    "max_input_length = 1024\n",
    "max_target_length = 128\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    labels = tokenizer(text_target=examples[\"spoiler\"], max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "def preprocess_function_test(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:37:34.113688Z",
     "iopub.status.busy": "2023-07-29T05:37:34.113307Z",
     "iopub.status.idle": "2023-07-29T05:37:34.136011Z",
     "shell.execute_reply": "2023-07-29T05:37:34.134952Z",
     "shell.execute_reply.started": "2023-07-29T05:37:34.113662Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[21603, 10, 101, 7, 101, 40, 2304, 6834, 15, 26, 18428, 438, 3059, 24927, 6, 299, 20109, 7, 1593, 279, 10118, 10855, 22834, 101, 7, 101, 40, 2304, 6834, 15, 26, 18428, 438, 3059, 24927, 6, 299, 20109, 7, 1593, 279, 10118, 71, 10855, 22834, 196, 17, 22, 195, 36, 131, 114, 625, 648, 48, 1851, 21, 3059, 24927, 11, 101, 7, 101, 40, 2304, 101, 40, 2304, 5111, 1701, 1379, 30, 3, 9, 8327, 2252, 2478, 24, 3, 88, 3, 12655, 24927, 250, 3, 88, 22, 195, 36, 16, 1511, 21, 1771, 22, 7, 467, 344, 8, 368, 2789, 20109, 7, 11, 8327, 27676, 7, 44, 18584, 1954, 12750, 94, 3776, 114, 3, 9, 626, 1004, 21, 8, 192, 12, 3579, 95, 299, 24927, 22, 7, 4903, 13, 3, 11907, 95, 5806, 623, 72, 145, 131, 3, 9, 3506, 86, 685, 6, 34, 5806, 128, 26998, 3, 11907, 38, 8, 20109, 7, 20134, 1416, 12, 1049, 4816, 383, 112, 662, 7261, 374, 13710, 15, 5339, 9756, 27, 1560, 376, 95, 12, 103, 2634, 1856, 706, 216, 22, 7, 114, 6, 458, 196, 22, 51, 352, 12, 36, 7070, 16, 45, 6206, 27560, 865, 227, 8, 5847, 9939, 32, 19042, 3370, 467, 6, 68, 149, 81, 24, 1379, 62, 281, 3793, 58, 22, 101, 40, 2304, 243, 30, 549, 23008, 329, 6, 399, 37, 5053, 20790, 275, 27, 22, 51, 131, 3823, 132, 6, 27, 22, 51, 114, 6, 458, 196, 47, 131, 1631, 81, 2634, 6, 68, 17945, 6, 417, 27, 22, 195, 129, 147, 132, 778, 11, 62, 54, 3793, 3, 9, 385, 720, 22, 101, 40, 2304, 47, 80, 13, 24927, 22, 7, 1305, 8874, 21, 1296, 9385, 45, 4101, 12, 1673, 94, 22, 7, 734, 179, 376, 11, 24927, 241, 12, 942, 28, 321, 271, 16, 8, 337, 616, 299, 24927, 3115, 19, 66, 268, 383, 3370, 774, 101, 40, 2304, 1077, 225, 43, 801, 125, 3, 88, 47, 652, 139, 116, 7232, 91, 12, 112, 23707, 466, 22, 7, 8, 163, 589, 62, 310, 43, 4355, 6, 101, 40, 2304, 243, 13, 112, 3, 4685, 7203, 28, 24927, 94, 22, 7, 131, 6613, 27, 22, 51, 3823, 132, 1119, 12, 43, 2634, 458, 3845, 63, 6, 129, 39, 38, 7, 95, 270, 11, 752, 22, 7, 281, 3793, 22, 27, 22, 51, 114, 6, 458, 188, 210, 528, 457, 6, 388, 22, 216, 22, 7, 352, 12, 43, 140, 1180, 114, 204, 6890, 9722, 7, 16, 112, 11278, 42, 424, 3836, 24927, 56, 474, 3, 9, 207, 1448, 16, 21, 101, 40, 2304, 323, 16, 7547, 14901, 3, 99, 8, 1798, 20109, 7, 1148, 11487, 18514, 15, 7, 376, 631, 1], [21603, 10, 15971, 3369, 833, 21, 423, 3938, 13, 3, 32, 9431, 6356, 5838, 15, 86, 411, 9431, 22697, 19539, 15, 26, 304, 1796, 4043, 16532, 938, 460, 2518, 15971, 1755, 2518, 19, 20266, 95, 12, 36, 3, 9, 248, 215, 21, 8007, 4030, 466, 31, 7, 116, 15971, 7004, 33, 3, 29856, 8, 6356, 16, 8, 3, 32, 9431, 3760, 429, 2031, 143, 3, 9, 423, 3938, 23066, 2162, 70, 7489, 6, 16, 811, 12, 119, 7469, 6, 16, 3, 9, 3831, 2875, 383, 8, 2041, 797, 10107, 21682, 3545, 1338, 16, 1051, 5901, 37, 372, 13, 7004, 3346, 2299, 44, 8, 5368, 5761, 13, 8, 3, 32, 9431, 6356, 6, 84, 65, 3, 21082, 16, 321, 812, 11, 4963, 437, 8, 5792, 13, 8, 17219, 21720, 16, 12701, 37, 2791, 18168, 165, 3, 27181, 1320, 6546, 1440, 45, 338, 9356, 6, 114, 19782, 32, 6947, 127, 32, 17089, 7, 205, 5390, 7, 6, 24, 1733, 323, 139, 29879, 16, 8, 4548, 4643, 11, 6263, 8, 3, 32, 9431, 3760, 328, 435, 24, 6, 298, 1425, 13, 29879, 16, 8, 4643, 43, 5071, 13665, 38, 3, 9, 741, 13, 8, 10015, 6, 34, 31, 7, 396, 1116, 12, 6177, 135, 12, 3, 9, 11960, 3, 32, 9431, 3760, 411, 9431, 8034, 28, 2755, 844, 11, 3, 9, 2186, 792, 866, 13, 3, 32, 9431, 33, 59, 6539, 2084, 13, 3938, 44, 5135, 3869, 12, 8, 1644, 29879, 7198, 6, 10445, 5438, 2618, 13, 15971, 31, 7, 601, 26, 986, 5844, 16736, 1166, 5243, 16, 3, 9, 783, 4456, 53, 466, 20662, 19, 114, 1119, 12, 734, 125, 31, 7, 1786, 28, 39, 443, 31, 7, 1948, 406, 14931, 8, 3, 4500, 3910, 6, 8, 7004, 857, 8, 167, 1100, 3, 32, 9431, 6356, 1112, 6, 379, 321, 8, 2015, 6356, 664, 6, 16, 3581, 6, 11, 80, 13, 8, 3, 17924, 8034, 6, 16, 1673, 6, 33, 3, 5325, 788, 12, 1969, 16366, 13551, 43, 8, 1418, 12, 888, 3, 32, 9431, 16, 508, 16274, 6, 3762, 17292, 8, 6356, 128, 203, 6, 298, 12385, 12, 2463, 34, 16, 717, 486, 8, 798, 6, 34, 19, 13551, 11, 7902, 24, 33, 310, 14498, 149, 600, 8, 3, 32, 9431, 6356, 19, 6, 5438, 2618, 1219, 8, 9938, 3306, 31385, 2279, 1969, 19, 1644, 12, 36, 8, 31990, 2945, 16, 8, 3, 32, 9431, 6356, 31, 7, 812, 552, 460, 1828, 6, 44, 84, 500, 205, 5390, 7, 56, 43, 6292, 631, 38, 3, 9, 741, 13, 8, 17219, 21720, 12, 582, 20815, 938, 460, 2518, 6, 983, 6, 8, 3, 32, 9431, 6356, 19, 1644, 12, 43, 263, 3, 9, 423, 3938, 94, 22, 7, 59, 352, 12, 36, 3, 9, 3050, 2564, 6, 5438, 2618, 14291, 15, 26, 8, 3144, 4975, 5324, 290, 56, 36, 128, 13033, 7, 16, 8, 1373, 6, 68, 1879, 8, 4166, 19, 22032, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[149, 81, 24, 1379, 62, 281, 3793, 58, 1], [460, 2518, 1]]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(preprocess_function(train_data[:1]))\n",
    "# len(preprocess_function(train_data[:1])[0]['input_ids'][0])\n",
    "preprocess_function(train_data['train'][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:37:34.137952Z",
     "iopub.status.busy": "2023-07-29T05:37:34.137536Z",
     "iopub.status.idle": "2023-07-29T05:37:34.151528Z",
     "shell.execute_reply": "2023-07-29T05:37:34.150298Z",
     "shell.execute_reply.started": "2023-07-29T05:37:34.137920Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[21603, 10, 216, 2067, 19376, 7, 71, 20252, 486, 37, 4457, 37, 29, 148, 1610, 363, 31, 7, 461, 37, 12324, 3021, 304, 37, 51, 17830, 20252, 11429, 7, 7309, 366, 978, 3, 17701, 6342, 15, 5405, 216, 1072, 6434, 5918, 71, 13824, 3186, 10555, 25, 317, 81, 39, 207, 803, 6, 186, 378, 369, 12, 809, 149, 28034, 280, 133, 36, 406, 135, 6, 149, 79, 143, 25, 8719, 11, 3993, 116, 25, 174, 34, 6, 11, 149, 79, 33, 132, 12, 380, 25, 16, 136, 1419, 148, 164, 237, 987, 909, 8, 822, 3, 318, 125, 133, 27, 103, 21, 135, 16, 1205, 58, 242, 997, 1201, 1490, 15146, 3038, 329, 1092, 152, 6, 8, 1525, 19, 650, 132, 19, 914, 150, 2006, 12, 125, 3, 88, 133, 103, 21, 112, 803, 264, 6, 116, 112, 23707, 19445, 12561, 172, 2381, 6, 3, 9, 1902, 1201, 1490, 10444, 44, 2474, 322, 432, 2788, 7, 16, 4361, 16990, 6, 332, 4, 6, 435, 2448, 16, 174, 13, 3, 9, 11546, 6, 3038, 329, 1092, 152, 737, 22, 17, 10888, 12, 253, 91, 3, 99, 3, 88, 228, 13213, 80, 13, 112, 282, 34, 2120, 91, 6, 3, 88, 47, 3, 9, 1588, 216, 1500, 12, 4158, 112, 1565, 28, 8, 207, 1506, 6, 11, 410, 78, 16, 8, 167, 3904, 194, 86, 48, 3973, 5516, 6, 3038, 329, 1092, 152, 10681, 139, 8, 2833, 213, 12561, 172, 2381, 930, 216, 65, 14526, 7, 11, 3, 9, 1320, 16, 609, 24, 608, 7, 6, 216, 986, 19981, 174, 13, 3, 9, 11546, 6, 241, 2000, 58, 94, 1330, 114, 8, 1021, 388, 19, 882, 8, 10802, 1370, 37, 798, 12561, 172, 2381, 217, 7, 376, 6, 3, 88, 734, 3834, 9797, 323, 139, 12795, 216, 54, 11289, 857, 112, 207, 5851, 59, 163, 405, 3, 88, 129, 3, 9, 11546, 6, 68, 3, 88, 4054, 24, 3, 88, 92, 65, 3, 9, 248, 1565, 113, 56, 36, 57, 112, 596, 190, 4126, 11, 5551, 37, 1876, 13, 280, 11, 8, 1876, 13, 9888, 33, 321, 594, 924, 1], [21603, 10, 1615, 25, 10046, 27986, 36, 25054, 44, 161, 1615, 25, 10046, 27986, 36, 25054, 44, 161, 5090, 53, 717, 56, 991, 12, 3, 31, 729, 15, 1859, 485, 5958, 670, 31, 11, 54, 1783, 39, 1415, 1326, 31, 60, 373, 271, 6470, 12, 199, 717, 274, 62, 199, 3242, 275, 16, 8, 6940, 3, 3131, 39, 523, 274, 273, 13, 39, 6976, 19, 557, 894, 38, 25054, 7916, 299, 126, 585, 845, 271, 1044, 924, 44, 161, 54, 223, 6608, 22643, 44, 8, 8225, 13, 39, 293, 19016, 8542, 39, 1253, 13, 307, 1987, 1269, 86, 46, 1108, 21, 37, 13199, 1769, 4543, 6, 549, 13626, 106, 1121, 13, 8, 636, 13, 8913, 5812, 6, 707, 7124, 8059, 11, 549, 13626, 106, 2449, 13926, 18658, 22789, 24438, 15, 2075, 8, 3, 31, 729, 15, 1859, 485, 5958, 670, 31, 328, 857, 24, 1044, 15543, 44, 161, 3433, 12, 10685, 23, 106, 6, 11, 3575, 6402, 557, 4781, 7, 8, 151, 25, 3855, 12, 199, 3, 31, 188, 40, 11841, 428, 52, 7, 33, 8, 167, 3435, 151, 16, 2371, 6, 79, 22, 60, 92, 44, 8, 4016, 1020, 21, 5958, 670, 31, 6, 8, 5921, 2832, 16, 37, 13199, 1769, 4543, 3, 31, 10555, 79, 278, 22, 17, 1822, 1452, 6, 70, 7686, 16, 717, 54, 1137, 135, 12, 473, 147, 19496, 11, 13034, 26, 6, 1590, 1187, 16, 70, 161, 1766, 6, 11, 522, 72, 2189, 11, 4129, 44, 234, 31, 6, 79, 243, 86, 70, 1083, 73, 23841, 585, 6, 5921, 707, 8059, 11, 1363, 24438, 15, 7463, 3, 9, 620, 13, 2476, 555, 331, 356, 764, 45, 3, 9, 810, 4468, 28, 72, 145, 4837, 3081, 16, 2061, 1019, 8, 837, 486, 8, 456, 13, 8, 215, 79, 1380, 135, 746, 81, 70, 1295, 12, 2022, 717, 2940, 4269, 2225, 8, 5921, 12, 9689, 149, 168, 70, 481, 133, 103, 16, 70, 14026, 44, 8, 414, 13, 8, 215, 947, 19, 3, 9, 3106, 822, 45, 70, 794, 6, 16854, 16, 1769, 9014, 52, 209, 6783, 155, 159, 15, 497, 4273, 116, 34, 4573, 167, 204, 6434, 16, 3, 9, 194, 24, 19, 16, 39, 293, 1046, 11, 8996, 7, 39, 293, 827, 1438, 220, 1008, 31, 17, 36, 7403, 12, 2401, 161, 12, 119, 151, 116, 25, 278, 31, 17, 43, 97, 314, 736, 102, 40, 4921, 39, 1113, 320, 21, 1155, 12, 199, 186, 151, 16, 3, 9, 712, 17374, 305, 374, 4370, 342, 6438, 13, 97, 12, 1517, 1066, 145, 692, 34, 66, 8, 97, 94, 31, 195, 143, 25, 72, 992, 3843, 11, 1231, 431, 15856, 151, 113, 163, 240, 79, 31, 195, 7128, 39, 827, 9149, 13199, 1769, 4543, 11648, 24, 25, 31, 60, 2119, 3, 9, 23898, 853, 6, 11, 25, 31, 162, 3, 29177, 12, 1049, 227, 496, 80, 239, 3, 9, 471, 12, 199, 80, 13, 39, 481, 6, 5104, 6, 1172, 112, 1705, 13, 23898, 216, 987, 7, 3, 99, 25, 31, 195, 92, 199, 112, 1565, 15597, 6, 113, 19, 29, 31, 17, 16, 39, 853, 363, 133, 25, 103, 58, 3, 9, 14890, 3, 9, 2450, 227, 6646, 2363, 12, 199, 15597, 6, 78, 25, 54, 394, 734, 112, 928, 523, 3, 115, 30090, 15597, 12, 2561, 16, 30, 39, 23898, 3975, 28, 5104, 3, 75, 8779, 5104, 24, 34, 31, 7, 1245, 24, 3, 88, 2746, 12, 199, 15597, 6, 68, 3, 88, 310, 523, 12, 992, 30, 112, 293, 161, 16, 455, 12, 3579, 95, 3, 26, 8779, 5104, 24, 15597, 225, 987, 112, 293, 3145, 21, 199, 3705, 2246, 7, 53, 120, 6, 8, 14614, 28, 3081, 113, 9986, 3, 9, 410, 8, 6025, 16, 70, 414, 13, 215, 14026, 37, 3081, 113, 5046, 1452, 11, 130, 705, 1044, 924, 530, 70, 481, 394, 6784, 3, 31, 134, 10386, 924, 16530, 21436, 1452, 1119, 12, 199, 921, 28, 334, 1690, 31, 6, 8, 5921, 243, 86, 8, 414, 6, 79, 130, 18488, 8, 182, 481, 79, 1114, 12, 199, 933, 163, 16, 2119, 6, 68, 1044, 924, 151, 5696, 167, 16, 6940, 7, 11, 253, 1452, 24614, 53, 16, 10473, 11, 3, 6319, 12, 6665, 70, 293, 1766, 38, 3, 9, 741, 2940, 585, 92, 3217, 151, 113, 1822, 70, 293, 97, 54, 428, 8, 167, 307, 1987, 6275, 2940, 161, 1267, 34, 31, 7, 81, 3, 10810, 4733, 97, 78, 116, 25, 199, 119, 151, 25, 278, 31, 17, 356, 909, 223, 16, 8, 433, 707, 8059, 11, 1363, 24438, 15, 3209, 24, 25, 174, 12, 1423, 386, 843, 378, 116, 1517, 12, 119, 151, 3, 31, 9032, 15908, 81, 149, 25, 199, 6, 116, 25, 199, 6, 11, 4068, 25, 199, 31, 465, 80, 54, 36, 347, 66, 8, 97, 12, 199, 119, 151, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_function_test(test_data['train'][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:37:34.153703Z",
     "iopub.status.busy": "2023-07-29T05:37:34.153357Z",
     "iopub.status.idle": "2023-07-29T05:37:34.157756Z",
     "shell.execute_reply": "2023-07-29T05:37:34.156887Z",
     "shell.execute_reply.started": "2023-07-29T05:37:34.153669Z"
    }
   },
   "outputs": [],
   "source": [
    "# temp_var = preprocess_function(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:37:34.160780Z",
     "iopub.status.busy": "2023-07-29T05:37:34.159956Z",
     "iopub.status.idle": "2023-07-29T05:37:43.012373Z",
     "shell.execute_reply": "2023-07-29T05:37:43.011213Z",
     "shell.execute_reply.started": "2023-07-29T05:37:34.160742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.dataset_dict.DatasetDict'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef68e8a573eb4802a91ef3815f5969bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb3ff9129c3148d3a4de6f75fecfb8cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bbc64de0812495fa24b2aa298dd1e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(type(train_data))\n",
    "\n",
    "\n",
    "# train_data_tokenized = preprocess_function(train_data)\n",
    "# test_data_tokenized = preprocess_function_test(test_data)\n",
    "# validation_data_tokenized = preprocess_function(validation_data)\n",
    "\n",
    "train_datasets = train_data.map(preprocess_function, batched=True)\n",
    "validation_datasets = val_data.map(preprocess_function, batched=True)\n",
    "test_datasets = test_data.map(preprocess_function_test, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:37:43.019119Z",
     "iopub.status.busy": "2023-07-29T05:37:43.018806Z",
     "iopub.status.idle": "2023-07-29T05:37:43.024129Z",
     "shell.execute_reply": "2023-07-29T05:37:43.023018Z",
     "shell.execute_reply.started": "2023-07-29T05:37:43.019084Z"
    }
   },
   "outputs": [],
   "source": [
    "# validation_data_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:37:43.026314Z",
     "iopub.status.busy": "2023-07-29T05:37:43.025710Z",
     "iopub.status.idle": "2023-07-29T05:37:43.092551Z",
     "shell.execute_reply": "2023-07-29T05:37:43.091286Z",
     "shell.execute_reply.started": "2023-07-29T05:37:43.026279Z"
    }
   },
   "outputs": [],
   "source": [
    "# from datasets import Dataset, DatasetDict\n",
    "# # train_data_tokenized = train_data_tokenized\n",
    "# # validation_data_tokenized = validation_data_tokenized\n",
    "# # test_data_tokenized = test_data_tokenized\n",
    "\n",
    "# # Creating the DatasetDict\n",
    "# train_dataset_dict = DatasetDict({\n",
    "#     'train': train_data_tokenized\n",
    "# })\n",
    "\n",
    "# validation_dataset_dict = DatasetDict({\n",
    "#     'validation': validation_data_tokenized\n",
    "# })\n",
    "\n",
    "# # Printing the dataset_dict\n",
    "# # print(dataset_dict['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:37:43.093951Z",
     "iopub.status.busy": "2023-07-29T05:37:43.093685Z",
     "iopub.status.idle": "2023-07-29T05:37:43.108275Z",
     "shell.execute_reply": "2023-07-29T05:37:43.107309Z",
     "shell.execute_reply.started": "2023-07-29T05:37:43.093928Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(validation_dataset_dict['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:37:43.109892Z",
     "iopub.status.busy": "2023-07-29T05:37:43.109482Z",
     "iopub.status.idle": "2023-07-29T05:37:56.909275Z",
     "shell.execute_reply": "2023-07-29T05:37:56.908291Z",
     "shell.execute_reply.started": "2023-07-29T05:37:43.109860Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "788b960801f148b680bc339d832f7838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a171ac1a7e4aac86bfed1eef2cca64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "\n",
    "# Load model directly\n",
    "# from transformers import AutoModel\n",
    "# model_longformer = AutoModel.from_pretrained(\"allenai/longformer-base-4096\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:37:56.911248Z",
     "iopub.status.busy": "2023-07-29T05:37:56.910772Z",
     "iopub.status.idle": "2023-07-29T05:37:57.007305Z",
     "shell.execute_reply": "2023-07-29T05:37:57.006369Z",
     "shell.execute_reply.started": "2023-07-29T05:37:56.911210Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 1    #for T5-small it is 16, for bart base, I am keeping it 4\n",
    "gradient_accumulation_steps = 1  # Use gradient accumulation to effectively increase the batch size\n",
    "\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-finetuned-xsum\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,    #2e-5 or any value can be used here\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,  # Add gradient accumulation\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=25,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:37:57.009297Z",
     "iopub.status.busy": "2023-07-29T05:37:57.008901Z",
     "iopub.status.idle": "2023-07-29T05:37:57.014160Z",
     "shell.execute_reply": "2023-07-29T05:37:57.013075Z",
     "shell.execute_reply.started": "2023-07-29T05:37:57.009261Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "# data_collator_longformer = DataCollatorForSeq2Seq(tokenizer, model=model_longformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:37:57.016112Z",
     "iopub.status.busy": "2023-07-29T05:37:57.015783Z",
     "iopub.status.idle": "2023-07-29T05:37:57.029806Z",
     "shell.execute_reply": "2023-07-29T05:37:57.028846Z",
     "shell.execute_reply.started": "2023-07-29T05:37:57.016081Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "#     # Round numeric values in the \"result\" dictionary\n",
    "#     rounded_result = {k: round(float(v), 4) if isinstance(v, (int, float)) else v for k, v in result.items()}\n",
    "#     rounded_result_meteor = {k: round(float(v), 4) if isinstance(v, (int, float)) else v for k, v in result_meteor.items()}\n",
    "    \n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    # Note that other metrics may not have a `use_aggregator` parameter\n",
    "    # and thus will return a list, computing a metric for each sentence.\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True, use_aggregator=True)\n",
    "    result_meteor = metric_meteor.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    # Convert tuples to strings to avoid TypeError during rounding\n",
    "    result = {key: str(value) if isinstance(value, tuple) else value for key, value in result.items()}\n",
    "    result_meteor = {key: str(value) if isinstance(value, tuple) else value for key, value in result_meteor.items()}\n",
    "    \n",
    "    # Add mean generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "#     # Round numeric values in the \"result\" dictionary\n",
    "#     rounded_result = {k: round(float(v), 4) if isinstance(v, (int, float)) else v for k, v in result.items()}\n",
    "#     rounded_result_meteor = {k: round(float(v), 4) if isinstance(v, (int, float)) else v for k, v in result_meteor.items()}\n",
    "    \n",
    "    result = {key: str(value) if isinstance(value, tuple) else value for key, value in result.items()}\n",
    "    result_meteor = {key: str(value) if isinstance(value, tuple) else value for key, value in result_meteor.items()}\n",
    "    \n",
    "    merged_result = {**result, **result_meteor}\n",
    "    \n",
    "    merged_result = {key: str(value) if isinstance(value, tuple) else value for key, value in merged_result.items()}\n",
    "\n",
    "    return merged_result\n",
    "#     return rounded_result, rounded_result_meteor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:37:57.031724Z",
     "iopub.status.busy": "2023-07-29T05:37:57.031115Z",
     "iopub.status.idle": "2023-07-29T05:37:57.048839Z",
     "shell.execute_reply": "2023-07-29T05:37:57.048169Z",
     "shell.execute_reply.started": "2023-07-29T05:37:57.031692Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics_meteor(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "\n",
    "    # Note that other metrics may not have a `use_aggregator` parameter\n",
    "    # and thus will return a list, computing a metric for each sentence.\n",
    "    result = metric_meteor.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "    # Convert tuples to strings to avoid TypeError during rounding\n",
    "    result = {key: str(value) if isinstance(value, tuple) else value for key, value in result.items()}\n",
    "\n",
    "    # Add mean generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    # Round numeric values in the \"result\" dictionary\n",
    "    rounded_result = {k: round(float(v), 4) if isinstance(v, (int, float)) else v for k, v in result.items()}\n",
    "\n",
    "    return rounded_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:37:57.050644Z",
     "iopub.status.busy": "2023-07-29T05:37:57.050072Z",
     "iopub.status.idle": "2023-07-29T05:38:05.886497Z",
     "shell.execute_reply": "2023-07-29T05:38:05.885385Z",
     "shell.execute_reply.started": "2023-07-29T05:37:57.050612Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_datasets['train'],\n",
    "    eval_dataset=validation_datasets['train'],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# trainer_longformer = Seq2SeqTrainer(\n",
    "#     model_longformer,\n",
    "#     args,\n",
    "#     train_dataset=train_datasets['train'],\n",
    "#     eval_dataset=validation_datasets['train'],\n",
    "#     data_collator=data_collator_longformer,\n",
    "#     tokenizer=tokenizer,\n",
    "#     compute_metrics=compute_metrics_meteor\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T05:38:05.888616Z",
     "iopub.status.busy": "2023-07-29T05:38:05.888200Z",
     "iopub.status.idle": "2023-07-29T12:24:14.732633Z",
     "shell.execute_reply": "2023-07-29T12:24:14.731603Z",
     "shell.execute_reply.started": "2023-07-29T05:38:05.888579Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20230729_053906-f4gilhrx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sushilkumar-yadav/huggingface/runs/f4gilhrx' target=\"_blank\">fiery-sound-13</a></strong> to <a href='https://wandb.ai/sushilkumar-yadav/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sushilkumar-yadav/huggingface' target=\"_blank\">https://wandb.ai/sushilkumar-yadav/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sushilkumar-yadav/huggingface/runs/f4gilhrx' target=\"_blank\">https://wandb.ai/sushilkumar-yadav/huggingface/runs/f4gilhrx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40000' max='40000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40000/40000 6:44:28, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Meteor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.824200</td>\n",
       "      <td>0.693415</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.50374467516246, recall=0.3950312421041104, fmeasure=0.4009300615671617), mid=Score(precision=0.5508269325649844, recall=0.4377431468047417, fmeasure=0.4437955403157695), high=Score(precision=0.5924131508656787, recall=0.4814349023947423, fmeasure=0.48569636357309853))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.32415513882563507, recall=0.24116713583581448, fmeasure=0.24807727303755503), mid=Score(precision=0.37230533110680164, recall=0.284048367036263, fmeasure=0.2917552116519039), high=Score(precision=0.41967156942322376, recall=0.3283530998381211, fmeasure=0.33637622054894095))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5002665993218384, recall=0.3908571259708004, fmeasure=0.39738353385688796), mid=Score(precision=0.5447898147604031, recall=0.43653778143686955, fmeasure=0.4417086861348908), high=Score(precision=0.5867395539713557, recall=0.4752899007117366, fmeasure=0.4805056434631726))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5030752680683289, recall=0.3933248535347709, fmeasure=0.40005799078094334), mid=Score(precision=0.5446403479078116, recall=0.43432685693357936, fmeasure=0.44093277493439226), high=Score(precision=0.5903517606015308, recall=0.47887897416149655, fmeasure=0.48380662321544093))</td>\n",
       "      <td>7.647500</td>\n",
       "      <td>0.347145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.622500</td>\n",
       "      <td>0.712881</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.527739741610514, recall=0.4370059980983654, fmeasure=0.4358954757256339), mid=Score(precision=0.5714736264552442, recall=0.4778611400925878, fmeasure=0.4768513234544952), high=Score(precision=0.6146321538245254, recall=0.5195119122954068, fmeasure=0.5177724887891918))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.3543141609768907, recall=0.28395698320495183, fmeasure=0.2851579799782941), mid=Score(precision=0.40616802345938374, recall=0.3275382621819256, fmeasure=0.3283892502617305), high=Score(precision=0.44978674108265104, recall=0.3698936635307192, fmeasure=0.36869021067127855))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5185538893143213, recall=0.4258741552636579, fmeasure=0.4270935995543483), mid=Score(precision=0.5653810165528919, recall=0.4746477038655662, fmeasure=0.4734905364837827), high=Score(precision=0.6095405537171162, recall=0.5147671669739285, fmeasure=0.5153524643838899))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.520625008814715, recall=0.4304497631912279, fmeasure=0.43007567480851583), mid=Score(precision=0.5646860274121306, recall=0.47321055104758847, fmeasure=0.4724515723061629), high=Score(precision=0.6120335296647796, recall=0.5185080231578897, fmeasure=0.5178683569804874))</td>\n",
       "      <td>8.265000</td>\n",
       "      <td>0.385405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.497100</td>\n",
       "      <td>0.777548</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5331904431863072, recall=0.45087585738649055, fmeasure=0.45075347532399707), mid=Score(precision=0.5763436989889197, recall=0.4945579037620764, fmeasure=0.49023178450295496), high=Score(precision=0.6174235605999394, recall=0.5365393927766676, fmeasure=0.5297563986141037))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.36719628309292823, recall=0.30587960609493176, fmeasure=0.301557969220732), mid=Score(precision=0.4169130579387933, recall=0.35045207108716137, fmeasure=0.3457120067846823), high=Score(precision=0.4598829581774435, recall=0.3910793078305143, fmeasure=0.384376074059876))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5267565052645476, recall=0.44491138252544865, fmeasure=0.4415243212615851), mid=Score(precision=0.5727273643431731, recall=0.4922134864432244, fmeasure=0.4880874401221894), high=Score(precision=0.6149689428422885, recall=0.532122136034154, fmeasure=0.5287386929330931))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5285157490130379, recall=0.4517453973610428, fmeasure=0.4468037832252721), mid=Score(precision=0.5719504160055633, recall=0.49089313461939194, fmeasure=0.48674249271064685), high=Score(precision=0.6156832945700133, recall=0.534725525577376, fmeasure=0.5289380355243442))</td>\n",
       "      <td>8.787500</td>\n",
       "      <td>0.403219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.375800</td>\n",
       "      <td>0.829872</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5412672658377163, recall=0.45513236507115323, fmeasure=0.4551835090858312), mid=Score(precision=0.5845412139943393, recall=0.49750124518721084, fmeasure=0.49446764261490556), high=Score(precision=0.6284674846803522, recall=0.540132108532697, fmeasure=0.5342480706395474))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.37346645680708185, recall=0.3047298385765066, fmeasure=0.30192393741350876), mid=Score(precision=0.42243776709401715, recall=0.3516826915753868, fmeasure=0.34878833425631783), high=Score(precision=0.46618386370573867, recall=0.3931275748566205, fmeasure=0.38816951133760863))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5348380660495552, recall=0.44730878128269425, fmeasure=0.4478069210386667), mid=Score(precision=0.5807231321578747, recall=0.49494168454390297, fmeasure=0.49223792047468123), high=Score(precision=0.6231185674262426, recall=0.5377793624840058, fmeasure=0.5325724675878535))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5376278306966727, recall=0.45214098918964046, fmeasure=0.4484315458777804), mid=Score(precision=0.5799661852648986, recall=0.4952037767825636, fmeasure=0.4924341795467362), high=Score(precision=0.6247090061898884, recall=0.5393116764093813, fmeasure=0.5355486715926939))</td>\n",
       "      <td>8.640000</td>\n",
       "      <td>0.405586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.298300</td>\n",
       "      <td>0.975063</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5175428294438408, recall=0.47447747145152425, fmeasure=0.45247994763655425), mid=Score(precision=0.5608362840182693, recall=0.5141582836336074, fmeasure=0.4947662046914818), high=Score(precision=0.6062349094583929, recall=0.5560253963267795, fmeasure=0.5353633280988147))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.3634709534848322, recall=0.3252322184343023, fmeasure=0.3107764772012784), mid=Score(precision=0.4106462962078772, recall=0.36772324037334886, fmeasure=0.35335459777754186), high=Score(precision=0.45479845344096287, recall=0.4106300748319435, fmeasure=0.3936347113975262))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5134401626202637, recall=0.46953668534920584, fmeasure=0.4484198269290288), mid=Score(precision=0.5577387804189275, recall=0.5112382236359349, fmeasure=0.49101449069668474), high=Score(precision=0.5996922877928851, recall=0.5570728278066365, fmeasure=0.5319522092190736))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5156355908848099, recall=0.4690588245617645, fmeasure=0.45011844068346246), mid=Score(precision=0.5566344452116511, recall=0.5115673244284322, fmeasure=0.49120991366107225), high=Score(precision=0.6014447967269659, recall=0.5544559703639872, fmeasure=0.5330012257331932))</td>\n",
       "      <td>10.007500</td>\n",
       "      <td>0.420511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.270800</td>\n",
       "      <td>1.098126</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5074463694954964, recall=0.46043762306410846, fmeasure=0.44109114118238485), mid=Score(precision=0.5486745771589521, recall=0.500025356707609, fmeasure=0.4808419807094889), high=Score(precision=0.5910796891272535, recall=0.5456416664037573, fmeasure=0.5217880315305629))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.34900603965070875, recall=0.31227670307354144, fmeasure=0.2980681799358823), mid=Score(precision=0.395378158095989, recall=0.3572343275681604, fmeasure=0.3412818654393265), high=Score(precision=0.4391090922965925, recall=0.4021170262677988, fmeasure=0.3822572048115607))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.49675160395160395, recall=0.45484595640212305, fmeasure=0.43814107846145894), mid=Score(precision=0.5438883900005225, recall=0.4973385692415147, fmeasure=0.4780715966275405), high=Score(precision=0.5872730261517488, recall=0.5411721439965795, fmeasure=0.5182359144438378))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5021420538203628, recall=0.4537165716052205, fmeasure=0.4368605729461429), mid=Score(precision=0.5445191572112527, recall=0.49757210153385667, fmeasure=0.47794721442314614), high=Score(precision=0.5875651611103356, recall=0.5405231495355977, fmeasure=0.5213669751271853))</td>\n",
       "      <td>9.745000</td>\n",
       "      <td>0.407566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.231400</td>\n",
       "      <td>1.162157</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5279019236329441, recall=0.4582564774034394, fmeasure=0.45077771364175206), mid=Score(precision=0.5672132612077465, recall=0.4975824986703318, fmeasure=0.48872959087434403), high=Score(precision=0.6124884771274478, recall=0.5421491029626436, fmeasure=0.5310636618202511))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.3684177153320537, recall=0.3194334517429859, fmeasure=0.3115894612592788), mid=Score(precision=0.4171563069283658, recall=0.3622446279463513, fmeasure=0.3552827610449666), high=Score(precision=0.4595523779172219, recall=0.405226968105026, fmeasure=0.3940583010565006))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5215926107695408, recall=0.4538265872469879, fmeasure=0.4466740623101706), mid=Score(precision=0.5657799414637651, recall=0.4972812741573638, fmeasure=0.48821242886618066), high=Score(precision=0.6083522260419322, recall=0.540542730053347, fmeasure=0.5306833399457865))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5201086107009821, recall=0.45542371511518526, fmeasure=0.446361724826062), mid=Score(precision=0.5653100323899958, recall=0.49707557573735406, fmeasure=0.48801635200403704), high=Score(precision=0.6114752105482345, recall=0.5427945296049967, fmeasure=0.5326318287072702))</td>\n",
       "      <td>9.237500</td>\n",
       "      <td>0.412180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.189200</td>\n",
       "      <td>1.328397</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5088618266373612, recall=0.44651644290888426, fmeasure=0.44385452486680455), mid=Score(precision=0.5517807234528889, recall=0.4901308157434101, fmeasure=0.4833751666425047), high=Score(precision=0.5976257852076547, recall=0.5343435312710926, fmeasure=0.523608930894507))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.34957141018193405, recall=0.29629787178900063, fmeasure=0.29220584844564423), mid=Score(precision=0.3967485821980308, recall=0.3412672545081693, fmeasure=0.33625902350036085), high=Score(precision=0.44074159453699896, recall=0.3853901770256663, fmeasure=0.3781420161781403))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5026992528009703, recall=0.44139888447759085, fmeasure=0.4377063693964112), mid=Score(precision=0.5490037775745495, recall=0.4868459572721204, fmeasure=0.47999681302534347), high=Score(precision=0.592378012019854, recall=0.5310890967587925, fmeasure=0.5230004613871058))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5031944884662014, recall=0.4428704693822705, fmeasure=0.434902569823429), mid=Score(precision=0.5479594686359393, recall=0.486137567841066, fmeasure=0.4794280842040535), high=Score(precision=0.5939611983768405, recall=0.5290960359746593, fmeasure=0.5248337099382135))</td>\n",
       "      <td>9.760000</td>\n",
       "      <td>0.400506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>1.519548</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5254833466662875, recall=0.48283532330657597, fmeasure=0.46340837571214116), mid=Score(precision=0.5664184386788391, recall=0.523352619611585, fmeasure=0.5018262332046505), high=Score(precision=0.6117395533487517, recall=0.5690682326569014, fmeasure=0.5436207106865026))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.3725046243584846, recall=0.331367922522707, fmeasure=0.31715305913642794), mid=Score(precision=0.41525216082936667, recall=0.3744057424302755, fmeasure=0.3579658063873329), high=Score(precision=0.46305015042147407, recall=0.4197436481890121, fmeasure=0.3998573397373148))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5183689082793285, recall=0.47514310761295836, fmeasure=0.45617049531987997), mid=Score(precision=0.5616655425811287, recall=0.5200177918888184, fmeasure=0.49858476068782054), high=Score(precision=0.6044913301973118, recall=0.5643763410894427, fmeasure=0.5403079992622108))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5171984363114418, recall=0.4750090091855632, fmeasure=0.45617652193343095), mid=Score(precision=0.5604365063041533, recall=0.51910689730996, fmeasure=0.49746726571690597), high=Score(precision=0.6063855403709529, recall=0.5633534481596324, fmeasure=0.5414657637591985))</td>\n",
       "      <td>9.910000</td>\n",
       "      <td>0.427569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.154800</td>\n",
       "      <td>1.565721</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.519332276138894, recall=0.45540902460559063, fmeasure=0.4502936638864189), mid=Score(precision=0.5620782091682829, recall=0.4961962715169351, fmeasure=0.48915800982836033), high=Score(precision=0.6030397984623626, recall=0.5390153857839094, fmeasure=0.5299891254049073))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.36130705550576864, recall=0.3128608905249644, fmeasure=0.3058173466130353), mid=Score(precision=0.41073494030479324, recall=0.35631421276855757, fmeasure=0.3488305699302061), high=Score(precision=0.4552941680715118, recall=0.4009188004466326, fmeasure=0.3898088084887284))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5136245749858801, recall=0.44910417445990336, fmeasure=0.4429549138757769), mid=Score(precision=0.5580181999373177, recall=0.4935563805071704, fmeasure=0.48615483361957734), high=Score(precision=0.6020836025188049, recall=0.537570221695835, fmeasure=0.5294499938103411))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5139879072163539, recall=0.4497998110506827, fmeasure=0.44440701461703963), mid=Score(precision=0.5579562556520278, recall=0.4938320290285534, fmeasure=0.48572559620631783), high=Score(precision=0.6008782883323781, recall=0.5401125246774225, fmeasure=0.5300783968382127))</td>\n",
       "      <td>9.275000</td>\n",
       "      <td>0.409586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.154600</td>\n",
       "      <td>1.723782</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4968514442053046, recall=0.46285938810131344, fmeasure=0.4420541542105452), mid=Score(precision=0.5399816349908264, recall=0.5032616816103892, fmeasure=0.48141033392707183), high=Score(precision=0.5819972521198163, recall=0.5488395198740775, fmeasure=0.5218876013739285))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.3500363176804814, recall=0.31976399797246585, fmeasure=0.30298659974614295), mid=Score(precision=0.39793811723407324, recall=0.36274966725705693, fmeasure=0.34494832804371595), high=Score(precision=0.4409133671016483, recall=0.40591331602247793, fmeasure=0.38486833851649455))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4916245673954314, recall=0.45415845162899493, fmeasure=0.4363521835964432), mid=Score(precision=0.5362615304425966, recall=0.49961416298161343, fmeasure=0.47812884278816614), high=Score(precision=0.575994393586397, recall=0.5454500046310237, fmeasure=0.5194046820148732))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.49043395912196475, recall=0.45519013143860076, fmeasure=0.4354600402653439), mid=Score(precision=0.5350552124550287, recall=0.4998654780380736, fmeasure=0.4772227356674026), high=Score(precision=0.5779284809043082, recall=0.5432246771144335, fmeasure=0.5215696686775481))</td>\n",
       "      <td>10.157500</td>\n",
       "      <td>0.412929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.144900</td>\n",
       "      <td>1.815919</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5239208069555037, recall=0.46119678700042765, fmeasure=0.45469508552994176), mid=Score(precision=0.5654750210981829, recall=0.5021341387913091, fmeasure=0.49269682917650914), high=Score(precision=0.6092722973309371, recall=0.5495915682047908, fmeasure=0.5365693231343706))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.3752792118828885, recall=0.31779842078431275, fmeasure=0.31540815187901466), mid=Score(precision=0.4218647497314777, recall=0.3600825889898074, fmeasure=0.3577351379620063), high=Score(precision=0.4668649263624447, recall=0.4053166643844428, fmeasure=0.3993110794224982))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5167584991244458, recall=0.45560359368040226, fmeasure=0.4508105714819054), mid=Score(precision=0.5611446323284557, recall=0.49848285518787394, fmeasure=0.4898476306195585), high=Score(precision=0.6034493225422455, recall=0.5444270539187636, fmeasure=0.5331567193366722))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5160928357182035, recall=0.4548910078139914, fmeasure=0.44822169885103064), mid=Score(precision=0.56059775232937, recall=0.4991266189621465, fmeasure=0.4896389238881288), high=Score(precision=0.6052813502520766, recall=0.5432161583490037, fmeasure=0.5333563710779229))</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.414196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.129500</td>\n",
       "      <td>1.936873</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5215023684087564, recall=0.4542089052637769, fmeasure=0.446890666160161), mid=Score(precision=0.5653214360190462, recall=0.49329073942947477, fmeasure=0.48849329231344785), high=Score(precision=0.6094241134733321, recall=0.5367875352403714, fmeasure=0.5309304285915148))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.37150784311174956, recall=0.3132969921011673, fmeasure=0.3100422552322328), mid=Score(precision=0.4208913066100567, recall=0.35629813109785413, fmeasure=0.35456660597319145), high=Score(precision=0.4671432036713289, recall=0.40029330072561575, fmeasure=0.39366248710995666))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.51638109867563, recall=0.44662053978783867, fmeasure=0.44354385464778834), mid=Score(precision=0.5607602978108494, recall=0.4890674578604165, fmeasure=0.48505271015151596), high=Score(precision=0.6047821060628507, recall=0.5354915814077419, fmeasure=0.5280699575464369))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5148155313640609, recall=0.4474773467770893, fmeasure=0.44266964803268444), mid=Score(precision=0.5609084819388129, recall=0.4892974960301463, fmeasure=0.48595439908495014), high=Score(precision=0.605557663909824, recall=0.5337544631513031, fmeasure=0.5278007297569663))</td>\n",
       "      <td>9.390000</td>\n",
       "      <td>0.408504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.093000</td>\n",
       "      <td>2.024045</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5077650587893575, recall=0.4521055966706473, fmeasure=0.44287500393207346), mid=Score(precision=0.555058044858693, recall=0.4968598246594882, fmeasure=0.48535728157120184), high=Score(precision=0.5972896737343646, recall=0.5384108338573397, fmeasure=0.5235618777979676))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.3674102551094738, recall=0.3200204857933514, fmeasure=0.30728798201804), mid=Score(precision=0.41546018738206253, recall=0.363725273839795, fmeasure=0.352345055961262), high=Score(precision=0.4603884839986403, recall=0.4082434816369546, fmeasure=0.3953492477632247))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5059292721900672, recall=0.44944051877902025, fmeasure=0.43963588732202147), mid=Score(precision=0.5497753545957396, recall=0.49254540180952366, fmeasure=0.4810729698772206), high=Score(precision=0.5933243493864241, recall=0.5371076486306401, fmeasure=0.523755155260313))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5020359799358494, recall=0.4498956714737435, fmeasure=0.4372788881107203), mid=Score(precision=0.5499017922383346, recall=0.49201338686092944, fmeasure=0.4811699524342048), high=Score(precision=0.5959897606121412, recall=0.5381265229137174, fmeasure=0.5240576072360391))</td>\n",
       "      <td>10.192500</td>\n",
       "      <td>0.411985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.112900</td>\n",
       "      <td>2.125327</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.486686824745924, recall=0.45191249142676204, fmeasure=0.43440277286492385), mid=Score(precision=0.531182852482485, recall=0.4927761646641642, fmeasure=0.4734242818966785), high=Score(precision=0.5737997853402724, recall=0.5334450487684109, fmeasure=0.5136498015379044))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.3472453576448062, recall=0.3142886117059245, fmeasure=0.29659333799759924), mid=Score(precision=0.39400716124153623, recall=0.3570534359466754, fmeasure=0.34042026127062724), high=Score(precision=0.438583895444833, recall=0.39983418031890916, fmeasure=0.37899867759797445))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4822570556792064, recall=0.44144150639878393, fmeasure=0.42662605396800424), mid=Score(precision=0.5258442164453194, recall=0.4876143818429054, fmeasure=0.4695626388543048), high=Score(precision=0.5694627852539618, recall=0.5327939346574238, fmeasure=0.5119401930105479))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4783401996594093, recall=0.4442796685644574, fmeasure=0.4297276439882073), mid=Score(precision=0.5261760182219742, recall=0.489034533028618, fmeasure=0.46964189370222403), high=Score(precision=0.5699735227344144, recall=0.5326285249233337, fmeasure=0.5127037395338363))</td>\n",
       "      <td>10.457500</td>\n",
       "      <td>0.405261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.122900</td>\n",
       "      <td>2.241618</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5035219762569948, recall=0.45640224408325025, fmeasure=0.4392359238819198), mid=Score(precision=0.5460710549662755, recall=0.49526564270791623, fmeasure=0.4788726079762551), high=Score(precision=0.5894722611385754, recall=0.5369493018018354, fmeasure=0.5183326704547319))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.35795586144860053, recall=0.31423642088393844, fmeasure=0.30005034842987066), mid=Score(precision=0.40679402572509193, recall=0.3573321114327889, fmeasure=0.34444199066064474), high=Score(precision=0.4512062551011082, recall=0.39982955000071396, fmeasure=0.38509452964095137))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4949235728119922, recall=0.4453972183515878, fmeasure=0.4313637784907534), mid=Score(precision=0.540718921091164, recall=0.4908092360564654, fmeasure=0.4747786163841954), high=Score(precision=0.5854782956116595, recall=0.5363868937676515, fmeasure=0.5168021571733423))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.49568868170738595, recall=0.44751118196648004, fmeasure=0.4328225465504499), mid=Score(precision=0.5411180594323979, recall=0.49059642892182687, fmeasure=0.47456533529130374), high=Score(precision=0.5858807735565088, recall=0.5358177727204837, fmeasure=0.5175478473337166))</td>\n",
       "      <td>10.142500</td>\n",
       "      <td>0.404711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.116100</td>\n",
       "      <td>2.315884</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4925792550586671, recall=0.4446008379838566, fmeasure=0.4333057003514691), mid=Score(precision=0.537971465829922, recall=0.48696464083721724, fmeasure=0.47488630926256864), high=Score(precision=0.5788946617669505, recall=0.5278171102539789, fmeasure=0.515794590773799))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.34964965626183464, recall=0.3054911295318235, fmeasure=0.296509989744889), mid=Score(precision=0.3994834404770066, recall=0.3506555269611866, fmeasure=0.34094113583137087), high=Score(precision=0.44074829585243175, recall=0.39039644470773166, fmeasure=0.3782401137512875))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4870389971650082, recall=0.4379029689386181, fmeasure=0.428743324285709), mid=Score(precision=0.5320718428834239, recall=0.4820805709741244, fmeasure=0.4708259393410138), high=Score(precision=0.5763755691510287, recall=0.5272012633853557, fmeasure=0.5135341695294894))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.48635610775560223, recall=0.4403412540554721, fmeasure=0.43021998995474264), mid=Score(precision=0.5323182322171294, recall=0.48200503371440884, fmeasure=0.47017516710859), high=Score(precision=0.5803930461644158, recall=0.5279884439666805, fmeasure=0.5143202280146179))</td>\n",
       "      <td>10.397500</td>\n",
       "      <td>0.399447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.096500</td>\n",
       "      <td>2.316361</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5096513011581534, recall=0.4506800913596715, fmeasure=0.4409529759876206), mid=Score(precision=0.5524859285343999, recall=0.49028584741513564, fmeasure=0.4803721613075702), high=Score(precision=0.5954471885661854, recall=0.5298993581058163, fmeasure=0.5177436367839529))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.3546781425172051, recall=0.303506900460024, fmeasure=0.2950338867746057), mid=Score(precision=0.4049479288073039, recall=0.3475070861392263, fmeasure=0.3418187006584402), high=Score(precision=0.44790893334096454, recall=0.3911674975664491, fmeasure=0.382344586604369))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5018351557116987, recall=0.4415104822504437, fmeasure=0.43291421889171755), mid=Score(precision=0.5461693974294111, recall=0.4851748896494311, fmeasure=0.475654583642793), high=Score(precision=0.5921684680435022, recall=0.5287225522603369, fmeasure=0.5178521235409711))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5001525012365085, recall=0.43926935788627636, fmeasure=0.43254627191309813), mid=Score(precision=0.5476036831299504, recall=0.4853362946908566, fmeasure=0.47631664357569903), high=Score(precision=0.5929252480617827, recall=0.5310118323438294, fmeasure=0.5206673394408562))</td>\n",
       "      <td>9.977500</td>\n",
       "      <td>0.398935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.092000</td>\n",
       "      <td>2.411178</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5019342431822671, recall=0.4418586292765876, fmeasure=0.43276937526277043), mid=Score(precision=0.5454002069213468, recall=0.4836050234196686, fmeasure=0.4753739438401116), high=Score(precision=0.5904634914768648, recall=0.5254126123480753, fmeasure=0.5157728742616418))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.3545222883019758, recall=0.3051469023998484, fmeasure=0.2983132735255827), mid=Score(precision=0.4048096885753136, recall=0.34932049330573745, fmeasure=0.34373813039205997), high=Score(precision=0.4483669618575869, recall=0.3925911940430847, fmeasure=0.3831050974840791))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4972849670345991, recall=0.4362293225618122, fmeasure=0.42974717718932787), mid=Score(precision=0.5413214349988248, recall=0.47940117194051957, fmeasure=0.47146354653066075), high=Score(precision=0.5861233146908242, recall=0.5256404339060297, fmeasure=0.5158667813545508))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4942697365287897, recall=0.43757575956915074, fmeasure=0.42906574560142985), mid=Score(precision=0.5414489866750898, recall=0.4800819326611794, fmeasure=0.4711929169841734), high=Score(precision=0.5875408650224367, recall=0.5267104780623668, fmeasure=0.5160077897340741))</td>\n",
       "      <td>9.595000</td>\n",
       "      <td>0.397263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>2.390162</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5078992430293952, recall=0.44679207152638206, fmeasure=0.4367983891806217), mid=Score(precision=0.5512131379918239, recall=0.48683480804167956, fmeasure=0.47894154787798704), high=Score(precision=0.5964515004063597, recall=0.5274062160201234, fmeasure=0.518249091024026))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.3630570536234598, recall=0.30703918426258436, fmeasure=0.30183864183534), mid=Score(precision=0.4125992420569625, recall=0.35215245241085646, fmeasure=0.34697761059527454), high=Score(precision=0.4558213674346486, recall=0.3954878323345921, fmeasure=0.3887577783552697))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5020536329146431, recall=0.4372262394573521, fmeasure=0.4320860345722755), mid=Score(precision=0.5464053636314665, recall=0.481777927969017, fmeasure=0.47488694219327865), high=Score(precision=0.5912159805214564, recall=0.5268732303113832, fmeasure=0.5184406563165931))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.49916447785745377, recall=0.4396220897548678, fmeasure=0.4311469356353175), mid=Score(precision=0.5470296274825106, recall=0.4827081395230465, fmeasure=0.4752727160290486), high=Score(precision=0.5908039780787024, recall=0.5272154423236273, fmeasure=0.5185958887659661))</td>\n",
       "      <td>9.835000</td>\n",
       "      <td>0.400680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.094700</td>\n",
       "      <td>2.451745</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.502506236681007, recall=0.45060439178904726, fmeasure=0.43547645565521786), mid=Score(precision=0.5454424019607844, recall=0.4907755762334418, fmeasure=0.47657621317979193), high=Score(precision=0.5868481127736646, recall=0.5319950938272876, fmeasure=0.5166419209164365))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.3608754985567945, recall=0.30972551169882206, fmeasure=0.30357958236045013), mid=Score(precision=0.409827308006536, recall=0.3556708340106427, fmeasure=0.3485490290439031), high=Score(precision=0.4532628324596156, recall=0.39878231729050173, fmeasure=0.3901584882437119))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4960528912519263, recall=0.4439065471179646, fmeasure=0.42987299261948847), mid=Score(precision=0.5406718485762605, recall=0.4858423682236215, fmeasure=0.47269356446324845), high=Score(precision=0.5859835328172643, recall=0.5299284330574959, fmeasure=0.5164918134211643))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.49408676088005155, recall=0.4429590775069074, fmeasure=0.42923122521443324), mid=Score(precision=0.5411597428306987, recall=0.4867416149033823, fmeasure=0.47320261768006655), high=Score(precision=0.5872740062072326, recall=0.5332425653405093, fmeasure=0.51814711653653))</td>\n",
       "      <td>10.160000</td>\n",
       "      <td>0.402985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.082500</td>\n",
       "      <td>2.512465</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5015161094849853, recall=0.4489401713410114, fmeasure=0.4386340046429024), mid=Score(precision=0.5456955923602113, recall=0.4902005089898098, fmeasure=0.47875072167339705), high=Score(precision=0.5868989316148033, recall=0.5284563406339949, fmeasure=0.5147975419607171))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.35755235259532137, recall=0.3077019300075788, fmeasure=0.3012498381469187), mid=Score(precision=0.40573751075313585, recall=0.3532062224427511, fmeasure=0.34659994906067826), high=Score(precision=0.4498823067557443, recall=0.39739536410718235, fmeasure=0.38748701349771286))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4964331117358305, recall=0.44092974493581066, fmeasure=0.43089492778499205), mid=Score(precision=0.5392619257194042, recall=0.4843490327668669, fmeasure=0.4741904093251174), high=Score(precision=0.5835599590612991, recall=0.5314072350253668, fmeasure=0.5176455621171648))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.49219532679572103, recall=0.4412591359433724, fmeasure=0.4310377527711343), mid=Score(precision=0.5399807502976042, recall=0.484948588473194, fmeasure=0.474271744440947), high=Score(precision=0.5839103270933572, recall=0.530860316555562, fmeasure=0.5187091038611463))</td>\n",
       "      <td>10.287500</td>\n",
       "      <td>0.402388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.085600</td>\n",
       "      <td>2.538798</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5034339623203593, recall=0.4509600891952754, fmeasure=0.4400175048903605), mid=Score(precision=0.5444059673986146, recall=0.4898741678951163, fmeasure=0.48012214160882216), high=Score(precision=0.5854137868820314, recall=0.5296417630699165, fmeasure=0.5191390353724822))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.3593196562628548, recall=0.31082609154710705, fmeasure=0.3050614912127828), mid=Score(precision=0.40783518146477704, recall=0.3557175728192573, fmeasure=0.3493573342486714), high=Score(precision=0.4532473410219275, recall=0.40112333836919645, fmeasure=0.39103627229146287))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4941420922572118, recall=0.44207549812646435, fmeasure=0.43273823474809403), mid=Score(precision=0.5387153369506312, recall=0.4855798993298531, fmeasure=0.4758327430183029), high=Score(precision=0.5831066216922376, recall=0.5303754685328498, fmeasure=0.5195357620353819))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4935114282980093, recall=0.4431707675360697, fmeasure=0.43226346418832146), mid=Score(precision=0.5390839979056892, recall=0.48571495141053944, fmeasure=0.47606269819147484), high=Score(precision=0.5822764235968276, recall=0.5311724132023866, fmeasure=0.5190552678693404))</td>\n",
       "      <td>10.247500</td>\n",
       "      <td>0.403841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.101400</td>\n",
       "      <td>2.542148</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5035903403001797, recall=0.44853405874805813, fmeasure=0.4375391501491598), mid=Score(precision=0.5447530492812998, recall=0.4885973823249623, fmeasure=0.478151839046302), high=Score(precision=0.5855656326323316, recall=0.5275456535325644, fmeasure=0.5164082052543307))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.35600196366133874, recall=0.3091656356229152, fmeasure=0.3016756933864776), mid=Score(precision=0.40431497873042, recall=0.3536627545552657, fmeasure=0.3461607808004148), high=Score(precision=0.44889438413914523, recall=0.39865039205629993, fmeasure=0.3884882261364476))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.49391328279536717, recall=0.4397880574800801, fmeasure=0.4307565163053942), mid=Score(precision=0.5387199186531134, recall=0.48383120979651095, fmeasure=0.4740157974171927), high=Score(precision=0.5833373419494161, recall=0.5290137309188044, fmeasure=0.5176097108733968))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4930194440003798, recall=0.4412354654472746, fmeasure=0.43009867971675275), mid=Score(precision=0.5392452538753816, recall=0.4839011537640895, fmeasure=0.4737889516131716), high=Score(precision=0.5836071304174194, recall=0.5297718896014149, fmeasure=0.5178303721856421))</td>\n",
       "      <td>10.185000</td>\n",
       "      <td>0.401847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.087300</td>\n",
       "      <td>2.558767</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.5039998595318619, recall=0.4470012867272692, fmeasure=0.43518582862242594), mid=Score(precision=0.545030608323565, recall=0.4866960341968658, fmeasure=0.47723612924355385), high=Score(precision=0.5879438767209207, recall=0.5267762009345779, fmeasure=0.5149597143633609))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.35923758131166234, recall=0.3073431449877997, fmeasure=0.299858956824884), mid=Score(precision=0.4066846396046764, recall=0.3518857134680488, fmeasure=0.34502159714612096), high=Score(precision=0.45039526392724943, recall=0.397349592130319, fmeasure=0.3869058430532109))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.49359087634179544, recall=0.43780906168283645, fmeasure=0.42933452401824257), mid=Score(precision=0.539688953762096, recall=0.4820351919313641, fmeasure=0.47275309311845815), high=Score(precision=0.5833544202220745, recall=0.5263109189477608, fmeasure=0.5172162468991726))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4936958316343959, recall=0.43815424794573055, fmeasure=0.42896330737180205), mid=Score(precision=0.539964599120994, recall=0.48256690833498367, fmeasure=0.47300239727015275), high=Score(precision=0.584055468135182, recall=0.5278016701055552, fmeasure=0.5164129306639902))</td>\n",
       "      <td>10.130000</td>\n",
       "      <td>0.400162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.50374467516246, recall=0.3950312421041104, fmeasure=0.4009300615671617), mid=Score(precision=0.5508269325649844, recall=0.4377431468047417, fmeasure=0.4437955403157695), high=Score(precision=0.5924131508656787, recall=0.4814349023947423, fmeasure=0.48569636357309853))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.32415513882563507, recall=0.24116713583581448, fmeasure=0.24807727303755503), mid=Score(precision=0.37230533110680164, recall=0.284048367036263, fmeasure=0.2917552116519039), high=Score(precision=0.41967156942322376, recall=0.3283530998381211, fmeasure=0.33637622054894095))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5002665993218384, recall=0.3908571259708004, fmeasure=0.39738353385688796), mid=Score(precision=0.5447898147604031, recall=0.43653778143686955, fmeasure=0.4417086861348908), high=Score(precision=0.5867395539713557, recall=0.4752899007117366, fmeasure=0.4805056434631726))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5030752680683289, recall=0.3933248535347709, fmeasure=0.40005799078094334), mid=Score(precision=0.5446403479078116, recall=0.43432685693357936, fmeasure=0.44093277493439226), high=Score(precision=0.5903517606015308, recall=0.47887897416149655, fmeasure=0.48380662321544093))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.527739741610514, recall=0.4370059980983654, fmeasure=0.4358954757256339), mid=Score(precision=0.5714736264552442, recall=0.4778611400925878, fmeasure=0.4768513234544952), high=Score(precision=0.6146321538245254, recall=0.5195119122954068, fmeasure=0.5177724887891918))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.3543141609768907, recall=0.28395698320495183, fmeasure=0.2851579799782941), mid=Score(precision=0.40616802345938374, recall=0.3275382621819256, fmeasure=0.3283892502617305), high=Score(precision=0.44978674108265104, recall=0.3698936635307192, fmeasure=0.36869021067127855))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5185538893143213, recall=0.4258741552636579, fmeasure=0.4270935995543483), mid=Score(precision=0.5653810165528919, recall=0.4746477038655662, fmeasure=0.4734905364837827), high=Score(precision=0.6095405537171162, recall=0.5147671669739285, fmeasure=0.5153524643838899))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.520625008814715, recall=0.4304497631912279, fmeasure=0.43007567480851583), mid=Score(precision=0.5646860274121306, recall=0.47321055104758847, fmeasure=0.4724515723061629), high=Score(precision=0.6120335296647796, recall=0.5185080231578897, fmeasure=0.5178683569804874))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5331904431863072, recall=0.45087585738649055, fmeasure=0.45075347532399707), mid=Score(precision=0.5763436989889197, recall=0.4945579037620764, fmeasure=0.49023178450295496), high=Score(precision=0.6174235605999394, recall=0.5365393927766676, fmeasure=0.5297563986141037))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.36719628309292823, recall=0.30587960609493176, fmeasure=0.301557969220732), mid=Score(precision=0.4169130579387933, recall=0.35045207108716137, fmeasure=0.3457120067846823), high=Score(precision=0.4598829581774435, recall=0.3910793078305143, fmeasure=0.384376074059876))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5267565052645476, recall=0.44491138252544865, fmeasure=0.4415243212615851), mid=Score(precision=0.5727273643431731, recall=0.4922134864432244, fmeasure=0.4880874401221894), high=Score(precision=0.6149689428422885, recall=0.532122136034154, fmeasure=0.5287386929330931))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5285157490130379, recall=0.4517453973610428, fmeasure=0.4468037832252721), mid=Score(precision=0.5719504160055633, recall=0.49089313461939194, fmeasure=0.48674249271064685), high=Score(precision=0.6156832945700133, recall=0.534725525577376, fmeasure=0.5289380355243442))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5412672658377163, recall=0.45513236507115323, fmeasure=0.4551835090858312), mid=Score(precision=0.5845412139943393, recall=0.49750124518721084, fmeasure=0.49446764261490556), high=Score(precision=0.6284674846803522, recall=0.540132108532697, fmeasure=0.5342480706395474))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.37346645680708185, recall=0.3047298385765066, fmeasure=0.30192393741350876), mid=Score(precision=0.42243776709401715, recall=0.3516826915753868, fmeasure=0.34878833425631783), high=Score(precision=0.46618386370573867, recall=0.3931275748566205, fmeasure=0.38816951133760863))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5348380660495552, recall=0.44730878128269425, fmeasure=0.4478069210386667), mid=Score(precision=0.5807231321578747, recall=0.49494168454390297, fmeasure=0.49223792047468123), high=Score(precision=0.6231185674262426, recall=0.5377793624840058, fmeasure=0.5325724675878535))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5376278306966727, recall=0.45214098918964046, fmeasure=0.4484315458777804), mid=Score(precision=0.5799661852648986, recall=0.4952037767825636, fmeasure=0.4924341795467362), high=Score(precision=0.6247090061898884, recall=0.5393116764093813, fmeasure=0.5355486715926939))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5175428294438408, recall=0.47447747145152425, fmeasure=0.45247994763655425), mid=Score(precision=0.5608362840182693, recall=0.5141582836336074, fmeasure=0.4947662046914818), high=Score(precision=0.6062349094583929, recall=0.5560253963267795, fmeasure=0.5353633280988147))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.3634709534848322, recall=0.3252322184343023, fmeasure=0.3107764772012784), mid=Score(precision=0.4106462962078772, recall=0.36772324037334886, fmeasure=0.35335459777754186), high=Score(precision=0.45479845344096287, recall=0.4106300748319435, fmeasure=0.3936347113975262))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5134401626202637, recall=0.46953668534920584, fmeasure=0.4484198269290288), mid=Score(precision=0.5577387804189275, recall=0.5112382236359349, fmeasure=0.49101449069668474), high=Score(precision=0.5996922877928851, recall=0.5570728278066365, fmeasure=0.5319522092190736))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5156355908848099, recall=0.4690588245617645, fmeasure=0.45011844068346246), mid=Score(precision=0.5566344452116511, recall=0.5115673244284322, fmeasure=0.49120991366107225), high=Score(precision=0.6014447967269659, recall=0.5544559703639872, fmeasure=0.5330012257331932))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5074463694954964, recall=0.46043762306410846, fmeasure=0.44109114118238485), mid=Score(precision=0.5486745771589521, recall=0.500025356707609, fmeasure=0.4808419807094889), high=Score(precision=0.5910796891272535, recall=0.5456416664037573, fmeasure=0.5217880315305629))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.34900603965070875, recall=0.31227670307354144, fmeasure=0.2980681799358823), mid=Score(precision=0.395378158095989, recall=0.3572343275681604, fmeasure=0.3412818654393265), high=Score(precision=0.4391090922965925, recall=0.4021170262677988, fmeasure=0.3822572048115607))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.49675160395160395, recall=0.45484595640212305, fmeasure=0.43814107846145894), mid=Score(precision=0.5438883900005225, recall=0.4973385692415147, fmeasure=0.4780715966275405), high=Score(precision=0.5872730261517488, recall=0.5411721439965795, fmeasure=0.5182359144438378))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5021420538203628, recall=0.4537165716052205, fmeasure=0.4368605729461429), mid=Score(precision=0.5445191572112527, recall=0.49757210153385667, fmeasure=0.47794721442314614), high=Score(precision=0.5875651611103356, recall=0.5405231495355977, fmeasure=0.5213669751271853))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5279019236329441, recall=0.4582564774034394, fmeasure=0.45077771364175206), mid=Score(precision=0.5672132612077465, recall=0.4975824986703318, fmeasure=0.48872959087434403), high=Score(precision=0.6124884771274478, recall=0.5421491029626436, fmeasure=0.5310636618202511))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.3684177153320537, recall=0.3194334517429859, fmeasure=0.3115894612592788), mid=Score(precision=0.4171563069283658, recall=0.3622446279463513, fmeasure=0.3552827610449666), high=Score(precision=0.4595523779172219, recall=0.405226968105026, fmeasure=0.3940583010565006))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5215926107695408, recall=0.4538265872469879, fmeasure=0.4466740623101706), mid=Score(precision=0.5657799414637651, recall=0.4972812741573638, fmeasure=0.48821242886618066), high=Score(precision=0.6083522260419322, recall=0.540542730053347, fmeasure=0.5306833399457865))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5201086107009821, recall=0.45542371511518526, fmeasure=0.446361724826062), mid=Score(precision=0.5653100323899958, recall=0.49707557573735406, fmeasure=0.48801635200403704), high=Score(precision=0.6114752105482345, recall=0.5427945296049967, fmeasure=0.5326318287072702))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5088618266373612, recall=0.44651644290888426, fmeasure=0.44385452486680455), mid=Score(precision=0.5517807234528889, recall=0.4901308157434101, fmeasure=0.4833751666425047), high=Score(precision=0.5976257852076547, recall=0.5343435312710926, fmeasure=0.523608930894507))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.34957141018193405, recall=0.29629787178900063, fmeasure=0.29220584844564423), mid=Score(precision=0.3967485821980308, recall=0.3412672545081693, fmeasure=0.33625902350036085), high=Score(precision=0.44074159453699896, recall=0.3853901770256663, fmeasure=0.3781420161781403))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5026992528009703, recall=0.44139888447759085, fmeasure=0.4377063693964112), mid=Score(precision=0.5490037775745495, recall=0.4868459572721204, fmeasure=0.47999681302534347), high=Score(precision=0.592378012019854, recall=0.5310890967587925, fmeasure=0.5230004613871058))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5031944884662014, recall=0.4428704693822705, fmeasure=0.434902569823429), mid=Score(precision=0.5479594686359393, recall=0.486137567841066, fmeasure=0.4794280842040535), high=Score(precision=0.5939611983768405, recall=0.5290960359746593, fmeasure=0.5248337099382135))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5254833466662875, recall=0.48283532330657597, fmeasure=0.46340837571214116), mid=Score(precision=0.5664184386788391, recall=0.523352619611585, fmeasure=0.5018262332046505), high=Score(precision=0.6117395533487517, recall=0.5690682326569014, fmeasure=0.5436207106865026))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.3725046243584846, recall=0.331367922522707, fmeasure=0.31715305913642794), mid=Score(precision=0.41525216082936667, recall=0.3744057424302755, fmeasure=0.3579658063873329), high=Score(precision=0.46305015042147407, recall=0.4197436481890121, fmeasure=0.3998573397373148))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5183689082793285, recall=0.47514310761295836, fmeasure=0.45617049531987997), mid=Score(precision=0.5616655425811287, recall=0.5200177918888184, fmeasure=0.49858476068782054), high=Score(precision=0.6044913301973118, recall=0.5643763410894427, fmeasure=0.5403079992622108))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5171984363114418, recall=0.4750090091855632, fmeasure=0.45617652193343095), mid=Score(precision=0.5604365063041533, recall=0.51910689730996, fmeasure=0.49746726571690597), high=Score(precision=0.6063855403709529, recall=0.5633534481596324, fmeasure=0.5414657637591985))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.519332276138894, recall=0.45540902460559063, fmeasure=0.4502936638864189), mid=Score(precision=0.5620782091682829, recall=0.4961962715169351, fmeasure=0.48915800982836033), high=Score(precision=0.6030397984623626, recall=0.5390153857839094, fmeasure=0.5299891254049073))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.36130705550576864, recall=0.3128608905249644, fmeasure=0.3058173466130353), mid=Score(precision=0.41073494030479324, recall=0.35631421276855757, fmeasure=0.3488305699302061), high=Score(precision=0.4552941680715118, recall=0.4009188004466326, fmeasure=0.3898088084887284))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5136245749858801, recall=0.44910417445990336, fmeasure=0.4429549138757769), mid=Score(precision=0.5580181999373177, recall=0.4935563805071704, fmeasure=0.48615483361957734), high=Score(precision=0.6020836025188049, recall=0.537570221695835, fmeasure=0.5294499938103411))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5139879072163539, recall=0.4497998110506827, fmeasure=0.44440701461703963), mid=Score(precision=0.5579562556520278, recall=0.4938320290285534, fmeasure=0.48572559620631783), high=Score(precision=0.6008782883323781, recall=0.5401125246774225, fmeasure=0.5300783968382127))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4968514442053046, recall=0.46285938810131344, fmeasure=0.4420541542105452), mid=Score(precision=0.5399816349908264, recall=0.5032616816103892, fmeasure=0.48141033392707183), high=Score(precision=0.5819972521198163, recall=0.5488395198740775, fmeasure=0.5218876013739285))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.3500363176804814, recall=0.31976399797246585, fmeasure=0.30298659974614295), mid=Score(precision=0.39793811723407324, recall=0.36274966725705693, fmeasure=0.34494832804371595), high=Score(precision=0.4409133671016483, recall=0.40591331602247793, fmeasure=0.38486833851649455))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4916245673954314, recall=0.45415845162899493, fmeasure=0.4363521835964432), mid=Score(precision=0.5362615304425966, recall=0.49961416298161343, fmeasure=0.47812884278816614), high=Score(precision=0.575994393586397, recall=0.5454500046310237, fmeasure=0.5194046820148732))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.49043395912196475, recall=0.45519013143860076, fmeasure=0.4354600402653439), mid=Score(precision=0.5350552124550287, recall=0.4998654780380736, fmeasure=0.4772227356674026), high=Score(precision=0.5779284809043082, recall=0.5432246771144335, fmeasure=0.5215696686775481))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5239208069555037, recall=0.46119678700042765, fmeasure=0.45469508552994176), mid=Score(precision=0.5654750210981829, recall=0.5021341387913091, fmeasure=0.49269682917650914), high=Score(precision=0.6092722973309371, recall=0.5495915682047908, fmeasure=0.5365693231343706))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.3752792118828885, recall=0.31779842078431275, fmeasure=0.31540815187901466), mid=Score(precision=0.4218647497314777, recall=0.3600825889898074, fmeasure=0.3577351379620063), high=Score(precision=0.4668649263624447, recall=0.4053166643844428, fmeasure=0.3993110794224982))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5167584991244458, recall=0.45560359368040226, fmeasure=0.4508105714819054), mid=Score(precision=0.5611446323284557, recall=0.49848285518787394, fmeasure=0.4898476306195585), high=Score(precision=0.6034493225422455, recall=0.5444270539187636, fmeasure=0.5331567193366722))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5160928357182035, recall=0.4548910078139914, fmeasure=0.44822169885103064), mid=Score(precision=0.56059775232937, recall=0.4991266189621465, fmeasure=0.4896389238881288), high=Score(precision=0.6052813502520766, recall=0.5432161583490037, fmeasure=0.5333563710779229))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5215023684087564, recall=0.4542089052637769, fmeasure=0.446890666160161), mid=Score(precision=0.5653214360190462, recall=0.49329073942947477, fmeasure=0.48849329231344785), high=Score(precision=0.6094241134733321, recall=0.5367875352403714, fmeasure=0.5309304285915148))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.37150784311174956, recall=0.3132969921011673, fmeasure=0.3100422552322328), mid=Score(precision=0.4208913066100567, recall=0.35629813109785413, fmeasure=0.35456660597319145), high=Score(precision=0.4671432036713289, recall=0.40029330072561575, fmeasure=0.39366248710995666))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.51638109867563, recall=0.44662053978783867, fmeasure=0.44354385464778834), mid=Score(precision=0.5607602978108494, recall=0.4890674578604165, fmeasure=0.48505271015151596), high=Score(precision=0.6047821060628507, recall=0.5354915814077419, fmeasure=0.5280699575464369))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5148155313640609, recall=0.4474773467770893, fmeasure=0.44266964803268444), mid=Score(precision=0.5609084819388129, recall=0.4892974960301463, fmeasure=0.48595439908495014), high=Score(precision=0.605557663909824, recall=0.5337544631513031, fmeasure=0.5278007297569663))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5077650587893575, recall=0.4521055966706473, fmeasure=0.44287500393207346), mid=Score(precision=0.555058044858693, recall=0.4968598246594882, fmeasure=0.48535728157120184), high=Score(precision=0.5972896737343646, recall=0.5384108338573397, fmeasure=0.5235618777979676))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.3674102551094738, recall=0.3200204857933514, fmeasure=0.30728798201804), mid=Score(precision=0.41546018738206253, recall=0.363725273839795, fmeasure=0.352345055961262), high=Score(precision=0.4603884839986403, recall=0.4082434816369546, fmeasure=0.3953492477632247))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5059292721900672, recall=0.44944051877902025, fmeasure=0.43963588732202147), mid=Score(precision=0.5497753545957396, recall=0.49254540180952366, fmeasure=0.4810729698772206), high=Score(precision=0.5933243493864241, recall=0.5371076486306401, fmeasure=0.523755155260313))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5020359799358494, recall=0.4498956714737435, fmeasure=0.4372788881107203), mid=Score(precision=0.5499017922383346, recall=0.49201338686092944, fmeasure=0.4811699524342048), high=Score(precision=0.5959897606121412, recall=0.5381265229137174, fmeasure=0.5240576072360391))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.486686824745924, recall=0.45191249142676204, fmeasure=0.43440277286492385), mid=Score(precision=0.531182852482485, recall=0.4927761646641642, fmeasure=0.4734242818966785), high=Score(precision=0.5737997853402724, recall=0.5334450487684109, fmeasure=0.5136498015379044))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.3472453576448062, recall=0.3142886117059245, fmeasure=0.29659333799759924), mid=Score(precision=0.39400716124153623, recall=0.3570534359466754, fmeasure=0.34042026127062724), high=Score(precision=0.438583895444833, recall=0.39983418031890916, fmeasure=0.37899867759797445))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4822570556792064, recall=0.44144150639878393, fmeasure=0.42662605396800424), mid=Score(precision=0.5258442164453194, recall=0.4876143818429054, fmeasure=0.4695626388543048), high=Score(precision=0.5694627852539618, recall=0.5327939346574238, fmeasure=0.5119401930105479))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4783401996594093, recall=0.4442796685644574, fmeasure=0.4297276439882073), mid=Score(precision=0.5261760182219742, recall=0.489034533028618, fmeasure=0.46964189370222403), high=Score(precision=0.5699735227344144, recall=0.5326285249233337, fmeasure=0.5127037395338363))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5035219762569948, recall=0.45640224408325025, fmeasure=0.4392359238819198), mid=Score(precision=0.5460710549662755, recall=0.49526564270791623, fmeasure=0.4788726079762551), high=Score(precision=0.5894722611385754, recall=0.5369493018018354, fmeasure=0.5183326704547319))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.35795586144860053, recall=0.31423642088393844, fmeasure=0.30005034842987066), mid=Score(precision=0.40679402572509193, recall=0.3573321114327889, fmeasure=0.34444199066064474), high=Score(precision=0.4512062551011082, recall=0.39982955000071396, fmeasure=0.38509452964095137))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4949235728119922, recall=0.4453972183515878, fmeasure=0.4313637784907534), mid=Score(precision=0.540718921091164, recall=0.4908092360564654, fmeasure=0.4747786163841954), high=Score(precision=0.5854782956116595, recall=0.5363868937676515, fmeasure=0.5168021571733423))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.49568868170738595, recall=0.44751118196648004, fmeasure=0.4328225465504499), mid=Score(precision=0.5411180594323979, recall=0.49059642892182687, fmeasure=0.47456533529130374), high=Score(precision=0.5858807735565088, recall=0.5358177727204837, fmeasure=0.5175478473337166))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4925792550586671, recall=0.4446008379838566, fmeasure=0.4333057003514691), mid=Score(precision=0.537971465829922, recall=0.48696464083721724, fmeasure=0.47488630926256864), high=Score(precision=0.5788946617669505, recall=0.5278171102539789, fmeasure=0.515794590773799))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.34964965626183464, recall=0.3054911295318235, fmeasure=0.296509989744889), mid=Score(precision=0.3994834404770066, recall=0.3506555269611866, fmeasure=0.34094113583137087), high=Score(precision=0.44074829585243175, recall=0.39039644470773166, fmeasure=0.3782401137512875))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4870389971650082, recall=0.4379029689386181, fmeasure=0.428743324285709), mid=Score(precision=0.5320718428834239, recall=0.4820805709741244, fmeasure=0.4708259393410138), high=Score(precision=0.5763755691510287, recall=0.5272012633853557, fmeasure=0.5135341695294894))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.48635610775560223, recall=0.4403412540554721, fmeasure=0.43021998995474264), mid=Score(precision=0.5323182322171294, recall=0.48200503371440884, fmeasure=0.47017516710859), high=Score(precision=0.5803930461644158, recall=0.5279884439666805, fmeasure=0.5143202280146179))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5096513011581534, recall=0.4506800913596715, fmeasure=0.4409529759876206), mid=Score(precision=0.5524859285343999, recall=0.49028584741513564, fmeasure=0.4803721613075702), high=Score(precision=0.5954471885661854, recall=0.5298993581058163, fmeasure=0.5177436367839529))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.3546781425172051, recall=0.303506900460024, fmeasure=0.2950338867746057), mid=Score(precision=0.4049479288073039, recall=0.3475070861392263, fmeasure=0.3418187006584402), high=Score(precision=0.44790893334096454, recall=0.3911674975664491, fmeasure=0.382344586604369))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5018351557116987, recall=0.4415104822504437, fmeasure=0.43291421889171755), mid=Score(precision=0.5461693974294111, recall=0.4851748896494311, fmeasure=0.475654583642793), high=Score(precision=0.5921684680435022, recall=0.5287225522603369, fmeasure=0.5178521235409711))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5001525012365085, recall=0.43926935788627636, fmeasure=0.43254627191309813), mid=Score(precision=0.5476036831299504, recall=0.4853362946908566, fmeasure=0.47631664357569903), high=Score(precision=0.5929252480617827, recall=0.5310118323438294, fmeasure=0.5206673394408562))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5019342431822671, recall=0.4418586292765876, fmeasure=0.43276937526277043), mid=Score(precision=0.5454002069213468, recall=0.4836050234196686, fmeasure=0.4753739438401116), high=Score(precision=0.5904634914768648, recall=0.5254126123480753, fmeasure=0.5157728742616418))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.3545222883019758, recall=0.3051469023998484, fmeasure=0.2983132735255827), mid=Score(precision=0.4048096885753136, recall=0.34932049330573745, fmeasure=0.34373813039205997), high=Score(precision=0.4483669618575869, recall=0.3925911940430847, fmeasure=0.3831050974840791))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4972849670345991, recall=0.4362293225618122, fmeasure=0.42974717718932787), mid=Score(precision=0.5413214349988248, recall=0.47940117194051957, fmeasure=0.47146354653066075), high=Score(precision=0.5861233146908242, recall=0.5256404339060297, fmeasure=0.5158667813545508))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4942697365287897, recall=0.43757575956915074, fmeasure=0.42906574560142985), mid=Score(precision=0.5414489866750898, recall=0.4800819326611794, fmeasure=0.4711929169841734), high=Score(precision=0.5875408650224367, recall=0.5267104780623668, fmeasure=0.5160077897340741))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5078992430293952, recall=0.44679207152638206, fmeasure=0.4367983891806217), mid=Score(precision=0.5512131379918239, recall=0.48683480804167956, fmeasure=0.47894154787798704), high=Score(precision=0.5964515004063597, recall=0.5274062160201234, fmeasure=0.518249091024026))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.3630570536234598, recall=0.30703918426258436, fmeasure=0.30183864183534), mid=Score(precision=0.4125992420569625, recall=0.35215245241085646, fmeasure=0.34697761059527454), high=Score(precision=0.4558213674346486, recall=0.3954878323345921, fmeasure=0.3887577783552697))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5020536329146431, recall=0.4372262394573521, fmeasure=0.4320860345722755), mid=Score(precision=0.5464053636314665, recall=0.481777927969017, fmeasure=0.47488694219327865), high=Score(precision=0.5912159805214564, recall=0.5268732303113832, fmeasure=0.5184406563165931))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.49916447785745377, recall=0.4396220897548678, fmeasure=0.4311469356353175), mid=Score(precision=0.5470296274825106, recall=0.4827081395230465, fmeasure=0.4752727160290486), high=Score(precision=0.5908039780787024, recall=0.5272154423236273, fmeasure=0.5185958887659661))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.502506236681007, recall=0.45060439178904726, fmeasure=0.43547645565521786), mid=Score(precision=0.5454424019607844, recall=0.4907755762334418, fmeasure=0.47657621317979193), high=Score(precision=0.5868481127736646, recall=0.5319950938272876, fmeasure=0.5166419209164365))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.3608754985567945, recall=0.30972551169882206, fmeasure=0.30357958236045013), mid=Score(precision=0.409827308006536, recall=0.3556708340106427, fmeasure=0.3485490290439031), high=Score(precision=0.4532628324596156, recall=0.39878231729050173, fmeasure=0.3901584882437119))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4960528912519263, recall=0.4439065471179646, fmeasure=0.42987299261948847), mid=Score(precision=0.5406718485762605, recall=0.4858423682236215, fmeasure=0.47269356446324845), high=Score(precision=0.5859835328172643, recall=0.5299284330574959, fmeasure=0.5164918134211643))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.49408676088005155, recall=0.4429590775069074, fmeasure=0.42923122521443324), mid=Score(precision=0.5411597428306987, recall=0.4867416149033823, fmeasure=0.47320261768006655), high=Score(precision=0.5872740062072326, recall=0.5332425653405093, fmeasure=0.51814711653653))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5015161094849853, recall=0.4489401713410114, fmeasure=0.4386340046429024), mid=Score(precision=0.5456955923602113, recall=0.4902005089898098, fmeasure=0.47875072167339705), high=Score(precision=0.5868989316148033, recall=0.5284563406339949, fmeasure=0.5147975419607171))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.35755235259532137, recall=0.3077019300075788, fmeasure=0.3012498381469187), mid=Score(precision=0.40573751075313585, recall=0.3532062224427511, fmeasure=0.34659994906067826), high=Score(precision=0.4498823067557443, recall=0.39739536410718235, fmeasure=0.38748701349771286))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4964331117358305, recall=0.44092974493581066, fmeasure=0.43089492778499205), mid=Score(precision=0.5392619257194042, recall=0.4843490327668669, fmeasure=0.4741904093251174), high=Score(precision=0.5835599590612991, recall=0.5314072350253668, fmeasure=0.5176455621171648))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.49219532679572103, recall=0.4412591359433724, fmeasure=0.4310377527711343), mid=Score(precision=0.5399807502976042, recall=0.484948588473194, fmeasure=0.474271744440947), high=Score(precision=0.5839103270933572, recall=0.530860316555562, fmeasure=0.5187091038611463))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5034339623203593, recall=0.4509600891952754, fmeasure=0.4400175048903605), mid=Score(precision=0.5444059673986146, recall=0.4898741678951163, fmeasure=0.48012214160882216), high=Score(precision=0.5854137868820314, recall=0.5296417630699165, fmeasure=0.5191390353724822))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.3593196562628548, recall=0.31082609154710705, fmeasure=0.3050614912127828), mid=Score(precision=0.40783518146477704, recall=0.3557175728192573, fmeasure=0.3493573342486714), high=Score(precision=0.4532473410219275, recall=0.40112333836919645, fmeasure=0.39103627229146287))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4941420922572118, recall=0.44207549812646435, fmeasure=0.43273823474809403), mid=Score(precision=0.5387153369506312, recall=0.4855798993298531, fmeasure=0.4758327430183029), high=Score(precision=0.5831066216922376, recall=0.5303754685328498, fmeasure=0.5195357620353819))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4935114282980093, recall=0.4431707675360697, fmeasure=0.43226346418832146), mid=Score(precision=0.5390839979056892, recall=0.48571495141053944, fmeasure=0.47606269819147484), high=Score(precision=0.5822764235968276, recall=0.5311724132023866, fmeasure=0.5190552678693404))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5035903403001797, recall=0.44853405874805813, fmeasure=0.4375391501491598), mid=Score(precision=0.5447530492812998, recall=0.4885973823249623, fmeasure=0.478151839046302), high=Score(precision=0.5855656326323316, recall=0.5275456535325644, fmeasure=0.5164082052543307))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.35600196366133874, recall=0.3091656356229152, fmeasure=0.3016756933864776), mid=Score(precision=0.40431497873042, recall=0.3536627545552657, fmeasure=0.3461607808004148), high=Score(precision=0.44889438413914523, recall=0.39865039205629993, fmeasure=0.3884882261364476))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.49391328279536717, recall=0.4397880574800801, fmeasure=0.4307565163053942), mid=Score(precision=0.5387199186531134, recall=0.48383120979651095, fmeasure=0.4740157974171927), high=Score(precision=0.5833373419494161, recall=0.5290137309188044, fmeasure=0.5176097108733968))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4930194440003798, recall=0.4412354654472746, fmeasure=0.43009867971675275), mid=Score(precision=0.5392452538753816, recall=0.4839011537640895, fmeasure=0.4737889516131716), high=Score(precision=0.5836071304174194, recall=0.5297718896014149, fmeasure=0.5178303721856421))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.5039998595318619, recall=0.4470012867272692, fmeasure=0.43518582862242594), mid=Score(precision=0.545030608323565, recall=0.4866960341968658, fmeasure=0.47723612924355385), high=Score(precision=0.5879438767209207, recall=0.5267762009345779, fmeasure=0.5149597143633609))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.35923758131166234, recall=0.3073431449877997, fmeasure=0.299858956824884), mid=Score(precision=0.4066846396046764, recall=0.3518857134680488, fmeasure=0.34502159714612096), high=Score(precision=0.45039526392724943, recall=0.397349592130319, fmeasure=0.3869058430532109))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.49359087634179544, recall=0.43780906168283645, fmeasure=0.42933452401824257), mid=Score(precision=0.539688953762096, recall=0.4820351919313641, fmeasure=0.47275309311845815), high=Score(precision=0.5833544202220745, recall=0.5263109189477608, fmeasure=0.5172162468991726))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4936958316343959, recall=0.43815424794573055, fmeasure=0.42896330737180205), mid=Score(precision=0.539964599120994, recall=0.48256690833498367, fmeasure=0.47300239727015275), high=Score(precision=0.584055468135182, recall=0.5278016701055552, fmeasure=0.5164129306639902))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=40000, training_loss=0.21655789289474486, metrics={'train_runtime': 24368.4952, 'train_samples_per_second': 3.283, 'train_steps_per_second': 1.641, 'total_flos': 7.049878619231232e+16, 'train_loss': 0.21655789289474486, 'epoch': 25.0})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T12:24:14.735175Z",
     "iopub.status.busy": "2023-07-29T12:24:14.734466Z",
     "iopub.status.idle": "2023-07-29T12:24:14.751981Z",
     "shell.execute_reply": "2023-07-29T12:24:14.750883Z",
     "shell.execute_reply.started": "2023-07-29T12:24:14.735136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 0, 'text': \"He Tackles A Nurse At The Hospital Then You See What's On The Floor Next To Them  Male Nurse Breaks Down When His Friend Reveals He Can Give Him A KidneyWhen you think about your good friends, many things come to mind how bland life would be without them, how they make you laugh and smile when you need it, and how they are there to support you in any situation You may even ask yourself the question — what would I do for them in return? For 24yearold Graham McMillan, the answer is simple there is simply no limit to what he would do for his friends So, when his buddy Danny Kolzow, a 23yearold nurse at Baylor All Saints in Fort Worth, TX, found himself in need of a kidney, McMillan didn’t hesitate to find out if he could donate one of his As it turned out, he was a match He decided to surprise his friend with the good news, and did so in the most incredible way In this emotional clip, McMillan walks into the hospital where Kolzow works He has balloons and a sign in hand that reads, Heard urine need of a kidney, want mine? It seems like the young man is quite the jokester The moment Kolzow sees him, he understandably breaks down into tears He can barely believe his good luck not only does he get a kidney, but he knows that he also has a great friend who will be by his side through thick and thin The gift of life and the gift of friendship are both priceless\"}\n"
     ]
    }
   ],
   "source": [
    "print(test_data[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T12:24:14.754137Z",
     "iopub.status.busy": "2023-07-29T12:24:14.753809Z",
     "iopub.status.idle": "2023-07-29T12:25:04.241454Z",
     "shell.execute_reply": "2023-07-29T12:25:04.240417Z",
     "shell.execute_reply.started": "2023-07-29T12:24:14.754103Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28/2904365645.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch_input = {k: torch.tensor(v).to(model.device) for k, v in batch_input.items()}\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_28/2904365645.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  output = [torch.tensor(o).to(model.device) for o in output]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 0, spoiler: Danny Kolzow, a 23yearold nurse at Baylor All Saints in\n",
      "id: 1, spoiler: Putting your needs before those of your colleagues is often seen as selfish behaviour But new research says\n",
      "id: 2, spoiler: The big finding from Stanford economist Raj Chetty and his seven coauthors is not that rich\n",
      "id: 3, spoiler: any of numerous wasps of the family Braconidae, the larva\n",
      "id: 4, spoiler: remove any excess water from the yolks 1 Start by combining 1 cup salt and\n",
      "id: 5, spoiler: John Williams\n",
      "id: 6, spoiler: turning on your bed, just randomly checking the fridge for late night munchies and scroll\n",
      "id: 7, spoiler: Flynn the dog does a lot to help out his 17yearold human, Hai\n",
      "id: 8, spoiler: Lord Ivar Mountbatten has revealed that he is now dating a man after \n",
      "id: 9, spoiler: too much too soon Brandon says Focus on the power that you're getting along\n",
      "id: 10, spoiler: I was with them The 1yearold must be changed, washed, \n",
      "id: 11, spoiler: Foursquare cofounder Dennis Crowley This Mistake Will Get You Called Out on Social Media\n",
      "id: 12, spoiler: Celia Cruz\n",
      "id: 13, spoiler: David De Gea\n",
      "id: 14, spoiler: selfish people doing foul things are mustreads The Bottom Line 'Homesick For\n",
      "id: 15, spoiler: Saudi Arabia holds roughly 117 billion of the US government’s debt\n",
      "id: 16, spoiler: swine transformation\n",
      "id: 17, spoiler: Sophia AlMaria\n",
      "id: 18, spoiler: 1 Get an education\n",
      "id: 19, spoiler: Your Cat Could Become Illegal If You Live In This State Cat Claw Removal\n",
      "id: 20, spoiler: Michael Sam Comes Out As Gay Missouri Football Star Could Be 1st Openly Gay NFL\n",
      "id: 21, spoiler: Drunk or Danish? Swedish police eventually work it out Police in western Sweden initially thought a\n",
      "id: 22, spoiler: very affordable prices, these can be purchased online for a fraction of their retail value\n",
      "id: 23, spoiler: The Man In The Yellow Hat from Curious George, she makes this long patent jacket look\n",
      "id: 24, spoiler: The Polished Man Project But upon further inspection, one could learn about the reason\n",
      "id: 25, spoiler: her. Jessica Bentley Luke Skywalker Even though I'm a girl\n",
      "id: 26, spoiler: fter the funeral of Columbus, Ohio SWAT Officer Steven Smith, nine police officers who\n",
      "id: 27, spoiler: The poll shows that the vast majority of Americans think climate change, and more frequent and severe natural\n",
      "id: 28, spoiler: Trump’s stunning win in Florida\n",
      "id: 29, spoiler: about 100 people between 1,500 and 2,000 every month to spend on whatever they please\n",
      "id: 30, spoiler: women have far more parity with their male counterparts than women do in the US\n",
      "id: 31, spoiler: some seriously relentless sideeye Watch the hilarious video below to see one unamused puppy\n",
      "id: 32, spoiler: Putting a gloss on your waste problem by repackaging it as a food\n",
      "id: 33, spoiler: November 11 and just pick one up Unfortunately, a glance at the Amazon page for\n",
      "id: 34, spoiler: textbooks\n",
      "id: 35, spoiler: at the gym And at the shower, he keeps them all organized in one spot And\n",
      "id: 36, spoiler: Laziness might not be a terrible trait after all\n",
      "id: 37, spoiler: bats count as breakfast 1 People play bingo with chicken sht Seriously Austin is\n",
      "id: 38, spoiler: ALS is a form of the motorneuron disease amyotrophic \n",
      "id: 39, spoiler: YInMn blue\n",
      "id: 40, spoiler: you sleep better A new study of cataract patients indicates that artificial lens implants can help improve\n",
      "id: 41, spoiler: An eagleeyed Mars 'anomaly hunter' has \n",
      "id: 42, spoiler: Proof That 'Parenthood' Is The Saddest, Happiest Show\n",
      "id: 43, spoiler: the greenhouse effect is still strong and can be deadly In fact, the greenhouse effect is still\n",
      "id: 44, spoiler: A Wood Plank That He Led On The Inside Of The Dumpster And Made A \n",
      "id: 45, spoiler: Jason Aldean has found himself in unfortunate circumstances after a tour bus carrying the Dirt\n",
      "id: 46, spoiler: he was doing his job as normal when, reading The Prisoner of Azkaban\n",
      "id: 47, spoiler: urinals to pee in And as we get closer to our imminent deaths,\n",
      "id: 48, spoiler: Russell Wilson Listens To Gospel Before Kickoff\n",
      "id: 49, spoiler: One Extra Box Of tissues Signed, A Frustrated Parent Signe\n",
      "id: 50, spoiler: Jordan Rodgers\n",
      "id: 51, spoiler: As it turns out, the first free DLC —which included 70 new events, \n",
      "id: 52, spoiler: Mad Men earned more than 1 million viewers But by season two, those numbers spiked\n",
      "id: 53, spoiler: avoid Do YOU have high cholesterol? Here are 5 foods to eat and avoid Do YOU\n",
      "id: 54, spoiler: Pennsylvania 6 percent sales tax Pennsylvania is taxing netflix spotify and apple\n",
      "id: 55, spoiler: whales dyed to begin with Scientists were very concerned and deeply disturbed as to what they\n",
      "id: 56, spoiler: Among those who are 65 and older and eligible to remarry, age made \n",
      "id: 57, spoiler: Amber Galloway Gallego is not your everyday American Sign Language ASL interpreter —\n",
      "id: 58, spoiler: Kili the Senegal parrot has somehow managed to become a master at playing dead\n",
      "id: 59, spoiler: Miley Cyrus\n",
      "id: 60, spoiler: a sweet note to her students, saying Mrs Thom is in charge of worrying you\n",
      "id: 61, spoiler: automatically Step 1 At first, you’ll need to use the items in normal ways Simply\n",
      "id: 62, spoiler: six seconds Or The Biggest Mistake You're Making In The Bathroom\n",
      "id: 63, spoiler: Jussie Smollett\n",
      "id: 64, spoiler: Hillary Clinton\n",
      "id: 65, spoiler: you can also provide someone else access to your travel informationYour phone number, frequent flyer\n",
      "id: 66, spoiler: Delaware loophole — the unassuming building at 1209 North Orange Street — has become\n",
      "id: 67, spoiler: Kevin Hart\n",
      "id: 68, spoiler: WAY better Amazon Prime Just Got Way Better With A Ton Of Old HBO Shows\n",
      "id: 69, spoiler: Katie Holmes Rents New York City PenthouseRENTER Katie Holmes LOCATION New York\n",
      "id: 70, spoiler: still using regular glass And here’s where it gets interesting, because Apple still advertises\n",
      "id: 71, spoiler: They They has become an increasingly popular substitute for he or she They They has become an\n",
      "id: 72, spoiler: In the 90s, these were physical doors rather than virtual ones, but the concept is the\n",
      "id: 73, spoiler: 1 Museum of Modern Art\n",
      "id: 74, spoiler: I need to eat cupfuls of chickpeas Can athletes be\n",
      "id: 75, spoiler: Tanzania Bolivia's chaotic San Pedro Prison Bolivia's chaotic San Pedro Prison\n",
      "id: 76, spoiler: Until this new discovery, scientists believed Makemake was the only one of the four officially recognized\n",
      "id: 77, spoiler: Tokyo\n",
      "id: 78, spoiler: Guy Bourdininspired line The cosmetics company has revealed that they'll be t\n",
      "id: 79, spoiler: Mexico City Will Infuriate Him Mexico City The PGA Just Cancel\n",
      "id: 80, spoiler: the dapper cool look As a father with his daughter Ziva sitting on his lap\n",
      "id: 81, spoiler: she should eat less calories So she did But even eating 1000 calories per day, nothing\n",
      "id: 82, spoiler: The Most Requested In America The Most Requested In America The Most\n",
      "id: 83, spoiler: Plastic Surgery Years ago to make her eyes look bigger and advance her career\n",
      "id: 84, spoiler: Robert Redford Shape Magazine Meryl Streep Marries Robert Redford Shape Magazine\n",
      "id: 85, spoiler: metabolic conditioning can help you improve your work capacity, making your body more efficient for all those\n",
      "id: 86, spoiler: Katy Perry Catches Bouquet At Grammys mass wedding\n",
      "id: 87, spoiler: Netherlands launches legal proceedings against Russia over Greenpeace arrests\n",
      "id: 88, spoiler: some people saw it as a chance to bodyshame Tetteh\n",
      "id: 89, spoiler: I absolutely rejected it But anyway, things changed after DICE showed him a small\n",
      "id: 90, spoiler: Amazon sent Emily Heller two brand new doormats but when they arrived weeks later, the\n",
      "id: 91, spoiler: white chocolate white chocolate He turned me on to white chocolate White chocolate I now acceptand\n",
      "id: 92, spoiler: a Hooters girl\n",
      "id: 93, spoiler: In 2009, the eccentric and brilliant uncle of a brother and sister in Newcastle upon Tyn\n",
      "id: 94, spoiler: Donald Trump But what bothers him even more is the Democratic Party’s support of same\n",
      "id: 95, spoiler: Peter Pilotto\n",
      "id: 96, spoiler: IVF or intracytoplasmic sperm injection\n",
      "id: 97, spoiler: Jennifer Lawrence\n",
      "id: 98, spoiler: Nebraska\n",
      "id: 99, spoiler: Trump promised to cancel the Paris Climate Plan\n",
      "id: 100, spoiler: 1 Adventurous Christmas Chile\n",
      "id: 101, spoiler: ___ SECOND WIND As has become familiar practice at E3 _\n",
      "id: 102, spoiler: A new survey says that, not taking into account sleeping time, Thai people spend the majority of\n",
      "id: 103, spoiler: A new update for the Xbox One version of Terraria has caused a serious issue\n",
      "id: 104, spoiler: a simple way To Banish Stinky Garlic Breath 25 seconds\n",
      "id: 105, spoiler: his wife three last words, I love you before he took his last breath and died\n",
      "id: 106, spoiler: Alfredo\n",
      "id: 107, spoiler: you’re not doing anything wrong 7 Years 1 7 Years an image\n",
      "id: 108, spoiler: Delores Curtis Lost 181 PoundsName Delores Curtis Age\n",
      "id: 109, spoiler: fire authorities in Western Australia say no properties were lost during a bushfire around the town of\n",
      "id: 110, spoiler: 1,000 unconditionally unconditionally’s What Happens When You Give 1,000 to Someone\n",
      "id: 111, spoiler: Ultimately, his experiences led Woods to reject the way drugs are policed in the UK\n",
      "id: 112, spoiler: tikka masala The people who were not able to eat that delicious spiced\n",
      "id: 113, spoiler: the rest of it There’s a reason the title was shortened was so that\n",
      "id: 114, spoiler: Shamus Beaglehole Wins 2014 Name of the Year Contest\n",
      "id: 115, spoiler: one that offered free DNA testing a familial DNA search a familial\n",
      "id: 116, spoiler: three The ideal number of people you sleep with, for both men and women to retain\n",
      "id: 117, spoiler: Viralands Viralands He Places Colored Water in Bread\n",
      "id: 118, spoiler: The basic similarities are all there A cloaked protagonist with superhuman strength locks horn\n",
      "id: 119, spoiler: National Cheeseburger Day\n",
      "id: 120, spoiler: lower Than they will eventually get back if they hold them to maturity negative Something\n",
      "id: 121, spoiler: Walmart's Biggest Black Friday Seller was a 29cent towel\n",
      "id: 122, spoiler: prices This spring J Crew J Crew Stores Lower Prices This Spring J Crew Store\n",
      "id: 123, spoiler: Universal Basic Income\n",
      "id: 124, spoiler: there are also side characters who have a father and no mother And that's \n",
      "id: 125, spoiler: Donald Trump Appeared In A 2000 Playboy Softcore Porn\n",
      "id: 126, spoiler: the bigger pocket of your jeans?? According to a question and answer on\n",
      "id: 127, spoiler: whale\n",
      "id: 128, spoiler: Peter Dinklage's voiceover work on this video game Destiny has not been well\n",
      "id: 129, spoiler: the Playstation 45, and you won’t be seeing that with the Xbox One\n",
      "id: 130, spoiler: now Costco Visa Anywhere card is the only credit card accepted at Costco Debit\n",
      "id: 131, spoiler: Ken Worrall\n",
      "id: 132, spoiler: Kim Jong Un impersonator Howard decided it was time to take a different\n",
      "id: 133, spoiler: Can You Pick The Apple Logo From This LineUp?4 More than half of the 85 students\n",
      "id: 134, spoiler: the Oregonian reported The two brothers are arguing that they cannot sufficiently prepare for their Sept\n",
      "id: 135, spoiler: frostbite The doctor told her that the extent of her injuries ranged from\n",
      "id: 136, spoiler: whitewashing\n",
      "id: 137, spoiler: Recordbreaking CPR saved this woman Snowshoer Who Fell Into Tree Well Surv\n",
      "id: 138, spoiler: VERY gruesome habits From leaving used condoms on the bed and women flash\n",
      "id: 139, spoiler: Salman Khan Salman Khan’s fans Here Is The Reason Why Sal\n",
      "id: 140, spoiler: Jose Jose, Mexican Singer, Falls Off Stage During Anniversary Concert\n",
      "id: 141, spoiler: Using the latest International Panel on Climate Change report, it is possible to estimate how much each\n",
      "id: 142, spoiler: 2016 was good But there were still some good things that happened in 2016 Eight Good Things\n",
      "id: 143, spoiler: Thousands of genes have evolved recently in the last 40,000 years Changes we are seeing include\n",
      "id: 144, spoiler: 24week pregnant woman facing danger to her life due to an abnormality in the foe\n",
      "id: 145, spoiler: Donald Trump takes poll lead over Hillary Clinton – is it time to panic?\n",
      "id: 146, spoiler: Whale Ear Wax Stores All sorts of useful information on the animal’s exposure to\n",
      "id: 147, spoiler: replace all the larger vessels with those of smaller sizes According to this report in the TO\n",
      "id: 148, spoiler: Queen Elizabeth II can occasionally walk among the public and avoid detection, at least according to an account\n",
      "id: 149, spoiler: Release Date, Share Daydreaming VideoAt long last, it's here Radio\n",
      "id: 150, spoiler: Daniel Radcliffe On 'Kill Your Darlings' Moving Beyond, But Not\n",
      "id: 151, spoiler: The Rock\n",
      "id: 152, spoiler: Jackson Vroman\n",
      "id: 153, spoiler: 1 Ideas Have Consequences by Richard Weaver\n",
      "id: 154, spoiler: MIT researchers can read pages of a book without opening it\n",
      "id: 155, spoiler: Katherine Heigl's Difficult Behavior Is 'Not Worth It\n",
      "id: 156, spoiler: some varieties of red grapes have virtually none Melatonin While some varieties of red\n",
      "id: 157, spoiler: Penn Teller amp Teller loses 100 lbs with ONE vegetable Jill\n",
      "id: 158, spoiler: Applying your foundation, blusher and concealer incorrectly can add decades to your looks\n",
      "id: 159, spoiler: Taran Killam\n",
      "id: 160, spoiler: the aggressive drivers who speed around them and flip them off\n",
      "id: 161, spoiler: they became more sympathetic towards similar groups in contemporary society such as the LGBT and immigrant\n",
      "id: 162, spoiler: Katrina Henry\n",
      "id: 163, spoiler: Does Your IQ Correlate With The rap Music You Listen To? Does\n",
      "id: 164, spoiler: Ernestine Shepherd\n",
      "id: 165, spoiler: they destroy–or prune–the synapse They prune your synapt\n",
      "id: 166, spoiler: 66 or 67 medals But if they managed to nab 11\n",
      "id: 167, spoiler: pork loin Nicole Hillman, from Brynmawr, Wales, bought the\n",
      "id: 168, spoiler: your bump Don't tell her she's getting bigger and NEVER touch the bump\n",
      "id: 169, spoiler: Harry Potter is not what she's most proud of JK Rowling Single Motherhood\n",
      "id: 170, spoiler: almost double the 383,413 from 2008 You Won't Believe How Much\n",
      "id: 171, spoiler: Laws that maintain the legal drinking age of 21 save lives on the road, and protect young\n",
      "id: 172, spoiler: Oregon has more marijuana shops than Starbucks or McDonald’s\n",
      "id: 173, spoiler: this Romney's Home Has A Slide, Craft Room And Much More\n",
      "id: 174, spoiler: brazillian takes on new role Barcelona Sign Ronaldinho for the Second Time as Brazilian Take\n",
      "id: 175, spoiler: Jennifer Lawrence will make an unexpected cameo in highly anticipated sequel\n",
      "id: 176, spoiler: her beautiful girl Emily after a threeyear battle with cancer One in 285 is \n",
      "id: 177, spoiler: Steam users own hundreds of thousands of dollars worth of CSGO skins\n",
      "id: 178, spoiler: tahini Decadent Pumpkin Pie Recipe Has a Salty\n",
      "id: 179, spoiler: Prancer sitting on a couch, reading newspaper and sipping tea Greg Pu\n",
      "id: 180, spoiler: Bear breaks into bakery and devours dozens of pies, but leaves one kind behind\n",
      "id: 181, spoiler: paper bag\n",
      "id: 182, spoiler: Brussels sprouts\n",
      "id: 183, spoiler: my entire face I could immediately feel and see how it locked in muchneeded moisture\n",
      "id: 184, spoiler: that Jimmy Smits as Bail Organa Rogue One Cameo\n",
      "id: 185, spoiler: Linux will remain Windows 10 Linux isn’t going anywhere, with a market\n",
      "id: 186, spoiler: headphones to give you an opportunity to create a spark with her How to actually\n",
      "id: 187, spoiler: calling it ‘shit’ stopped the show to berate a thrilled Belieb\n",
      "id: 188, spoiler: years to build And with fickle markets and studios losing funding, even after a\n",
      "id: 189, spoiler: Tempting as it might be, don't make fun of the funny looking soldiers in\n",
      "id: 190, spoiler: NJ police are searching for two men who they say tried to abduct a 10yearold\n",
      "id: 191, spoiler: Laura Bush\n",
      "id: 192, spoiler: Michael Brain, a former Royal Marine, has been banned from going on dating websites for life\n",
      "id: 193, spoiler: her voice I can’t eat pizza anymore guys, how bad is that?\n",
      "id: 194, spoiler: Justin Timberlake's ButtDuring A Song\n",
      "id: 195, spoiler: Buying organic food typically involves shelling out a premium But is the extra pinch to the\n",
      "id: 196, spoiler: 1 Because with 300 days of sunshine, Colorado is one of the sunniest places in America\n",
      "id: 197, spoiler: Initial jobless claims unexpectedly fall\n",
      "id: 198, spoiler: Lego did something unusual last year It began looking for ways to discourage customers from buying its products\n",
      "id: 199, spoiler: Indiana Jones 5 One Big Thing for Indiana Jones 5Steven Spielberg Promises\n",
      "id: 200, spoiler: electronic contactless inlays for manufacturing of epassports to India Security Press I\n",
      "id: 201, spoiler: there are still things that are unresolved These are the people coming right back\n",
      "id: 202, spoiler: it took 10 years But it turns out Mad Men star took 10 years to make this\n",
      "id: 203, spoiler: A black bag, hidden inside Inside the bag were bricklike objects covered in tape Unw\n",
      "id: 204, spoiler: escaping from a pursuit is much more rare In Los Angeles But a driver escaping\n",
      "id: 205, spoiler: A 35yearold man from Bhiwandi who used his fourwheeler to ferry\n",
      "id: 206, spoiler: A talented Irish rower has died after falling in a freak accident just hours after winning \n",
      "id: 207, spoiler: the ultimate goal You Can Be Mentally Stronger If You Do This Small Act Every\n",
      "id: 208, spoiler: ChicagoTaxes on cigarettes are rising yet again in Chicago with a 50cent increase that\n",
      "id: 209, spoiler: if yes is the answer to any of the following questions Does the image show only parts of\n",
      "id: 210, spoiler: Nellie Bly\n",
      "id: 211, spoiler: Sadly, This Is The Top Vegetable 1YearOlds In\n",
      "id: 212, spoiler: a burnt bear bone The chamber was vast, thirtymeterlong, and there were\n",
      "id: 213, spoiler: because she got distracted by her own ‘erotic thoughts’\n",
      "id: 214, spoiler: I said Just imagine him trying to save him from himself I really was But what do you\n",
      "id: 215, spoiler: The simple reason the Cavs can't win the NBA title\n",
      "id: 216, spoiler: Eatsa The techsavvy restaurant chain, which just opened its first East Coast location in New\n",
      "id: 217, spoiler: You'll Never Guess How Much Money the Marvel Universe Has Grossed\n",
      "id: 218, spoiler: your cell phone will automatically explode Black Cellphones and soon after an explosion is \n",
      "id: 219, spoiler: student debt\n",
      "id: 220, spoiler: Palestinian terrorist who plowed his truck into a group of soldiers in Jerusalem on Sunday,\n",
      "id: 221, spoiler: they still hope they can reconcile But Will or won’t they divorce?\n",
      "id: 222, spoiler: 'Please value life' The vet who 'euthanised' herself in Taiwan\n",
      "id: 223, spoiler: Police arrested four women in North Carolina for allegedly spraying antiTrump, antipolice\n",
      "id: 224, spoiler: she predicted her death in her final text message to him Emily Gardner\n",
      "id: 225, spoiler: Ava Urrea, a 4yearold who was born with hypoplastic left heart syndrome\n",
      "id: 226, spoiler: The blink182 song we beat to death in Tucson is 'Feeling This\n",
      "id: 227, spoiler: Los Angeles X17 Online snagged photos of Kardashian dressed in legging\n",
      "id: 228, spoiler: Ana Ana, the kickass healsniper Ana’s inclusion in the game is\n",
      "id: 229, spoiler: Charles Barkley laughs off LeBron James' barbs, stands by criticism of the\n",
      "id: 230, spoiler: Orlando Coroner Did Something Unusual with Shooter’s Body to Honor the 49\n",
      "id: 231, spoiler: pears You won’t believe what it is —gt You won\n",
      "id: 232, spoiler: Blake McIver\n",
      "id: 233, spoiler: in Illinois, it is now legal to hunt for catfish with pitchforks or spear\n",
      "id: 234, spoiler: His son, Calvin, died in a fatal highspeed car wreck Paul Li\n",
      "id: 235, spoiler: 1 Miley Cyrus\n",
      "id: 236, spoiler: Adele forgot the lyrics to her song and this was her reaction Will Make You LOL\n",
      "id: 237, spoiler: I need feminism because I intend on marrying rich and I can’t do\n",
      "id: 238, spoiler: Santa Claus loves pit bulls Santa Claus loves pit bulls Lola The Dog'\n",
      "id: 239, spoiler: Amy Schumer Takes On 'The Newsroom' And NAILS It\n",
      "id: 240, spoiler: Microsoft Applicant Shares Crazy Hard Interview Question That Left Him Stumped Microsoft Applic\n",
      "id: 241, spoiler: Brexit Vote Has Exposed polarization between Scotland and large parts of England who \n",
      "id: 242, spoiler: a calling a calling purpose is incredibly tied to both business and personal\n",
      "id: 243, spoiler: A 60yearold woman sitting alone in her car reading a book Quintin\n",
      "id: 244, spoiler: Emperor Palpatine's granddaughter\n",
      "id: 245, spoiler: Superior mesenteric artery syndrome, a condition in which her small intestine\n",
      "id: 246, spoiler: the ALS Association to the ALS Association The Ice Bucket Challenge went\n",
      "id: 247, spoiler: Venus Holes are located in a place where there is no muscle, it’s impossible\n",
      "id: 248, spoiler: mysterious dots heated cups are placed on the skin heated cups are placed on the skin\n",
      "id: 249, spoiler: Gaza residents arrested for participating in protests against cuts to the electricity supply\n",
      "id: 250, spoiler: Depending on your definition of sleep, you might be surprised to learn that some plants open their\n",
      "id: 251, spoiler: Khan's win I think it's a very good thing, and I hope \n",
      "id: 252, spoiler: Vievu AP Image Vievu AP Image Vievu \n",
      "id: 253, spoiler: ManilaSPOTph Manila ManilaSPOTph ManilaSPOTp\n",
      "id: 254, spoiler: stressed and sleepless How to Fall Asleep in Under a Minute\n",
      "id: 255, spoiler: retired detective reunites with girl he saved years ago\n",
      "id: 256, spoiler: a chopsticks holder The tab needs to be separated from the chopstick\n",
      "id: 257, spoiler: ice cube trays Egg Cartons Egg Cartons Make Great Organization Tools\n",
      "id: 258, spoiler: convicted of them More Likely to Commit Sexual Assault?\n",
      "id: 259, spoiler: you can actually gain an inch or two because the pubic fat around your pubic area\n",
      "id: 260, spoiler: Trump is a good candidate with flaws He is egotistical, bomb\n",
      "id: 261, spoiler: You can now use them as a standalone snack or add them to your salads and\n",
      "id: 262, spoiler: Ben Bernanke Should Stay On As Fed Chair\n",
      "id: 263, spoiler: Jordan Klepper\n",
      "id: 264, spoiler: Online ID protection\n",
      "id: 265, spoiler: they were offered snacks From which to choose They included the kind of snacks we like to indulge\n",
      "id: 266, spoiler: Final episodes of Breaking Bad will be on Netflix way sooner than you thought\n",
      "id: 267, spoiler: Depending on your priorities, you might find that you need to exercise more often than you might\n",
      "id: 268, spoiler: 74 of millennial couples talk about their money weekly, and that those who do report\n",
      "id: 269, spoiler: polymyalgia rheumatica (PMR) is an \n",
      "id: 270, spoiler: The Cubs rallied and celebrated on the diamond while thousands of visiting Cubs fans \n",
      "id: 271, spoiler: Pokémon Go requires your full attention People People a Pokémon on a backdrop\n",
      "id: 272, spoiler: a drink coaster The standard Starbucks lid was designed to be used as a\n",
      "id: 273, spoiler: unfortunately they are genuinely not wanted at all The worst gift to give this Christmas The\n",
      "id: 274, spoiler: Matt Damon You can be a cool dad?\n",
      "id: 275, spoiler: Scarlett Johansson could make Oscar history\n",
      "id: 276, spoiler: HERC2\n",
      "id: 277, spoiler: 's heart beatA mother hears her dead son four years ago, and now she\n",
      "id: 278, spoiler: my hair would fall out? Roxie Darling Daenerys Tar\n",
      "id: 279, spoiler: the entire crowd simply stood up after a brutally long second inning of play,\n",
      "id: 280, spoiler: incredibly cool The researchers explained that rice contains two kinds of starch—one that is\n",
      "id: 281, spoiler: they’re trying to tell you something Very Important If You Ever See Your Cat Doing\n",
      "id: 282, spoiler: spy camera Hidden inside a wall hook is a tiny camera that records people in the bathroom\n",
      "id: 283, spoiler: Oprah Winfrey net worth 28 billion\n",
      "id: 284, spoiler: Where Opportunity Knox\n",
      "id: 285, spoiler: They profile They profile People that maybe look suspicious I don’t know, Trump replied\n",
      "id: 286, spoiler: over her head Why? Why? Because women have more room Carson Daly\n",
      "id: 287, spoiler: During Sunday’s finale, a subtle but important change was made to the animation\n",
      "id: 288, spoiler: is Redheads, We've Found The Perfect Eyeshadow Color For You PH\n",
      "id: 289, spoiler: Aaron Judge's blasts go a long way\n",
      "id: 290, spoiler: Thiruvananthapuram, India Thiruvananthapuram,\n",
      "id: 291, spoiler: the list. The authors note, foods dense in fat and glycemic\n",
      "id: 292, spoiler: 1 Ecuador  Gabrielle Michel TherinWeiseGetty Images Reti\n",
      "id: 293, spoiler: The terrifying way not sleeping enough actually changes your gut\n",
      "id: 294, spoiler: There were many plot twists and updates that gave the newly released Beauty and the Beast \n",
      "id: 295, spoiler: Miley Cyrus strips down in an entirely different way Acoustic Take On 'Ad\n",
      "id: 296, spoiler: they heard their ideas projected morality Like this While your thoughts were similar to other students'\n",
      "id: 297, spoiler: Buffy the Vampire Slayer was the best possible name for that show TV THE\n",
      "id: 298, spoiler: Mr Burger is offering just that, but on one condition Mr Burger wants you to change your last\n",
      "id: 299, spoiler: 4 types of cancer Foods and Healthy Life Stop Eating This Food Immediately It Cause\n",
      "id: 300, spoiler: Peter Facinelli\n",
      "id: 301, spoiler: Chris Pratt Jokes About 'Guardians Of The Galaxy' Alien Se\n",
      "id: 302, spoiler: audiologist and tenured professor, require a PhD Others, like medical and pharmacy\n",
      "id: 303, spoiler: there is a way to reduce your chances Of course, you can avoid prison But,\n",
      "id: 304, spoiler: You may not even know that in your garden, you have the most miraculous plant that is\n",
      "id: 305, spoiler: Scarlett Johansson's SAT score Scarlett Jo\n",
      "id: 306, spoiler: Google Free music streaming service unveiled\n",
      "id: 307, spoiler: 1 CHILI PEPPERS\n",
      "id: 308, spoiler: Vermont Sen Bernie Sanders‘ Secret Service code name is Intrepid Intrepid Intrepid\n",
      "id: 309, spoiler: the best time of day to do number two's Healthiest You guys\n",
      "id: 310, spoiler: UCLA Has More NCAA Championships Than Black Male Freshmen\n",
      "id: 311, spoiler: the chance That a stranger will abduct and kill or not return a child,\n",
      "id: 312, spoiler: crazy The Pigeon game mode That is to say it’s similar to Capture\n",
      "id: 313, spoiler: priyankachopra said what? Baywatchmovie MAY 25\n",
      "id: 314, spoiler: Dallas Season 3 premiere date revealed\n",
      "id: 315, spoiler: probably more like seven and a half Sleeping less than seven hours has been proven to\n",
      "id: 316, spoiler: Closer\n",
      "id: 317, spoiler: Muncie Animal Shelter\n",
      "id: 318, spoiler: AP Photo Donald Trump calls Ted Cruz the P word\n",
      "id: 319, spoiler: Paul Ryan President Trump will have the funding to build the wall, and he already has the\n",
      "id: 320, spoiler: Hillary Clinton is a hawk and warmonger People often point to her vote in 2002\n",
      "id: 321, spoiler: Lawrence Phillips, 39, was suspected in the death of 37yearold Damion Soward\n",
      "id: 322, spoiler: Carrer Avinyó, a gorgeous Barcelona apartment designed by David Kohn Architect\n",
      "id: 323, spoiler: walking Marriott Rewards has committed to sponsor Johnson’s mission to catch the remaining Pokémon in\n",
      "id: 324, spoiler: she could set up a payment plan, but the older man told her that the only\n",
      "id: 325, spoiler: community gardens of solar panels\n",
      "id: 326, spoiler: superfetation In humans, it's possible, but it's very uncommon\n",
      "id: 327, spoiler: Tina Fey reveals one SNL costar once called her the Cword\n",
      "id: 328, spoiler: Facebook Messenger\n",
      "id: 329, spoiler: ChristOn Christmas Day 2015, a farmer was out on his land and found what \n",
      "id: 330, spoiler: I also start saving early so I have a little stash that I know is for others\n",
      "id: 331, spoiler: 10 CocaCola Memorabilia\n",
      "id: 332, spoiler: evacuation of civilians and opposition fighters from eastern Aleppo have been suspended after rebels\n",
      "id: 333, spoiler: something he could’ve never imagined This Rock Seems Out Of Place When\n",
      "id: 334, spoiler: The Jump 2017 lineup confirmed by Channel 4 Sir Bradley Wiggins, Lydia Bright and Louis Smith\n",
      "id: 335, spoiler: you don't need to touch The goal is to make Watch Dogs 2 more\n",
      "id: 336, spoiler: if this happens If Elliott can give this offense what DeMarco Murray provided in\n",
      "id: 337, spoiler: Pikaqiu\n",
      "id: 338, spoiler: Plussize Top Model winner Whitney Thompson\n",
      "id: 339, spoiler: Scientists Have Formulated An Equation To Show Just How Much Damage Humans Are Causing\n",
      "id: 340, spoiler: You Guess It Rasputin You Guess It Rasputin Why? Radio Drama\n",
      "id: 341, spoiler: cucumbers\n",
      "id: 342, spoiler: You Want To Lose More Weight? Simply Replace Your Diet Soda With\n",
      "id: 343, spoiler: Captain Phillips,\n",
      "id: 344, spoiler: a black panther creeps up behind him Just as the big cat goes\n",
      "id: 345, spoiler: a rag\n",
      "id: 346, spoiler: Black Lives Matter is a movement that counters BLM by encouraging citizens to support police\n",
      "id: 347, spoiler: Houston clears rape kit backlog\n",
      "id: 348, spoiler: the very most was still sitting in a closet unopened On the plain white box was\n",
      "id: 349, spoiler: you're responsible for covering any fraudulent charges — not the bank And some retailers are\n",
      "id: 350, spoiler: Melissa McCarthy's Elle cover\n",
      "id: 351, spoiler: you can save water and energy The National Post in 2011 The studentteacher team was\n",
      "id: 352, spoiler: Howard Dean was speaking nonsense Notice Trump sniffing all the time Coke user? \n",
      "id: 353, spoiler: whiter teeth In minutes rinses it off Rubbing These Two Things on Your\n",
      "id: 354, spoiler: You Should Drink Milk Before A Road Trip You find yourself dehydrated you find\n",
      "id: 355, spoiler: this  pictwittercom8hOY899wNZ\n",
      "id: 356, spoiler: Chris Crocker\n",
      "id: 357, spoiler: Men are more likely to have a heart attack after a snowfall, and it'\n",
      "id: 358, spoiler: Baby Aubrey Her Daddy Died Before She Was Born But Watch What They\n",
      "id: 359, spoiler: McDonalds You'll Never Believe What Selena Gomez Orders at\n",
      "id: 360, spoiler: Minnesota Wants To Legalize Medical Marijuana, But Police Agencies Are In The\n",
      "id: 361, spoiler: personal responsibility and achievement\n",
      "id: 362, spoiler: During Gameplay in SSB4 on 3DS For Glory\n",
      "id: 363, spoiler: Two Strangers Hug a Woman After Asking for Directions, but Watch What the\n",
      "id: 364, spoiler: Cecily Strong\n",
      "id: 365, spoiler: high maintenance 19 Things You’ll Only Get If You’re High AND HighMain\n",
      "id: 366, spoiler: Arizona lawmakers are pushing to provide elected officials with more privacy as they draft legislation because they say the\n",
      "id: 367, spoiler: more wall than window The real reason your airplane seat is woefully misaligne\n",
      "id: 368, spoiler: the real Springfield is closer to Springfield, Oregon, where Matt Groening is from,\n",
      "id: 369, spoiler: the United House of Prayer Pregnant Dog Lays Lifelessly In A Field\n",
      "id: 370, spoiler: Rocket League The first game to make use of Microsoft’s crossnetwork features would be\n",
      "id: 371, spoiler: The canisters Bruce WayneBatman used have Pb — the abbrevi\n",
      "id: 372, spoiler: Here Are Two Possible Reasons Why You Shiver When You Pee There's Nothing\n",
      "id: 373, spoiler: NASA has just confirmed that a gargantuan milelong asteroid is heading\n",
      "id: 374, spoiler: Where do you see yourself in five years?\n",
      "id: 375, spoiler: Brexit speech was uploaded to Pornhub with a new titleBritain's decision\n",
      "id: 376, spoiler: Pat Patterson\n",
      "id: 377, spoiler: That’s what he does Just puts it out there and then he puts\n",
      "id: 378, spoiler: Yvette Nicole Brown\n",
      "id: 379, spoiler: Florida\n",
      "id: 380, spoiler: When a fan asked Rowling what form Hagrid's Patronus would take –\n",
      "id: 381, spoiler: Missouri the most shocking result so far is in Missouri Missouri the most shocking result\n",
      "id: 382, spoiler: 44 minutes 44 seconds The average time for each couple that is, averaged across\n",
      "id: 383, spoiler: Donald Trump looks around desperately to his left and right, saying Oh there's Rudy\n",
      "id: 384, spoiler: adapt themselves to the shape of her body The antibodies of the film look like w\n",
      "id: 385, spoiler: the holy grail tends to be the ones aiming for a deeper experience\n",
      "id: 386, spoiler: white pepper\n",
      "id: 387, spoiler: a sexual square Then, a week later, heavily circulated rumors\n",
      "id: 388, spoiler: no sense Bizarre things about the Olsen twins that make no sense\n",
      "id: 389, spoiler: keys keys, a little child Luvdisk a child Lu\n",
      "id: 390, spoiler: Elizabeth Taylor Taught Us About The Art Of Love\n",
      "id: 391, spoiler: The Houston Chronicle made its official endorsement known in an article titled These are unsettling times that\n",
      "id: 392, spoiler: quickly regretted it Crack House And Instantly Regretted It Crack\n",
      "id: 393, spoiler: HSBC economists Qu Hongbin and Jing Li have posited in a\n",
      "id: 394, spoiler: water hemlock\n",
      "id: 395, spoiler: The maid's coworker told Kyle and Josh, who have also carried out kind\n",
      "id: 396, spoiler: he won't vote for TrumpA Republican elector in Texas says he will\n",
      "id: 397, spoiler: her severe skin condition Low fat vegan plant based diet nothing processed I would cry\n",
      "id: 398, spoiler: a dead man’s switch had been activated leading many onlookers to\n",
      "id: 399, spoiler: Richard Belzer is leaving Law Order SVU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Function to generate spoilers using the trained model and tokenizer\n",
    "def generate_spoilers(encoded_input, batch_size=1):\n",
    "    with torch.no_grad():\n",
    "        num_samples = len(encoded_input[\"input_ids\"])\n",
    "        decoded_spoilers = []\n",
    "\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            batch_input = {k: v[i:i+batch_size] for k, v in encoded_input.items()}\n",
    "            batch_input = {k: torch.tensor(v).to(model.device) for k, v in batch_input.items()}\n",
    "            output = model.generate(**batch_input)\n",
    "            \n",
    "            # Convert output to a list of tensors\n",
    "            output = [torch.tensor(o).to(model.device) for o in output]\n",
    "\n",
    "            # Perform batch decoding\n",
    "            batch_decoded = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "            decoded_spoilers.extend(batch_decoded)\n",
    "\n",
    "    return decoded_spoilers\n",
    "\n",
    "# Generate spoilers for the test_data using the trained model\n",
    "test_texts = test_data[\"train\"][\"text\"]\n",
    "encoded_input = tokenizer(test_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "batch_size = 4\n",
    "decoded_test_preds = generate_spoilers(encoded_input, batch_size=batch_size)\n",
    "# decoded_test_preds = generate_spoilers(encoded_input)\n",
    "\n",
    "# Print the generated spoilers along with their corresponding ids\n",
    "for spoiler, sample_id in zip(decoded_test_preds, test_data[\"train\"][\"id\"]):\n",
    "    print(f\"id: {sample_id}, spoiler: {spoiler}\")\n",
    "    \n",
    "# Create a DataFrame to store the spoilers and their IDs\n",
    "spoilers_df = pd.DataFrame({\"id\": test_data[\"train\"][\"id\"], \"spoiler\": decoded_test_preds})\n",
    "\n",
    "# Strip leading and trailing whitespaces in the \"spoiler\" column\n",
    "spoilers_df[\"spoiler\"] = spoilers_df[\"spoiler\"].str.strip()\n",
    "\n",
    "# Check for any other representations of null spoilers (e.g., empty strings or NaN)\n",
    "null_spoilers = spoilers_df[spoilers_df[\"spoiler\"].isna() | (spoilers_df[\"spoiler\"] == \"\")]\n",
    "\n",
    "if not null_spoilers.empty:\n",
    "    print(\"Null spoilers found. Replacing alternative representations...\")\n",
    "    print(null_spoilers)\n",
    "    spoilers_df.replace({\"\": np.nan}, inplace=True)  # Replace empty strings with NaN\n",
    "    spoilers_df[\"spoiler\"].fillna(\"No Spoilers Generated\", inplace=True)\n",
    "\n",
    "    # Print rows with null spoilers\n",
    "    print(spoilers_df[spoilers_df[\"spoiler\"].isnull()])\n",
    "    \n",
    "# Save the DataFrame to a CSV file\n",
    "spoilers_df.to_csv(\"generated_spoilers_t5_base_25.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T12:25:04.251304Z",
     "iopub.status.busy": "2023-07-29T12:25:04.245733Z",
     "iopub.status.idle": "2023-07-29T12:25:04.264346Z",
     "shell.execute_reply": "2023-07-29T12:25:04.263499Z",
     "shell.execute_reply.started": "2023-07-29T12:25:04.251265Z"
    }
   },
   "outputs": [],
   "source": [
    "### print the number of trainable parameters in the tranformers model\n",
    "# from transformers import AutoModel, AutoTokenizer, MODEL_NAMES_MAPPING\n",
    "\n",
    "# # Get a list of all available transformer model names\n",
    "# all_model_names = list(MODEL_NAMES_MAPPING.keys())\n",
    "\n",
    "# for model_name in all_model_names:\n",
    "#     try:\n",
    "#         # Load the model\n",
    "#         model_class = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "#         # Count the number of trainable parameters\n",
    "#         num_trainable_params = sum(p.numel() for p in model_class.parameters() if p.requires_grad)\n",
    "\n",
    "#         print(f\"Model: {model_name}\")\n",
    "#         print(f\"Number of trainable parameters: {num_trainable_params}\")\n",
    "#         print(\"=\" * 50)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error loading model {model_name}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
