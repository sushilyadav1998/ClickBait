{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-29T00:37:17.277994Z",
     "iopub.status.busy": "2023-07-29T00:37:17.277299Z",
     "iopub.status.idle": "2023-07-29T00:37:33.038294Z",
     "shell.execute_reply": "2023-07-29T00:37:33.036571Z",
     "shell.execute_reply.started": "2023-07-29T00:37:17.277956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.30.2)\n",
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.16.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.6.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.5.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24954 sha256=06275969c6442a1e66b7563b0d55ff93826f98a9820506faf3d069dcf82acef9\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: rouge-score, evaluate\n",
      "Successfully installed evaluate-0.4.0 rouge-score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "! pip install datasets evaluate transformers rouge-score nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:37:33.050609Z",
     "iopub.status.busy": "2023-07-29T00:37:33.045558Z",
     "iopub.status.idle": "2023-07-29T00:38:10.752933Z",
     "shell.execute_reply": "2023-07-29T00:38:10.751623Z",
     "shell.execute_reply.started": "2023-07-29T00:37:33.050562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.30.2)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.30.2\n",
      "    Uninstalling transformers-4.30.2:\n",
      "      Successfully uninstalled transformers-4.30.2\n",
      "Successfully installed transformers-4.31.0\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.15.5)\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.15.7-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.3)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.31)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.27.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (59.8.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.5.7)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n",
      "Installing collected packages: wandb\n",
      "  Attempting uninstall: wandb\n",
      "    Found existing installation: wandb 0.15.5\n",
      "    Uninstalling wandb-0.15.5:\n",
      "      Successfully uninstalled wandb-0.15.5\n",
      "Successfully installed wandb-0.15.7\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers --upgrade\n",
    "!pip install wandb --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:38:10.755489Z",
     "iopub.status.busy": "2023-07-29T00:38:10.755056Z",
     "iopub.status.idle": "2023-07-29T00:38:12.460525Z",
     "shell.execute_reply": "2023-07-29T00:38:12.459442Z",
     "shell.execute_reply.started": "2023-07-29T00:38:10.755460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.31.0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:38:12.464099Z",
     "iopub.status.busy": "2023-07-29T00:38:12.463529Z",
     "iopub.status.idle": "2023-07-29T00:38:12.469627Z",
     "shell.execute_reply": "2023-07-29T00:38:12.468635Z",
     "shell.execute_reply.started": "2023-07-29T00:38:12.464070Z"
    }
   },
   "outputs": [],
   "source": [
    "# model_checkpoint = \"t5-small\"\n",
    "model_checkpoint = \"facebook/bart-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:38:12.471763Z",
     "iopub.status.busy": "2023-07-29T00:38:12.470969Z",
     "iopub.status.idle": "2023-07-29T00:38:20.370521Z",
     "shell.execute_reply": "2023-07-29T00:38:20.369394Z",
     "shell.execute_reply.started": "2023-07-29T00:38:12.471726Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Masking, LSTM\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:38:20.373151Z",
     "iopub.status.busy": "2023-07-29T00:38:20.371827Z",
     "iopub.status.idle": "2023-07-29T00:38:20.827105Z",
     "shell.execute_reply": "2023-07-29T00:38:20.826012Z",
     "shell.execute_reply.started": "2023-07-29T00:38:20.373122Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset(file_name):\n",
    "    data = []\n",
    "    with open(file_name, encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            example = json.loads(line)\n",
    "            post_text = example['postText'][0]\n",
    "            title = example['targetTitle']\n",
    "            paragraphs = ' '.join(example['targetParagraphs'])\n",
    "            spoiler = example['spoiler'][0]\n",
    "            data.append({'text': post_text + ' - ' + title + paragraphs, 'spoiler': spoiler})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def load_dataset_test(file_name):\n",
    "    data = []\n",
    "    with open(file_name, encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            example = json.loads(line)\n",
    "            post_text = example['postText'][0]\n",
    "            title = example['targetTitle']\n",
    "            id = example['id']\n",
    "            paragraphs = ' '.join(example['targetParagraphs'])\n",
    "            # label = example['tags'][0] if 'tags' in example else None\n",
    "            # if label in ['phrase', 'multi', 'passage']:\n",
    "            data.append({'id': id, 'text': post_text + ' - ' + title + paragraphs})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "test_data = load_dataset_test('/kaggle/input/mscitask1-spoiler-generation/test.jsonl')\n",
    "train_data = load_dataset('/kaggle/input/mscitask1-spoiler-generation/train.jsonl')\n",
    "validation_data = load_dataset('/kaggle/input/mscitask1-spoiler-generation/val.jsonl')\n",
    "# test_data = load_dataset_test('/kaggle/input/clickbait-detection-msci641-s23/test.jsonl')\n",
    "# all_datasets = pd.concat([test_data, train_data, validation_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:38:20.829035Z",
     "iopub.status.busy": "2023-07-29T00:38:20.828634Z",
     "iopub.status.idle": "2023-07-29T00:38:20.845070Z",
     "shell.execute_reply": "2023-07-29T00:38:20.843806Z",
     "shell.execute_reply.started": "2023-07-29T00:38:20.828996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "                                                text  \\\n",
      "0  Wes Welker Wanted Dinner With Tom Brady, But P...   \n",
      "1  NASA sets date for full recovery of ozone hole...   \n",
      "\n",
      "                               spoiler  \n",
      "0  how about that morning we go throw?  \n",
      "1                                 2070  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   id                                               text\n",
      "0   0  He Tackles A Nurse At The Hospital. Then You S...\n",
      "1   1  Why you SHOULD be selfish at work - Why you SH...\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data))\n",
    "print(train_data[:2])\n",
    "print(type(test_data))\n",
    "print(test_data[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:38:20.847183Z",
     "iopub.status.busy": "2023-07-29T00:38:20.846496Z",
     "iopub.status.idle": "2023-07-29T00:38:20.855411Z",
     "shell.execute_reply": "2023-07-29T00:38:20.854351Z",
     "shell.execute_reply.started": "2023-07-29T00:38:20.847142Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = np.array(train_data)\n",
    "validation_data = np.array(validation_data)\n",
    "test_data = np.array(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:38:20.857723Z",
     "iopub.status.busy": "2023-07-29T00:38:20.857035Z",
     "iopub.status.idle": "2023-07-29T00:38:21.318011Z",
     "shell.execute_reply": "2023-07-29T00:38:21.316901Z",
     "shell.execute_reply.started": "2023-07-29T00:38:20.857627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200\n",
      "400\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "characters = ['!','\"','#','$','%','&','(',')','*','+','/',':',';','<','=','>','@','^','`','|','~','\\t','[',']','{','}','\\\\','.','-']\n",
    "for i in range(len(train_data)):\n",
    "    for j in characters:\n",
    "        train_data[i][0] = train_data[i][0].replace(j,\"\")\n",
    "        train_data[i][1] = train_data[i][1].replace(j,\"\")\n",
    "\n",
    "for i in range(len(validation_data)):\n",
    "    for j in characters:\n",
    "        validation_data[i][0] = validation_data[i][0].replace(j,\"\")\n",
    "        validation_data[i][1] = validation_data[i][1].replace(j,\"\")\n",
    "        \n",
    "for i in range(len(test_data)):\n",
    "    for j in characters:\n",
    "        test_data[i][1] = test_data[i][1].replace(j,\"\")\n",
    "\n",
    "        \n",
    "print(len(train_data))\n",
    "print(len(validation_data))\n",
    "print(len(test_data))\n",
    "\n",
    "train_data = pd.DataFrame(train_data, columns=[\"text\", \"spoiler\"])\n",
    "validation_data = pd.DataFrame(validation_data, columns=[\"text\", \"spoiler\"])\n",
    "test_data = pd.DataFrame(test_data, columns=[\"id\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:38:21.323887Z",
     "iopub.status.busy": "2023-07-29T00:38:21.323196Z",
     "iopub.status.idle": "2023-07-29T00:38:21.920170Z",
     "shell.execute_reply": "2023-07-29T00:38:21.919128Z",
     "shell.execute_reply.started": "2023-07-29T00:38:21.323846Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.to_csv('train_data.csv', index=False)\n",
    "validation_data.to_csv('validation_data.csv', index=False)\n",
    "test_data.to_csv('test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:38:21.922170Z",
     "iopub.status.busy": "2023-07-29T00:38:21.921693Z",
     "iopub.status.idle": "2023-07-29T00:38:23.678396Z",
     "shell.execute_reply": "2023-07-29T00:38:23.677454Z",
     "shell.execute_reply.started": "2023-07-29T00:38:21.922117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-644ccf1fd51ef9f3/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "305b278dbd3d47f1ae119c3896ec81ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89f326618554bb6833eb630433afde4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/datasets/packaged_modules/csv/csv.py:154: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n",
      "  csv_file_reader = pd.read_csv(file, iterator=True, dtype=dtype, **self.config.read_csv_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-644ccf1fd51ef9f3/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1941094f05634277b3102e8a1fbec9ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-59d9f84ab7fe13eb/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e8a33d8b8e14a87bdd84618933c72d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d2b431472449439222e3f01d6128be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-59d9f84ab7fe13eb/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/datasets/packaged_modules/csv/csv.py:154: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n",
      "  csv_file_reader = pd.read_csv(file, iterator=True, dtype=dtype, **self.config.read_csv_kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eebba33224c4c82acf13e2766830732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-ce1e83be0e61952b/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13016ba87cc94eed9cb242e5c9cdbe26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "023be512be16493f9c811a87e1e31e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-ce1e83be0e61952b/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/datasets/packaged_modules/csv/csv.py:154: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n",
      "  csv_file_reader = pd.read_csv(file, iterator=True, dtype=dtype, **self.config.read_csv_kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "745054dc1e4c414e82c8546c4922106a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import datasets\n",
    "\n",
    "dataset_file_train = '/kaggle/working/train_data.csv'\n",
    "dataset_file_valid = '/kaggle/working/validation_data.csv'\n",
    "data_file_test = '/kaggle/working/test_data.csv'\n",
    "\n",
    "train_data = load_dataset('csv', data_files=dataset_file_train)\n",
    "val_data = load_dataset('csv', data_files=dataset_file_valid)\n",
    "test_data = load_dataset('csv', data_files=data_file_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:38:23.680681Z",
     "iopub.status.busy": "2023-07-29T00:38:23.680047Z",
     "iopub.status.idle": "2023-07-29T00:38:23.686483Z",
     "shell.execute_reply": "2023-07-29T00:38:23.685538Z",
     "shell.execute_reply.started": "2023-07-29T00:38:23.680644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'spoiler'],\n",
      "        num_rows: 3200\n",
      "    })\n",
      "})\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'spoiler'],\n",
      "        num_rows: 400\n",
      "    })\n",
      "})\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'text'],\n",
      "        num_rows: 400\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_data)\n",
    "print(val_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:38:23.688762Z",
     "iopub.status.busy": "2023-07-29T00:38:23.688104Z",
     "iopub.status.idle": "2023-07-29T00:38:23.705354Z",
     "shell.execute_reply": "2023-07-29T00:38:23.704153Z",
     "shell.execute_reply.started": "2023-07-29T00:38:23.688726Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Wes Welker Wanted Dinner With Tom Brady, But Patriots QB Had Better Idea  Wes Welker Wanted Dinner With Tom Brady, But Patriots QB Had A Better IdeaIt’ll be just like old times this weekend for Tom Brady and Wes Welker Welker revealed Friday morning on a Miami radio station that he contacted Brady because he’ll be in town for Sunday’s game between the New England Patriots and Miami Dolphins at Gillette Stadium It seemed like a perfect opportunity for the two to catch up But Brady’s definition of catching up involves far more than just a meal In fact, it involves some literal catching as the Patriots quarterback looks to stay sharp during his fourgame Deflategate suspension I hit him up to do dinner Saturday night He’s like, ‘I’m going to be flying in from Ann Arbor later after the MichiganColorado football game, but how about that morning we go throw?’  Welker said on WQAM, per The Boston Globe And I’m just sitting there, I’m like, ‘I was just thinking about dinner, but yeah, sure I’ll get over there early and we can throw a little bit’  Welker was one of Brady’s favorite targets for six seasons from 2007 to 2012 It’s understandable him and Brady want to meet with both being in the same area But Brady typically is all business during football season Welker probably should have known what he was getting into when reaching out to his buddy That’s the only thing we really have planned, Welker said of his upcoming workout with Brady It’s just funny I’m sitting there trying to have dinner ‘Hey, get your ass up here and let’s go throw’ I’m like, ‘Aw jeez, man’ He’s going to have me running like 2minute drills in his backyard or something Maybe Brady will put a good word in for Welker down in Foxboro if the former Patriots wide receiver impresses him enough',\n",
       " 'spoiler': 'how about that morning we go throw?'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:38:23.707856Z",
     "iopub.status.busy": "2023-07-29T00:38:23.707168Z",
     "iopub.status.idle": "2023-07-29T00:38:23.718268Z",
     "shell.execute_reply": "2023-07-29T00:38:23.717193Z",
     "shell.execute_reply.started": "2023-07-29T00:38:23.707821Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=5):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:38:23.720803Z",
     "iopub.status.busy": "2023-07-29T00:38:23.719971Z",
     "iopub.status.idle": "2023-07-29T00:38:23.740734Z",
     "shell.execute_reply": "2023-07-29T00:38:23.739473Z",
     "shell.execute_reply.started": "2023-07-29T00:38:23.720765Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spoiler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is No 1 financial regret of older Americans  This is No 1 financial regret of older AmericansMost Americans are filled with regrets — financial regrets Fully three in four, in fact, admit they harbor financial regrets, Fully three in four, in fact, admit they harbor financial regrets, according to a survey of more than 1,000 adults published Tuesday by Bankratecom Their biggest regret not saving for retirement early enough nearly one in five Americans put this in the No 1 spot What’s more, among those 65 and up, 27 said this was the biggest regret, compared with 17 of those aged 30 to 49 Indeed, it is costly to wait A person who starts saving 300 a month for retirement at age 25 assuming a 5 return on investment will have about 450,000 saved by age 65, despite only contributing 144,000 into his retirement account Meanwhile, if that person waits until 35 to save the same amount each month, he will contribute a total of 108,000 toward retirement but only have about 250,000 saved at age 65 If you don’t start saving early enough, you will start to notice that later, says Greg McBride, the chief financial analyst for Bankratecom What’s more, waiting to save only exacerbates the problem of our already paltry nest eggs According to 2015 data from the Employee Benefit Research Institute, fully 28 of workers say they have less than 1,000 saved and 17 have between 1,000 and 9,999 meanwhile, just 14 of workers have 250,000 or more saved © Provided by MarketWatch This is No 1 financial regret of older Americans That’s far too little, according to many financial advisers Guidelines from Fidelity, for example, state that by the age of 30, you should have your entire salary saved by 40, three times your salary saved and, by 50, six times your salary saved</td>\n",
       "      <td>not saving for retirement early enough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pitcher Who Allowed Tim Tebow's Home Run Tweets Funny Response  Pitcher who allowed Tim Tebow's home run tweets funny responseSt Louis Cardinals prospect John Kilichowski will forever be the answer to a trivia question no one thought would exist even two months ago During Wednesday’s instructional league game against the New York Mets, he was the pitcher who allowed a home run to Tim Tebow in Tebow’s first ever professional atbat On the first pitch he saw, Tebow took a highandoutside fastball from Kilichowski and basically tomahawked it over the fence in leftcenter field It was an impressive feat of strength that left Tebow undeniably giddy as he sprinted around the bases and talked to the media after the game It’s just fun, Tebow said It feels good to hit a home run Your first game, you want to win You’re with all your teammates The reception was fun, too View photos Tim Tebow homered off John Kilichowski in his first professional atbat in the instructional league APVanderbilt More That’s one side of the story On the other side, there’s a pitcher whose first claim to fame in baseball is as a footnote in Tim Tebow’s already well established legacy For some, that reality might be a crushing blow to their ego Not Kilichowski though He’s taking the whole thing in stride, even taking to Twitter to joke about the event I thought we agreed you were taking first pitch TimTebow — John Kilichowski JJkilich September 28, 2016 Truth be told, a lot of hitters probably would take that first pitch they saw just to get a feeling for the opposing pitcher It’s not farfetched to believe Kilichowski was expecting that to happen with Tebow But even if he was, that wasn’t a typical grooved fastball to get ahead in the count Tebow beat him, Kilichowski knows it and there’s nothing he can do but own it Tough day for that kid Probably should spend the rest of his instructs focused on locating his fastball down httpstcogVvss6ryFh — John Kilichowski JJkilich September 28, 2016 Kilichowski, 22, was the Cardinals’ 11thround pick in 2016 He comes out of the Vanderbilt program, which has produced a lot of majorleague talent over the past ten years It’s also a school Tebow did his share of damage against on the college gridiron at the University of Florida Given the Cardinals history of drafting wisely, developing players and pushing them to reach their potential, there’s a pretty good chance Wednesday’s home run won’t be the moment that defines Kilichowski’s baseball career But even if it does, his response under these unique circumstances suggests he has the mindset to deal with it More MLB coverage from Yahoo Sports</td>\n",
       "      <td>John Kilichowski</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Researchers Claim DMT Can Connect You To A Parallel Universe  UV Researchers Claim DMT Can Connect You To A Parallel UniverseDimethyltryptamine DMT acclaimed as the most fascinating psychoactive substance yet to be discovered Found in the plants and animals of Earth, DMT exists everywhere in life as we know it, even inside of ourselves Our familiarity with DMT and its chemical properties has improved, but there remains much to be known as to what exactly one’s consciousness is experiencing while the mind is under the effect of DMT, whether it be endogenous or professionally administered In Rick Strassman’s book, DMT The Spirit Molecule, he explores the possibility that the vivid, practically tangible realms visited on DMT may actually be our consciousness receiving access to a parallel plain of existence Similarities in testimonies given by the study volunteers suggest that there may be some validity to this hunch Each patient experiences their own unique journey with personalized details, however, the overall theme of the reports in juxtaposition was reoccurring a realm unlike anything of this existence, encounters with intelligent entities, experiences of death and rebirth, unfamiliar sensations, ego disolution, and so on DMT provides regular, repeated, and reliable access to ‘other’ channels The other planes of existence are always there In fact, they are right here, transmitting all the time But we cannot perceive them because we are not designed to do so our hardwiring keeps us tuned in to Channel Normal – Rick Strassman, MD In a correspondence between Strassman and David Deutsch, British scientist and author of The Fabric of Reality, Deutsch expressed doubt in the likeliness of one’s mind actually connecting to a parallel plain of existence as it would require quantum computing Quantum computing, based on our understanding, requires temperatures near absolute zero in order to take place Strassman proposed that perhaps it is possible that increased levels of DMT in the mind could be the key to a yet to be understood, quantum computation of the mind that is able to take place in our biological structure If it’s true that the DMT experience is actually a quantifiable displacement of one’s consciousness, then the answer to interstellar, intergalactic, even interdimensional exploration may reside inside of us Perhaps with more of its secrets unlocked, Dimethyltryptamine may play a pivotal role in humanity’s understanding of existence A brief overview of the science behind Parallel Universes Sources Strassman, Rick DMT The Spirit Molecule A Doctor’s Revolutionary Research into the Biology of Neardeath and Mystical Experiences Rochester, VT Park Street, 2001 Print</td>\n",
       "      <td>In Rick Strassman’s book, DMT The Spirit Molecule, he explores the possibility that the vivid, practically tangible realms visited on DMT may actually be our consciousness receiving access to a parallel plain of existence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Did Jason Momoa Just Drop A Massive Hint About GOT Season 7?  Did Jason Momoa Just Drop A Massive Hint About GOT Season 7?TheLADbible httpwwwtheladbiblecom httpwwwtheladbiblecomassetsimagesthemelogosvg September 27th 2016 15K Shares We might have to wait until next year for the next season of Game of Thrones but has Jason Momoa just dropped a huge clue about what's in store? There have been rumours about Khal Drogo's return circulating for a while being dead doesn't mean the end in Games of Thrones, ask Jon Snow Now, though, the rumours are definitely intensifying with this photo Jason uploaded to his Instagram account last week Congrats to my kit super proud of him and all the cast and crew congrats Game of thrones you are the best can't wait for the next season Aloha j Back to work A photo posted by Jason Momoa prideofgypsies on Sep 19, 2016 at 520pm PDT A photo posted by Jason Momoa prideofgypsies on Alongside the photo with Kit Harington Snow, Jason wrote Congrats to my kit super proud of him and all the cast and crew congrats Game of thrones you are the best can't wait for the next season Aloha j Back to work' sic Maybe he's getting resurrection tips? However, before we get too excited, the Metro reports that he was actually just taking a break from filming in London and decided to meet up with his old costars in Belfast Credit HBO What do you lads reckon? Would you like to Khal back? Featured image credit HBO</td>\n",
       "      <td>Alongside the photo with Kit Harington Snow, Jason wrote Congrats to my kit super proud of him and all the cast and crew congrats Game of thrones you are the best can't wait for the next season Aloha j Back to work' sic Maybe he's getting resurrection tips?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Here's What Scientists Found When They Opened A Cave That Had Been Isolated For More Than Five Million Years  Here's What Scientists Found When They Opened A Cave That Had Been Isolated For More Than Five Million YearsThe inhabitants of the Movile Cave are like no others The otherworldly conditions of this Romanian cave, just a few miles west from the Black Sea, have been sealed up for around 55 million years Although the air is poisonous and unbearably humid, this cocktail of factors has created a goldmine for biologists Fewer than 100 people have ever delved into the cave, according to BBC Earth  It was only discovered by humans in 1986, when workers of the Socialist Republic of Romania were looking for new ground to build a nuclear power plant Nowadays, it is blocked off by the authorities and only accessible with special permission, although the central caverns are naturally guarded by a series of vertical shafts and narrow limestone tunnels Once in the depths of the cave, the air contains half of the amount of oxygen than usual and is high in carbon dioxide and hydrogen sulfide It is also pitch black and hasn’t seen sunlight for at least 55 million years The location of the cave Google Maps But within this harsh environment, scientists have so far identified 48 species Among the creatures are an array of spiders, water scorpions, pseudoscorpions, centipedes, leeches, and isopods – 33 of which are totally unique to this one cave Most of the creatures in the cave have no vision and lack pigment After all, who needs sight or to be pretty in the pitch darkness? They’re also, on the whole, a spindly bunch, with extralong limbs and antennae that help them navigate in the darkness As if this world was not alien enough, it’s one of the only known ecosystems that relies on chemosynthetic bacteria Most ecosystems use photosynthesis to harness energy However, since there’s no natural sunlight in the cave, the bacteria need to get their energy and carbon directly from chemical reactions, such as the oxidation of sulfide or the oxidation of ammonium Closeup of an Armadillidium sp woodlouse found only in the Movile Cave, Romania Patrick LandmannScience Photo Library But how the animals ended up in the cave and became isolated remains unclear to scientists BBC Earth  They could have simply fallen in and become trapped when the limestone cast dropped, sealing the cave until it was discovered again in 1986 It's very likely that the bacteria have been there a lot longer than five million years, but that the insects became trapped there around that time, J Colin Murrell, a microbiologist from the University of East Anglia, said to They could have simply fallen in and become trapped when the limestone cast dropped, sealing the cave until it was discovered again in 1986 There are still many mysteries that lie deep within the Movile Cave But even after just 30 years of knowing it exists, researchers still have many more inhabitants to discover, some of whom could hold massive insights into evolutionary biology and even the nature of life itself Photo Gallery</td>\n",
       "      <td>an array of spiders, water scorpions, pseudoscorpions, centipedes, leeches, and isopods – 33 of which are totally unique to this one cave</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(train_data[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:38:23.743088Z",
     "iopub.status.busy": "2023-07-29T00:38:23.742687Z",
     "iopub.status.idle": "2023-07-29T00:38:39.565962Z",
     "shell.execute_reply": "2023-07-29T00:38:39.564761Z",
     "shell.execute_reply.started": "2023-07-29T00:38:23.743055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.65.0)\n",
      "Installing collected packages: nltk\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.2.4\n",
      "    Uninstalling nltk-3.2.4:\n",
      "      Successfully uninstalled nltk-3.2.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nltk-3.8.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe6021f0cc948f19c2faa97c650dc49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08cadcafd9c047e0b06bb42d3b512c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "!pip install -U nltk\n",
    "metric = load_metric(\"rouge\")\n",
    "metric_meteor = load_metric(\"meteor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:38:39.569297Z",
     "iopub.status.busy": "2023-07-29T00:38:39.568564Z",
     "iopub.status.idle": "2023-07-29T00:38:39.882716Z",
     "shell.execute_reply": "2023-07-29T00:38:39.881616Z",
     "shell.execute_reply.started": "2023-07-29T00:38:39.569254Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': AggregateScore(low=Score(precision=1.0, recall=1.0, fmeasure=1.0), mid=Score(precision=1.0, recall=1.0, fmeasure=1.0), high=Score(precision=1.0, recall=1.0, fmeasure=1.0)), 'rouge2': AggregateScore(low=Score(precision=1.0, recall=1.0, fmeasure=1.0), mid=Score(precision=1.0, recall=1.0, fmeasure=1.0), high=Score(precision=1.0, recall=1.0, fmeasure=1.0)), 'rougeL': AggregateScore(low=Score(precision=1.0, recall=1.0, fmeasure=1.0), mid=Score(precision=1.0, recall=1.0, fmeasure=1.0), high=Score(precision=1.0, recall=1.0, fmeasure=1.0)), 'rougeLsum': AggregateScore(low=Score(precision=1.0, recall=1.0, fmeasure=1.0), mid=Score(precision=1.0, recall=1.0, fmeasure=1.0), high=Score(precision=1.0, recall=1.0, fmeasure=1.0))}\n",
      "{'meteor': 0.9375}\n"
     ]
    }
   ],
   "source": [
    "fake_preds = [\"hello there\", \"general kenobi\"]\n",
    "fake_labels = [\"hello there\", \"general kenobi\"]\n",
    "print(metric.compute(predictions=fake_preds, references=fake_labels))\n",
    "print(metric_meteor.compute(predictions=fake_preds, references=fake_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:38:39.884824Z",
     "iopub.status.busy": "2023-07-29T00:38:39.884407Z",
     "iopub.status.idle": "2023-07-29T00:38:44.680349Z",
     "shell.execute_reply": "2023-07-29T00:38:44.679224Z",
     "shell.execute_reply.started": "2023-07-29T00:38:39.884789Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e499b328167f4c568c18ce2a3669a3eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "593ffe5fcdbd4bd5acf2b17dedf4911e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f53d6fc47cd475a9f2f6de1c5af46d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c495ff6f4bdf4fc8a556468009799f78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:38:44.683152Z",
     "iopub.status.busy": "2023-07-29T00:38:44.682279Z",
     "iopub.status.idle": "2023-07-29T00:38:44.705789Z",
     "shell.execute_reply": "2023-07-29T00:38:44.704892Z",
     "shell.execute_reply.started": "2023-07-29T00:38:44.683115Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 31414, 6, 42, 65, 3645, 328, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Hello, this one sentence!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:38:44.707511Z",
     "iopub.status.busy": "2023-07-29T00:38:44.707137Z",
     "iopub.status.idle": "2023-07-29T00:38:44.715519Z",
     "shell.execute_reply": "2023-07-29T00:38:44.714309Z",
     "shell.execute_reply.started": "2023-07-29T00:38:44.707483Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[0, 31414, 6, 42, 65, 3645, 328, 2], [0, 713, 16, 277, 3645, 4, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer([\"Hello, this one sentence!\", \"This is another sentence.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:38:44.718315Z",
     "iopub.status.busy": "2023-07-29T00:38:44.717542Z",
     "iopub.status.idle": "2023-07-29T00:38:44.725496Z",
     "shell.execute_reply": "2023-07-29T00:38:44.724278Z",
     "shell.execute_reply.started": "2023-07-29T00:38:44.718279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[0, 31414, 6, 42, 65, 3645, 328, 2], [0, 713, 16, 277, 3645, 4, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer(text_target=[\"Hello, this one sentence!\", \"This is another sentence.\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:38:44.728021Z",
     "iopub.status.busy": "2023-07-29T00:38:44.727111Z",
     "iopub.status.idle": "2023-07-29T00:38:44.735266Z",
     "shell.execute_reply": "2023-07-29T00:38:44.734224Z",
     "shell.execute_reply.started": "2023-07-29T00:38:44.727984Z"
    }
   },
   "outputs": [],
   "source": [
    "if model_checkpoint in [\"t5-small\", \"t5-base\", \"t5-larg\", \"t5-3b\", \"t5-11b\"]:\n",
    "    prefix = \"summarize: \"\n",
    "else:\n",
    "    prefix = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:38:44.739193Z",
     "iopub.status.busy": "2023-07-29T00:38:44.738749Z",
     "iopub.status.idle": "2023-07-29T00:38:44.748189Z",
     "shell.execute_reply": "2023-07-29T00:38:44.747255Z",
     "shell.execute_reply.started": "2023-07-29T00:38:44.739164Z"
    }
   },
   "outputs": [],
   "source": [
    "max_input_length = 1024\n",
    "max_target_length = 128\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    labels = tokenizer(text_target=examples[\"spoiler\"], max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "def preprocess_function_test(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:38:44.749714Z",
     "iopub.status.busy": "2023-07-29T00:38:44.749422Z",
     "iopub.status.idle": "2023-07-29T00:38:44.771416Z",
     "shell.execute_reply": "2023-07-29T00:38:44.770231Z",
     "shell.execute_reply.started": "2023-07-29T00:38:44.749683Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[0, 771, 293, 15565, 5029, 33149, 18171, 590, 1560, 5333, 6, 125, 4314, 8886, 7301, 11238, 28795, 1437, 15590, 15565, 5029, 33149, 18171, 590, 1560, 5333, 6, 125, 4314, 8886, 7301, 83, 11238, 28795, 243, 17, 27, 890, 28, 95, 101, 793, 498, 42, 983, 13, 1560, 5333, 8, 15590, 15565, 5029, 15565, 5029, 1487, 273, 662, 15, 10, 2561, 3188, 1992, 14, 37, 5590, 5333, 142, 37, 17, 27, 890, 28, 11, 1139, 13, 395, 17, 27, 29, 177, 227, 5, 188, 1156, 4314, 8, 2561, 8764, 23, 8205, 13476, 2689, 85, 2551, 101, 10, 1969, 945, 13, 5, 80, 7, 2916, 62, 125, 5333, 17, 27, 29, 8515, 9, 10205, 62, 6890, 444, 55, 87, 95, 10, 5820, 96, 754, 6, 24, 6890, 103, 27856, 10205, 25, 5, 4314, 2525, 1326, 7, 1095, 4406, 148, 39, 237, 2670, 7858, 462, 27586, 877, 5436, 38, 478, 123, 62, 7, 109, 3630, 378, 363, 91, 17, 27, 29, 101, 6, 44, 711, 100, 17, 27, 119, 164, 7, 28, 4731, 11, 31, 3921, 21970, 423, 71, 5, 2293, 39557, 1037, 177, 6, 53, 141, 59, 14, 662, 52, 213, 3211, 116, 17, 27, 1437, 15565, 5029, 26, 15, 305, 1864, 2620, 6, 228, 20, 2278, 10249, 178, 38, 17, 27, 119, 95, 2828, 89, 6, 38, 17, 27, 119, 101, 6, 44, 711, 100, 21, 95, 2053, 59, 3630, 6, 53, 11380, 6, 686, 38, 17, 27, 890, 120, 81, 89, 419, 8, 52, 64, 3211, 10, 410, 828, 17, 27, 1437, 15565, 5029, 21, 65, 9, 5333, 17, 27, 29, 2674, 3247, 13, 411, 2516, 31, 3010, 7, 1125, 85, 17, 27, 29, 19717, 123, 8, 5333, 236, 7, 972, 19, 258, 145, 11, 5, 276, 443, 125, 5333, 3700, 16, 70, 265, 148, 1037, 191, 15565, 5029, 1153, 197, 33, 684, 99, 37, 21, 562, 88, 77, 3970, 66, 7, 39, 23279, 280, 17, 27, 29, 5, 129, 631, 52, 269, 33, 1904, 6, 15565, 5029, 26, 9, 39, 2568, 10533, 19, 5333, 85, 17, 27, 29, 95, 6269, 38, 17, 27, 119, 2828, 89, 667, 7, 33, 3630, 44, 711, 13368, 6, 120, 110, 8446, 62, 259, 8, 905, 17, 27, 29, 213, 3211, 17, 27, 38, 17, 27, 119, 101, 6, 44, 711, 38145, 1236, 27719, 6, 313, 17, 27, 91, 17, 27, 29, 164, 7, 33, 162, 878, 101, 132, 4530, 13553, 11, 39, 12284, 50, 402, 5359, 5333, 40, 342, 10, 205, 2136, 11, 13, 15565, 5029, 159, 11, 2063, 9195, 114, 5, 320, 4314, 1810, 4797, 13113, 293, 123, 615, 2], [0, 34665, 3880, 1248, 13, 455, 2752, 9, 34011, 4683, 1437, 22933, 96, 384, 13930, 43262, 3015, 23088, 598, 5293, 6583, 16505, 870, 291, 3083, 6109, 844, 3083, 16, 16383, 62, 7, 28, 10, 372, 76, 13, 8133, 3875, 280, 18, 77, 6109, 4211, 32, 15924, 5, 4683, 11, 5, 34011, 10490, 429, 1747, 146, 10, 455, 2752, 11161, 585, 49, 6427, 6, 11, 1285, 7, 97, 4139, 6, 11, 10, 5209, 307, 148, 5, 1013, 470, 4177, 37846, 1332, 529, 11, 764, 2659, 20, 165, 9, 4211, 4010, 1415, 23, 5, 4747, 15229, 9, 5, 34011, 4683, 6, 61, 34, 9679, 11, 258, 1836, 8, 5581, 187, 5, 3133, 9, 5, 5817, 30463, 11, 11735, 20, 1288, 4968, 63, 31633, 1203, 5257, 749, 31, 634, 8321, 6, 101, 36846, 1116, 6487, 368, 1975, 271, 16830, 230, 5268, 29, 6, 14, 1108, 159, 88, 32457, 11, 5, 2853, 5466, 8, 4798, 5, 34011, 10490, 252, 303, 14, 6, 150, 1389, 9, 32457, 11, 5, 5466, 33, 5329, 8065, 25, 10, 898, 9, 5, 11883, 6, 24, 18, 350, 1010, 7, 3318, 106, 7, 10, 12732, 34011, 10490, 384, 13930, 6538, 19, 2735, 911, 8, 10, 2514, 746, 1280, 9, 34011, 32, 45, 4784, 1283, 9, 2752, 18297, 7, 5, 421, 32457, 2991, 6, 6470, 13893, 4134, 9, 6109, 18, 32603, 5374, 13275, 824, 2002, 11, 10, 433, 7515, 280, 15480, 16, 101, 667, 7, 1346, 99, 18, 1593, 19, 110, 512, 18, 3819, 396, 10201, 5, 9659, 2978, 6, 5, 4211, 679, 5, 144, 485, 34011, 4683, 1022, 6, 217, 258, 5, 1154, 4683, 655, 6, 11, 3503, 6, 8, 65, 9, 5, 15654, 6538, 6, 11, 1125, 6, 32, 4212, 528, 7, 1650, 8776, 2372, 33, 5, 1460, 7, 517, 34011, 11, 739, 20631, 6, 4296, 8890, 5, 4683, 103, 107, 6, 150, 4551, 7, 1803, 24, 11, 643, 497, 5, 1151, 6, 24, 16, 2372, 8, 3971, 14, 32, 269, 10568, 141, 380, 5, 34011, 4683, 16, 6, 13893, 4134, 174, 5, 3295, 3561, 36260, 690, 1650, 16, 421, 7, 28, 5, 41546, 3724, 11, 5, 34011, 4683, 18, 1836, 454, 10380, 6, 23, 61, 477, 230, 5268, 29, 40, 33, 1882, 615, 25, 10, 898, 9, 5, 5817, 30463, 7, 555, 20228, 870, 291, 3083, 6, 959, 6, 5, 34011, 4683, 16, 421, 7, 33, 156, 10, 455, 2752, 85, 17, 27, 29, 45, 164, 7, 28, 10, 6921, 3068, 6, 13893, 4134, 13335, 5, 1287, 1422, 1513, 345, 40, 28, 103, 24271, 11, 5, 921, 6, 53, 1374, 5, 2904, 16, 14659, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[0, 9178, 59, 14, 662, 52, 213, 3211, 116, 2], [0, 844, 3083, 2]]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(preprocess_function(train_data[:1]))\n",
    "# len(preprocess_function(train_data[:1])[0]['input_ids'][0])\n",
    "preprocess_function(train_data['train'][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:38:44.774861Z",
     "iopub.status.busy": "2023-07-29T00:38:44.774590Z",
     "iopub.status.idle": "2023-07-29T00:38:44.789156Z",
     "shell.execute_reply": "2023-07-29T00:38:44.788295Z",
     "shell.execute_reply.started": "2023-07-29T00:38:44.774836Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[0, 894, 255, 2990, 1634, 83, 25651, 497, 20, 2392, 1892, 370, 4250, 653, 18, 374, 20, 21607, 4130, 598, 28595, 1437, 21361, 25651, 5811, 6629, 5818, 520, 832, 22733, 23000, 1536, 91, 2615, 12192, 14003, 83, 10927, 2596, 1779, 47, 206, 59, 110, 205, 964, 6, 171, 383, 283, 7, 1508, 141, 35063, 301, 74, 28, 396, 106, 6, 141, 51, 146, 47, 7923, 8, 6675, 77, 47, 240, 24, 6, 8, 141, 51, 32, 89, 7, 323, 47, 11, 143, 1068, 370, 189, 190, 1394, 2512, 5, 864, 93, 99, 74, 38, 109, 13, 106, 11, 671, 116, 286, 706, 180, 279, 4572, 11271, 1873, 260, 6, 5, 1948, 16, 2007, 89, 16, 1622, 117, 3000, 7, 99, 37, 74, 109, 13, 39, 964, 407, 6, 77, 39, 23279, 6937, 16052, 329, 1722, 6, 10, 883, 180, 279, 9008, 23, 15903, 404, 6290, 11, 3339, 13399, 6, 12031, 6, 303, 1003, 11, 240, 9, 10, 12855, 6, 11271, 1873, 260, 399, 17, 27, 90, 21587, 7, 465, 66, 114, 37, 115, 8253, 65, 9, 39, 287, 24, 1224, 66, 6, 37, 21, 10, 914, 91, 1276, 7, 2755, 39, 1441, 19, 5, 205, 340, 6, 8, 222, 98, 11, 5, 144, 3997, 169, 96, 42, 3722, 7200, 6, 11271, 1873, 260, 5792, 88, 5, 1098, 147, 16052, 329, 1722, 1364, 91, 34, 22475, 8, 10, 1203, 11, 865, 14, 7005, 6, 30689, 20987, 240, 9, 10, 12855, 6, 236, 4318, 116, 85, 1302, 101, 5, 664, 313, 16, 1341, 5, 11248, 1334, 20, 1151, 16052, 329, 1722, 3681, 123, 6, 37, 26014, 6383, 159, 88, 6941, 91, 64, 6254, 679, 39, 205, 6620, 45, 129, 473, 37, 120, 10, 12855, 6, 53, 37, 2215, 14, 37, 67, 34, 10, 372, 1441, 54, 40, 28, 30, 39, 526, 149, 7992, 8, 7174, 20, 4085, 9, 301, 8, 5, 4085, 9, 9330, 32, 258, 33292, 2], [0, 7608, 47, 41814, 28, 20462, 23, 173, 1437, 2612, 47, 41814, 28, 20462, 23, 173, 10310, 154, 643, 40, 483, 7, 128, 20557, 39533, 7403, 995, 108, 8, 64, 1880, 110, 756, 170, 214, 460, 145, 4446, 7, 244, 643, 137, 52, 244, 4288, 178, 11, 5, 7637, 2057, 110, 782, 137, 167, 9, 110, 4025, 16, 747, 450, 25, 20462, 5759, 125, 92, 557, 161, 145, 1403, 1672, 23, 173, 64, 124, 7051, 19506, 23, 5, 5623, 9, 110, 308, 19715, 8357, 110, 778, 9, 251, 1279, 1282, 96, 41, 1566, 13, 20, 8412, 2090, 5872, 6, 3990, 24735, 835, 9, 5, 589, 9, 4367, 3097, 6, 925, 3086, 5980, 8, 3990, 24735, 1806, 17909, 9338, 21826, 1223, 1610, 459, 5393, 5, 128, 20557, 39533, 7403, 995, 108, 252, 679, 14, 1403, 16337, 23, 173, 3315, 7, 30567, 6, 8, 30829, 747, 15774, 5, 82, 47, 3833, 7, 244, 128, 13863, 821, 10744, 32, 5, 144, 5130, 82, 11, 2665, 6, 51, 17, 27, 241, 67, 23, 5, 3968, 810, 13, 7403, 995, 3934, 5, 7601, 875, 11, 20, 8412, 2090, 5872, 128, 1779, 51, 218, 17, 27, 90, 1744, 1235, 6, 49, 3227, 11, 643, 64, 1303, 106, 7, 619, 40894, 8, 36239, 6796, 6, 1136, 639, 11, 49, 173, 1175, 6, 8, 652, 55, 3992, 8, 3050, 23, 184, 3934, 51, 26, 96, 49, 855, 43179, 557, 6, 7601, 925, 5980, 8, 427, 1223, 1610, 459, 8069, 10, 1186, 9, 1315, 509, 414, 278, 376, 31, 10, 892, 2964, 19, 55, 87, 3675, 2948, 11, 1304, 1328, 5, 382, 497, 5, 386, 9, 5, 76, 51, 553, 106, 1142, 59, 49, 1548, 7, 1903, 643, 2667, 5274, 1220, 5, 7601, 7, 7006, 141, 157, 49, 521, 74, 109, 11, 49, 15734, 23, 5, 253, 9, 5, 76, 1398, 16, 10, 7728, 864, 31, 49, 1296, 6, 5304, 11, 2090, 9203, 112, 7987, 405, 1496, 1437, 224, 4420, 77, 24, 3510, 144, 132, 12192, 11, 10, 169, 14, 16, 11, 110, 308, 773, 8, 36740, 110, 308, 1007, 1915, 155, 1599, 75, 28, 6023, 7, 9115, 173, 7, 97, 82, 77, 47, 218, 75, 33, 86, 204, 37522, 4591, 110, 913, 1437, 356, 13, 1319, 7, 244, 171, 82, 11, 10, 881, 12433, 195, 25390, 14263, 5491, 9, 86, 7, 1311, 1195, 87, 608, 24, 70, 5, 86, 85, 581, 146, 47, 55, 25284, 22389, 8, 2375, 231, 1437, 20865, 82, 54, 129, 185, 1437, 51, 581, 15160, 110, 1007, 4253, 1437, 8412, 2090, 5872, 15467, 14, 47, 214, 5307, 10, 37639, 1380, 6, 8, 47, 348, 20792, 7, 1095, 71, 334, 65, 183, 10, 186, 7, 244, 65, 9, 110, 521, 6, 2618, 6, 1477, 39, 2969, 9, 37639, 91, 6990, 114, 47, 581, 67, 244, 39, 1441, 7056, 6, 54, 965, 75, 11, 110, 1380, 653, 74, 47, 109, 116, 10, 22557, 10, 2559, 71, 8813, 1852, 7, 244, 7056, 6, 98, 47, 64, 357, 1346, 39, 1736, 782, 741, 9318, 1459, 7056, 7, 2662, 11, 15, 110, 37639, 5453, 19, 2618, 740, 11378, 2618, 14, 24, 18, 2579, 14, 37, 1072, 7, 244, 7056, 6, 53, 37, 269, 782, 7, 1056, 15, 39, 308, 173, 11, 645, 7, 2916, 62, 385, 11378, 2618, 14, 7056, 197, 1394, 39, 308, 3254, 13, 244, 34277, 6, 5, 12384, 19, 2948, 54, 7173, 10, 222, 5, 2373, 11, 49, 253, 9, 76, 15734, 20, 2948, 54, 4371, 1235, 8, 58, 540, 1403, 1672, 300, 49, 521, 357, 4863, 128, 39762, 1672, 15969, 17067, 1235, 667, 7, 244, 961, 19, 358, 2069, 3934, 5, 7601, 26, 96, 5, 253, 6, 51, 58, 9055, 5, 182, 521, 51, 770, 7, 244, 1491, 129, 11, 5307, 6, 53, 1403, 1672, 82, 6297, 144, 11, 28717, 8, 465, 1235, 22866, 11, 28665, 8, 3276, 7, 5445, 49, 308, 1175, 25, 10, 898, 2667, 557, 67, 969, 82, 54, 1744, 49, 308, 86, 64, 492, 5, 144, 251, 1279, 5883, 2667, 173, 924, 24, 18, 59, 18442, 86, 98, 77, 47, 244, 97, 82, 47, 218, 75, 278, 2512, 124, 11, 5, 609, 925, 5980, 8, 427, 1223, 1610, 459, 3922, 14, 47, 240, 7, 2145, 130, 762, 383, 77, 1311, 7, 97, 82, 128, 9442, 16801, 59, 141, 47, 244, 6, 77, 47, 244, 6, 8, 2661, 47, 244, 108, 440, 65, 64, 28, 577, 70, 5, 86, 7, 244, 97, 82, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_function_test(test_data['train'][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:38:44.791081Z",
     "iopub.status.busy": "2023-07-29T00:38:44.790449Z",
     "iopub.status.idle": "2023-07-29T00:38:44.796306Z",
     "shell.execute_reply": "2023-07-29T00:38:44.795456Z",
     "shell.execute_reply.started": "2023-07-29T00:38:44.791044Z"
    }
   },
   "outputs": [],
   "source": [
    "# temp_var = preprocess_function(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:38:44.797426Z",
     "iopub.status.busy": "2023-07-29T00:38:44.797137Z",
     "iopub.status.idle": "2023-07-29T00:38:54.449172Z",
     "shell.execute_reply": "2023-07-29T00:38:54.448012Z",
     "shell.execute_reply.started": "2023-07-29T00:38:44.797381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.dataset_dict.DatasetDict'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c5b5f2bb37405892862700e417e584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "509611f1235345d6ab8f4c820547c08c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdee7f774d6a43a4b477970e22afe2b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(type(train_data))\n",
    "\n",
    "\n",
    "# train_data_tokenized = preprocess_function(train_data)\n",
    "# test_data_tokenized = preprocess_function_test(test_data)\n",
    "# validation_data_tokenized = preprocess_function(validation_data)\n",
    "\n",
    "train_datasets = train_data.map(preprocess_function, batched=True)\n",
    "validation_datasets = val_data.map(preprocess_function, batched=True)\n",
    "test_datasets = test_data.map(preprocess_function_test, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:38:54.456079Z",
     "iopub.status.busy": "2023-07-29T00:38:54.455769Z",
     "iopub.status.idle": "2023-07-29T00:38:54.462331Z",
     "shell.execute_reply": "2023-07-29T00:38:54.459571Z",
     "shell.execute_reply.started": "2023-07-29T00:38:54.456050Z"
    }
   },
   "outputs": [],
   "source": [
    "# validation_data_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:38:54.464563Z",
     "iopub.status.busy": "2023-07-29T00:38:54.464136Z",
     "iopub.status.idle": "2023-07-29T00:38:54.510419Z",
     "shell.execute_reply": "2023-07-29T00:38:54.509500Z",
     "shell.execute_reply.started": "2023-07-29T00:38:54.464495Z"
    }
   },
   "outputs": [],
   "source": [
    "# from datasets import Dataset, DatasetDict\n",
    "# # train_data_tokenized = train_data_tokenized\n",
    "# # validation_data_tokenized = validation_data_tokenized\n",
    "# # test_data_tokenized = test_data_tokenized\n",
    "\n",
    "# # Creating the DatasetDict\n",
    "# train_dataset_dict = DatasetDict({\n",
    "#     'train': train_data_tokenized\n",
    "# })\n",
    "\n",
    "# validation_dataset_dict = DatasetDict({\n",
    "#     'validation': validation_data_tokenized\n",
    "# })\n",
    "\n",
    "# # Printing the dataset_dict\n",
    "# # print(dataset_dict['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:38:54.514432Z",
     "iopub.status.busy": "2023-07-29T00:38:54.514083Z",
     "iopub.status.idle": "2023-07-29T00:38:54.521384Z",
     "shell.execute_reply": "2023-07-29T00:38:54.520408Z",
     "shell.execute_reply.started": "2023-07-29T00:38:54.514398Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(validation_dataset_dict['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:38:54.523667Z",
     "iopub.status.busy": "2023-07-29T00:38:54.523101Z",
     "iopub.status.idle": "2023-07-29T00:39:01.225137Z",
     "shell.execute_reply": "2023-07-29T00:39:01.223800Z",
     "shell.execute_reply.started": "2023-07-29T00:38:54.523629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b8f13a0920948139e9a2c5d5ab5784d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "\n",
    "# Load model directly\n",
    "# from transformers import AutoModel\n",
    "# model_longformer = AutoModel.from_pretrained(\"allenai/longformer-base-4096\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:39:01.227498Z",
     "iopub.status.busy": "2023-07-29T00:39:01.227039Z",
     "iopub.status.idle": "2023-07-29T00:39:01.324405Z",
     "shell.execute_reply": "2023-07-29T00:39:01.323411Z",
     "shell.execute_reply.started": "2023-07-29T00:39:01.227457Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 4    #for T5-small it is 16, for bart base, I am keeping it 4\n",
    "gradient_accumulation_steps = 4  # Use gradient accumulation to effectively increase the batch size\n",
    "\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-finetuned-xsum\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,    #2e-5 or any value can be used here\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,  # Add gradient accumulation\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=25,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:39:01.326372Z",
     "iopub.status.busy": "2023-07-29T00:39:01.325947Z",
     "iopub.status.idle": "2023-07-29T00:39:01.331542Z",
     "shell.execute_reply": "2023-07-29T00:39:01.330413Z",
     "shell.execute_reply.started": "2023-07-29T00:39:01.326321Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "# data_collator_longformer = DataCollatorForSeq2Seq(tokenizer, model=model_longformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:39:01.333790Z",
     "iopub.status.busy": "2023-07-29T00:39:01.333295Z",
     "iopub.status.idle": "2023-07-29T00:39:01.348195Z",
     "shell.execute_reply": "2023-07-29T00:39:01.347422Z",
     "shell.execute_reply.started": "2023-07-29T00:39:01.333753Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "#     # Round numeric values in the \"result\" dictionary\n",
    "#     rounded_result = {k: round(float(v), 4) if isinstance(v, (int, float)) else v for k, v in result.items()}\n",
    "#     rounded_result_meteor = {k: round(float(v), 4) if isinstance(v, (int, float)) else v for k, v in result_meteor.items()}\n",
    "    \n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    # Note that other metrics may not have a `use_aggregator` parameter\n",
    "    # and thus will return a list, computing a metric for each sentence.\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True, use_aggregator=True)\n",
    "    result_meteor = metric_meteor.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    # Convert tuples to strings to avoid TypeError during rounding\n",
    "    result = {key: str(value) if isinstance(value, tuple) else value for key, value in result.items()}\n",
    "    result_meteor = {key: str(value) if isinstance(value, tuple) else value for key, value in result_meteor.items()}\n",
    "    \n",
    "    # Add mean generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "#     # Round numeric values in the \"result\" dictionary\n",
    "#     rounded_result = {k: round(float(v), 4) if isinstance(v, (int, float)) else v for k, v in result.items()}\n",
    "#     rounded_result_meteor = {k: round(float(v), 4) if isinstance(v, (int, float)) else v for k, v in result_meteor.items()}\n",
    "    \n",
    "    result = {key: str(value) if isinstance(value, tuple) else value for key, value in result.items()}\n",
    "    result_meteor = {key: str(value) if isinstance(value, tuple) else value for key, value in result_meteor.items()}\n",
    "    \n",
    "    merged_result = {**result, **result_meteor}\n",
    "    \n",
    "    merged_result = {key: str(value) if isinstance(value, tuple) else value for key, value in merged_result.items()}\n",
    "\n",
    "    return merged_result\n",
    "#     return rounded_result, rounded_result_meteor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:39:01.350308Z",
     "iopub.status.busy": "2023-07-29T00:39:01.349643Z",
     "iopub.status.idle": "2023-07-29T00:39:01.364686Z",
     "shell.execute_reply": "2023-07-29T00:39:01.363565Z",
     "shell.execute_reply.started": "2023-07-29T00:39:01.350274Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics_meteor(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "\n",
    "    # Note that other metrics may not have a `use_aggregator` parameter\n",
    "    # and thus will return a list, computing a metric for each sentence.\n",
    "    result = metric_meteor.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "    # Convert tuples to strings to avoid TypeError during rounding\n",
    "    result = {key: str(value) if isinstance(value, tuple) else value for key, value in result.items()}\n",
    "\n",
    "    # Add mean generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    # Round numeric values in the \"result\" dictionary\n",
    "    rounded_result = {k: round(float(v), 4) if isinstance(v, (int, float)) else v for k, v in result.items()}\n",
    "\n",
    "    return rounded_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:39:01.366643Z",
     "iopub.status.busy": "2023-07-29T00:39:01.366288Z",
     "iopub.status.idle": "2023-07-29T00:39:07.190830Z",
     "shell.execute_reply": "2023-07-29T00:39:07.189749Z",
     "shell.execute_reply.started": "2023-07-29T00:39:01.366608Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_datasets['train'],\n",
    "    eval_dataset=validation_datasets['train'],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# trainer_longformer = Seq2SeqTrainer(\n",
    "#     model_longformer,\n",
    "#     args,\n",
    "#     train_dataset=train_datasets['train'],\n",
    "#     eval_dataset=validation_datasets['train'],\n",
    "#     data_collator=data_collator_longformer,\n",
    "#     tokenizer=tokenizer,\n",
    "#     compute_metrics=compute_metrics_meteor\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T00:39:07.193010Z",
     "iopub.status.busy": "2023-07-29T00:39:07.192411Z",
     "iopub.status.idle": "2023-07-29T02:51:41.752188Z",
     "shell.execute_reply": "2023-07-29T02:51:41.751165Z",
     "shell.execute_reply.started": "2023-07-29T00:39:07.192973Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20230729_004112-hx8bynje</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sushilkumar-yadav/huggingface/runs/hx8bynje' target=\"_blank\">amber-butterfly-11</a></strong> to <a href='https://wandb.ai/sushilkumar-yadav/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sushilkumar-yadav/huggingface' target=\"_blank\">https://wandb.ai/sushilkumar-yadav/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sushilkumar-yadav/huggingface/runs/hx8bynje' target=\"_blank\">https://wandb.ai/sushilkumar-yadav/huggingface/runs/hx8bynje</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2500/2500 2:09:47, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Meteor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.773928</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.3858696251511969, recall=0.30656133605023944, fmeasure=0.2930978773337898), mid=Score(precision=0.4253674649492664, recall=0.3444054404779554, fmeasure=0.3275592529612438), high=Score(precision=0.4677125103654516, recall=0.38500687224265884, fmeasure=0.365721580932506))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.24214207788739042, recall=0.18706447991188888, fmeasure=0.18766513398847134), mid=Score(precision=0.2831912115662116, recall=0.2241876822504651, fmeasure=0.22111990034025386), high=Score(precision=0.32786299013486503, recall=0.2628721757112617, fmeasure=0.2584090826596185))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.3815013556245633, recall=0.2999360985220592, fmeasure=0.2873262573504971), mid=Score(precision=0.4219155149384928, recall=0.3406936470834161, fmeasure=0.32408506544809024), high=Score(precision=0.4674961848608909, recall=0.3839927539767308, fmeasure=0.36424439249106016))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.38022833833343933, recall=0.3007668315991155, fmeasure=0.28725327026465575), mid=Score(precision=0.4210773025993614, recall=0.34306195420129165, fmeasure=0.32470125118523024), high=Score(precision=0.4632209041214096, recall=0.3837490292378207, fmeasure=0.3619812400445019))</td>\n",
       "      <td>9.337500</td>\n",
       "      <td>0.267234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.721358</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4448944972154074, recall=0.366952249041475, fmeasure=0.3615825212274586), mid=Score(precision=0.4856517078713771, recall=0.4073541315329049, fmeasure=0.39992784360286715), high=Score(precision=0.5285165320688299, recall=0.449265006691097, fmeasure=0.43976172801021246))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.28438278544372303, recall=0.22653058957244618, fmeasure=0.22584089190913395), mid=Score(precision=0.32403300865800866, recall=0.2641194340080197, fmeasure=0.2631265365693024), high=Score(precision=0.3705025128517317, recall=0.30538313598234257, fmeasure=0.3028580149433679))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4354552567020398, recall=0.3562285642520104, fmeasure=0.3514073649195632), mid=Score(precision=0.4786662258289096, recall=0.4019534179069576, fmeasure=0.3942764131062766), high=Score(precision=0.5263722404484811, recall=0.44634928671530255, fmeasure=0.43726595892300407))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4354316057920838, recall=0.36217305776968356, fmeasure=0.3535927568015278), mid=Score(precision=0.4789899734660763, recall=0.4030304667618776, fmeasure=0.39511025051717785), high=Score(precision=0.5234440393807581, recall=0.44679042422619447, fmeasure=0.43658954167081543))</td>\n",
       "      <td>9.322500</td>\n",
       "      <td>0.318590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.695293</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4200627592638163, recall=0.38615545648148436, fmeasure=0.36213540606789296), mid=Score(precision=0.4637507777149322, recall=0.4277983257466318, fmeasure=0.4005285653051624), high=Score(precision=0.5065111370196387, recall=0.467163427834517, fmeasure=0.4377027026825564))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.2677809065934067, recall=0.23627452471313407, fmeasure=0.22494662903687943), mid=Score(precision=0.30651807393994895, recall=0.273717863688771, fmeasure=0.260313906679952), high=Score(precision=0.3497433371316185, recall=0.311677049111372, fmeasure=0.2962463114621969))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4110186929951176, recall=0.3791109743830138, fmeasure=0.3536520283319849), mid=Score(precision=0.4564787404180788, recall=0.42152390157594294, fmeasure=0.39459869445330775), high=Score(precision=0.4982534745942374, recall=0.4634312264885589, fmeasure=0.4331629362780169))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.40956634400117836, recall=0.3779011149791976, fmeasure=0.35340049003543145), mid=Score(precision=0.4561680497811013, recall=0.4217313664678223, fmeasure=0.3952183373785083), high=Score(precision=0.49763545404758636, recall=0.46560865483214603, fmeasure=0.4373469955137082))</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>0.326591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.694027</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4453106193387904, recall=0.39392190100134705, fmeasure=0.3787753829984203), mid=Score(precision=0.49012643585989163, recall=0.43476685584471636, fmeasure=0.41872345041152126), high=Score(precision=0.5333260284649989, recall=0.47804952107710436, fmeasure=0.4586638301656301))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.28819420839577103, recall=0.2531287083149487, fmeasure=0.24379964892748984), mid=Score(precision=0.32943316232378733, recall=0.28964504847019046, fmeasure=0.27985467100473327), high=Score(precision=0.37403972581238204, recall=0.3321498944157027, fmeasure=0.320094530687467))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.44019152901326614, recall=0.38504795110029033, fmeasure=0.37109153676901663), mid=Score(precision=0.4836864862057876, recall=0.4290365078363552, fmeasure=0.41469968996702344), high=Score(precision=0.5257079420783465, recall=0.47325724783860046, fmeasure=0.4546909707886545))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4399305032334905, recall=0.3893545091456042, fmeasure=0.3725200049954087), mid=Score(precision=0.4836184213050021, recall=0.43044077120481006, fmeasure=0.41424643276173606), high=Score(precision=0.525666730415214, recall=0.47209663388583933, fmeasure=0.45456824236073357))</td>\n",
       "      <td>10.275000</td>\n",
       "      <td>0.346599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.760400</td>\n",
       "      <td>0.699629</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4508669381833445, recall=0.38977382709233227, fmeasure=0.38200070766623845), mid=Score(precision=0.49190837552969924, recall=0.4308824222394188, fmeasure=0.4198652041349976), high=Score(precision=0.5370005239093014, recall=0.4728774091045095, fmeasure=0.4604105754991434))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.2952308462370962, recall=0.25117651472121066, fmeasure=0.24700843393561275), mid=Score(precision=0.3391925505050506, recall=0.2900938471466885, fmeasure=0.28672888033464095), high=Score(precision=0.38661351356976353, recall=0.3290757236836538, fmeasure=0.3259688000711312))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.44430419151416406, recall=0.3807097983861289, fmeasure=0.37540757357400195), mid=Score(precision=0.4861313848528922, recall=0.42583367025071517, fmeasure=0.4169105508596428), high=Score(precision=0.5282730220249522, recall=0.46809489734029025, fmeasure=0.45731268683456133))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4416539898418575, recall=0.3821222320043674, fmeasure=0.373003831894518), mid=Score(precision=0.4859275380461041, recall=0.4261297941354337, fmeasure=0.4170826467146459), high=Score(precision=0.5306223212194258, recall=0.4683396560744519, fmeasure=0.4568717037197165))</td>\n",
       "      <td>10.142500</td>\n",
       "      <td>0.341648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.760400</td>\n",
       "      <td>0.716021</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.43985698550326324, recall=0.39625329763783557, fmeasure=0.3831017434605048), mid=Score(precision=0.48343049842314567, recall=0.43926672699036207, fmeasure=0.4228229129128428), high=Score(precision=0.526859666308977, recall=0.48361080077614416, fmeasure=0.46271221760138825))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.30322354598526485, recall=0.2736156279591297, fmeasure=0.26510875044829646), mid=Score(precision=0.34378770361582867, recall=0.3116683969884738, fmeasure=0.3009702774401807), high=Score(precision=0.38680319628288373, recall=0.3502693365860512, fmeasure=0.34094299377442455))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4339624671437632, recall=0.3903317328104224, fmeasure=0.3755351102083819), mid=Score(precision=0.47735083421480495, recall=0.43529222510352694, fmeasure=0.4186737668849265), high=Score(precision=0.5226187910078075, recall=0.4783145979944922, fmeasure=0.45974306699816353))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4327842451716994, recall=0.39280486469560705, fmeasure=0.3767552967954367), mid=Score(precision=0.4771109300217755, recall=0.43530094826897014, fmeasure=0.4183268625320519), high=Score(precision=0.5206189931443147, recall=0.4781874044419085, fmeasure=0.458885541002324))</td>\n",
       "      <td>10.445000</td>\n",
       "      <td>0.358281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.760400</td>\n",
       "      <td>0.723212</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.44954798658245343, recall=0.3993765102210907, fmeasure=0.3847317463287094), mid=Score(precision=0.4927776841214341, recall=0.44063891109965286, fmeasure=0.42391693715169754), high=Score(precision=0.5343846081512444, recall=0.48453110102651337, fmeasure=0.463676960483813))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.3032234178148241, recall=0.26470692027104487, fmeasure=0.2578603406656447), mid=Score(precision=0.34316821199633707, recall=0.3029442294770046, fmeasure=0.2930835303495837), high=Score(precision=0.38808602976884204, recall=0.3429886925636225, fmeasure=0.3313641836628815))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4443352538239947, recall=0.3899220916202348, fmeasure=0.37511601046094095), mid=Score(precision=0.48445853503114544, recall=0.43368973937999167, fmeasure=0.41743387303543344), high=Score(precision=0.5312510569444852, recall=0.4787680816868685, fmeasure=0.46188571305985604))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.43896485076402353, recall=0.39058027010563034, fmeasure=0.37450507492829666), mid=Score(precision=0.486132466797908, recall=0.4349747555337993, fmeasure=0.4190333734256221), high=Score(precision=0.5267683308776601, recall=0.47851247948513903, fmeasure=0.4590891386525202))</td>\n",
       "      <td>10.330000</td>\n",
       "      <td>0.353183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.760400</td>\n",
       "      <td>0.717607</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4449786923860452, recall=0.4012477124320868, fmeasure=0.3869916924992929), mid=Score(precision=0.4888703983924573, recall=0.44379089987583387, fmeasure=0.42657010131687123), high=Score(precision=0.5324522214101257, recall=0.4858802272170914, fmeasure=0.4670408901621352))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.29300253427128437, recall=0.2594138902862056, fmeasure=0.25127902258121687), mid=Score(precision=0.3342766192141192, recall=0.300013887876518, fmeasure=0.2881851552220536), high=Score(precision=0.37738456439393936, recall=0.33954003342429095, fmeasure=0.32647420638657315))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4391754104249509, recall=0.39522424023040265, fmeasure=0.38128262641739313), mid=Score(precision=0.4797792617921295, recall=0.43779796235219987, fmeasure=0.4202279882287337), high=Score(precision=0.5253338502133078, recall=0.4823408269409755, fmeasure=0.46349960114122346))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4371258485234128, recall=0.3972535206995124, fmeasure=0.37987488268842495), mid=Score(precision=0.48140621204775624, recall=0.4389726803041634, fmeasure=0.42225036415376516), high=Score(precision=0.5235859643114238, recall=0.4830477073209685, fmeasure=0.4643781183171954))</td>\n",
       "      <td>10.452500</td>\n",
       "      <td>0.351983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.760400</td>\n",
       "      <td>0.744307</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.473961947493887, recall=0.4011582665396792, fmeasure=0.39749875099671533), mid=Score(precision=0.5150308285464538, recall=0.4425978405693526, fmeasure=0.4362574105742246), high=Score(precision=0.5551628362191324, recall=0.484745729143011, fmeasure=0.4741847209117008))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.3216744814213564, recall=0.25820508525150493, fmeasure=0.2622894105414284), mid=Score(precision=0.3578174603174603, recall=0.2948969464478647, fmeasure=0.299173572060365), high=Score(precision=0.4027775951479078, recall=0.3364354665934083, fmeasure=0.3369438478927765))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.46545690263066186, recall=0.39554608040546063, fmeasure=0.390142480082393), mid=Score(precision=0.5090220922867983, recall=0.43682183208168895, fmeasure=0.4312399229338409), high=Score(precision=0.5525309493917031, recall=0.4828847720959082, fmeasure=0.47428984732811474))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4661605973887224, recall=0.39497690892286547, fmeasure=0.3889555663624529), mid=Score(precision=0.5094346737821003, recall=0.4376722160291639, fmeasure=0.43189829969785765), high=Score(precision=0.5542627652321127, recall=0.48018281978254423, fmeasure=0.47459512949319055))</td>\n",
       "      <td>9.772500</td>\n",
       "      <td>0.353113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.375200</td>\n",
       "      <td>0.750465</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.453133573304759, recall=0.40216564778005814, fmeasure=0.3871259161810139), mid=Score(precision=0.4945389467558586, recall=0.4429663863947386, fmeasure=0.42459790692370664), high=Score(precision=0.5347658066351545, recall=0.4838454454019771, fmeasure=0.46259201959680274))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.31500150275072153, recall=0.27768858536866436, fmeasure=0.26536412574170914), mid=Score(precision=0.35338351405538904, recall=0.31618647333652206, fmeasure=0.3006529316933355), high=Score(precision=0.4014272957077645, recall=0.3580753078309763, fmeasure=0.33933018904437684))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.44517765122438824, recall=0.3927977664344959, fmeasure=0.377289559758945), mid=Score(precision=0.4891418030498911, recall=0.43691686142020875, fmeasure=0.4196659326070169), high=Score(precision=0.5350172537582922, recall=0.4809567866628533, fmeasure=0.460825362269528))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.44649127128998445, recall=0.3931777708682148, fmeasure=0.3784037646999634), mid=Score(precision=0.488711664458907, recall=0.43660081746195406, fmeasure=0.419933238643441), high=Score(precision=0.5313062919566134, recall=0.4816921413108322, fmeasure=0.4605315446095441))</td>\n",
       "      <td>10.295000</td>\n",
       "      <td>0.356569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.375200</td>\n",
       "      <td>0.753729</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.45785545116137966, recall=0.3835319474748802, fmeasure=0.3836420669044032), mid=Score(precision=0.502486795985877, recall=0.42450898708960494, fmeasure=0.42438749530991876), high=Score(precision=0.5446467548842087, recall=0.46718348256788744, fmeasure=0.4640865731577586))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.3015996143613331, recall=0.2501378809727344, fmeasure=0.24855747095350572), mid=Score(precision=0.34130748938561445, recall=0.28854174117024756, fmeasure=0.2867714760890242), high=Score(precision=0.389852125999001, recall=0.3285510274729863, fmeasure=0.3258180785132492))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4537904361569801, recall=0.3752541988652364, fmeasure=0.377804756710345), mid=Score(precision=0.49604597567465203, recall=0.41909406186600284, fmeasure=0.419855575084811), high=Score(precision=0.5415146431642295, recall=0.4629242363543898, fmeasure=0.4631269079835103))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.45417710368675446, recall=0.3764288327027027, fmeasure=0.3783399994305929), mid=Score(precision=0.4958472037562111, recall=0.4208256950092918, fmeasure=0.42049168583587426), high=Score(precision=0.5410843234124942, recall=0.46377861995801595, fmeasure=0.46355982117858335))</td>\n",
       "      <td>9.730000</td>\n",
       "      <td>0.341515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.375200</td>\n",
       "      <td>0.778447</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.44615833611343725, recall=0.3996232600144963, fmeasure=0.38171104819939844), mid=Score(precision=0.48984043193326277, recall=0.4399856861122446, fmeasure=0.4232911024897985), high=Score(precision=0.5318228692416652, recall=0.48134981764027535, fmeasure=0.46200889000630935))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.3019290419649795, recall=0.2598035786173662, fmeasure=0.2533276901262929), mid=Score(precision=0.33962954927017425, recall=0.2975621959641473, fmeasure=0.28920840228921724), high=Score(precision=0.38784572328712946, recall=0.3400178260256822, fmeasure=0.32961347256358975))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.44045325961314036, recall=0.3903671677541619, fmeasure=0.37573124794787016), mid=Score(precision=0.48137247862431687, recall=0.4327113425843019, fmeasure=0.4169488256022502), high=Score(precision=0.5269481864897764, recall=0.47789326608029775, fmeasure=0.46131652958063857))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4390795979551492, recall=0.3915633844350389, fmeasure=0.3772964091730796), mid=Score(precision=0.4821951466629774, recall=0.4346012444459241, fmeasure=0.41910375490445007), high=Score(precision=0.523053330523643, recall=0.47804841487261096, fmeasure=0.4585671232931552))</td>\n",
       "      <td>10.762500</td>\n",
       "      <td>0.351129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.375200</td>\n",
       "      <td>0.788654</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4589144496383925, recall=0.41643220308756757, fmeasure=0.40052473982949427), mid=Score(precision=0.5016884265652647, recall=0.459570179902441, fmeasure=0.4397688204316479), high=Score(precision=0.5406453769525, recall=0.5006433897693279, fmeasure=0.47835544181953754))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.3138496279761905, recall=0.2748361807234644, fmeasure=0.2693165633308421), mid=Score(precision=0.35376627886002876, recall=0.3166716950565095, fmeasure=0.30780764150106954), high=Score(precision=0.39836201862373727, recall=0.3589501792021736, fmeasure=0.3511561459435002))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.45047077538474584, recall=0.40969443114910764, fmeasure=0.39202369537873727), mid=Score(precision=0.49304939474332854, recall=0.4523477769760078, fmeasure=0.43399520311542156), high=Score(precision=0.5387345614608021, recall=0.4948912337199696, fmeasure=0.47792251894719634))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4485713133373979, recall=0.40868049729981437, fmeasure=0.39004338831389984), mid=Score(precision=0.4935701513559968, recall=0.45304421564577657, fmeasure=0.4348834093797831), high=Score(precision=0.5329985182862481, recall=0.49775732730499495, fmeasure=0.47484134958944446))</td>\n",
       "      <td>10.745000</td>\n",
       "      <td>0.368134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.375200</td>\n",
       "      <td>0.792338</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.45313559885784155, recall=0.40818108198541114, fmeasure=0.39115406041657996), mid=Score(precision=0.4990915032679738, recall=0.44901395141982514, fmeasure=0.4296850498611554), high=Score(precision=0.5429398928226591, recall=0.49367168933750044, fmeasure=0.4709547132987814))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.2996202476343101, recall=0.26569579765999246, fmeasure=0.2540614697627098), mid=Score(precision=0.3410925411394162, recall=0.3071524300815706, fmeasure=0.29172549814356674), high=Score(precision=0.3892763437950938, recall=0.35024746402176926, fmeasure=0.33310307956301693))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4494967970142603, recall=0.40038128876356405, fmeasure=0.38310679094234296), mid=Score(precision=0.49124588422198734, recall=0.4427533892270593, fmeasure=0.42486399928457363), high=Score(precision=0.5357187389203932, recall=0.4876426675358737, fmeasure=0.46563035255035834))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4497103340236154, recall=0.40080180060483, fmeasure=0.3842242838904626), mid=Score(precision=0.49158869500597446, recall=0.4435258767758431, fmeasure=0.4249367345358715), high=Score(precision=0.5349043846421143, recall=0.48936326932879237, fmeasure=0.46739368235076134))</td>\n",
       "      <td>10.662500</td>\n",
       "      <td>0.357131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.222500</td>\n",
       "      <td>0.824692</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.46942715663625617, recall=0.4110178053564668, fmeasure=0.3998163008502162), mid=Score(precision=0.5106483105334209, recall=0.4533496481626904, fmeasure=0.43953959155574596), high=Score(precision=0.5497225719949987, recall=0.4960343961756628, fmeasure=0.4784304573082867))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.31539051452020206, recall=0.2765819189313313, fmeasure=0.2700938913440635), mid=Score(precision=0.3583806367243868, recall=0.3149320599768956, fmeasure=0.3065330565434003), high=Score(precision=0.40407069917929295, recall=0.35606380409631494, fmeasure=0.34382960980661126))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4589235625485626, recall=0.4009234137313931, fmeasure=0.3899796032925009), mid=Score(precision=0.5009472462790479, recall=0.4459101313567593, fmeasure=0.4328036910120333), high=Score(precision=0.5477604624695159, recall=0.48940413541505734, fmeasure=0.47439892964306274))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.45916895993610163, recall=0.40320728808141326, fmeasure=0.3914414028174608), mid=Score(precision=0.5005036258675966, recall=0.44582398478952384, fmeasure=0.43311372855715596), high=Score(precision=0.5430597612099911, recall=0.4914396848201414, fmeasure=0.4763664535716541))</td>\n",
       "      <td>10.547500</td>\n",
       "      <td>0.363874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.222500</td>\n",
       "      <td>0.816647</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.47477803644986555, recall=0.41631346192918417, fmeasure=0.4011329990786165), mid=Score(precision=0.5158816873485991, recall=0.459293309561158, fmeasure=0.4422733577743264), high=Score(precision=0.5567746362603899, recall=0.5005704230382088, fmeasure=0.48119631915838273))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.32806166012806637, recall=0.2817476338665225, fmeasure=0.2739113440386645), mid=Score(precision=0.3714660218253968, recall=0.32158801667860004, fmeasure=0.311082238008512), high=Score(precision=0.4186764587842713, recall=0.36449215666807167, fmeasure=0.3506786457579862))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.46696307964400785, recall=0.4097478732745868, fmeasure=0.3955690288168695), mid=Score(precision=0.508681268894504, recall=0.45141233071194464, fmeasure=0.43548574055589706), high=Score(precision=0.5539266415977814, recall=0.49346215320443065, fmeasure=0.47876360521783806))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4650049851292496, recall=0.412286892613999, fmeasure=0.39636991632757623), mid=Score(precision=0.5087874826358281, recall=0.45154240174010796, fmeasure=0.43633970963962887), high=Score(precision=0.5534159253634436, recall=0.4951669564112295, fmeasure=0.4777021064607985))</td>\n",
       "      <td>10.422500</td>\n",
       "      <td>0.368883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.222500</td>\n",
       "      <td>0.838214</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.46786372172047724, recall=0.4126875854134473, fmeasure=0.40139551685627534), mid=Score(precision=0.510682582327803, recall=0.45475458337736446, fmeasure=0.43965473208079464), high=Score(precision=0.5524458997038503, recall=0.4968519664924669, fmeasure=0.4791220629929968))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.31781429135101014, recall=0.2769908126002566, fmeasure=0.26822423298400366), mid=Score(precision=0.35995675505050506, recall=0.31819700390253763, fmeasure=0.30625810183024593), high=Score(precision=0.4055039411976912, recall=0.358819644536747, fmeasure=0.3453551499459212))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4601643405613994, recall=0.40598173978735896, fmeasure=0.39365622135977335), mid=Score(precision=0.5034357763355926, recall=0.44954114131679174, fmeasure=0.43506780169428344), high=Score(precision=0.5472227435350597, recall=0.49438964297754506, fmeasure=0.4774881908307901))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4614744097864965, recall=0.40755190171386313, fmeasure=0.3932710965212926), mid=Score(precision=0.503908769947373, recall=0.4500093855535068, fmeasure=0.43573415576393126), high=Score(precision=0.5479708379294318, recall=0.49391448374215935, fmeasure=0.4794113082092779))</td>\n",
       "      <td>10.527500</td>\n",
       "      <td>0.365477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.222500</td>\n",
       "      <td>0.846445</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4545374822787506, recall=0.4042518256823088, fmeasure=0.39196740318023626), mid=Score(precision=0.4979636621548386, recall=0.4447568754566119, fmeasure=0.431885495539179), high=Score(precision=0.5385025921229506, recall=0.4857940077481617, fmeasure=0.47148110435543783))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.3147435978084415, recall=0.2713037612633485, fmeasure=0.26654420208649937), mid=Score(precision=0.35692942821067813, recall=0.30997628258763876, fmeasure=0.3033853735109956), high=Score(precision=0.4041847549152236, recall=0.3522769846560195, fmeasure=0.34415642522885476))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4473621363420077, recall=0.3952154843039522, fmeasure=0.3848551893377812), mid=Score(precision=0.4908199191535591, recall=0.4382571772501427, fmeasure=0.4259578392846599), high=Score(precision=0.534444636531769, recall=0.48139847615454506, fmeasure=0.47002761594962245))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4495059530696021, recall=0.3982848464763004, fmeasure=0.38705970063695966), mid=Score(precision=0.49013500011018385, recall=0.43857101760981354, fmeasure=0.42665068613576906), high=Score(precision=0.5325146943130397, recall=0.48323713904011034, fmeasure=0.4693942120800748))</td>\n",
       "      <td>10.450000</td>\n",
       "      <td>0.358188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.222500</td>\n",
       "      <td>0.844295</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.46990069627574255, recall=0.42842309215772806, fmeasure=0.41015535154493377), mid=Score(precision=0.5136006447596524, recall=0.4679776759056243, fmeasure=0.4494974991831765), high=Score(precision=0.5550030369956842, recall=0.50869343275189, fmeasure=0.48717305465937283))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.32090180089008224, recall=0.28565080907118745, fmeasure=0.2748824980877571), mid=Score(precision=0.3614974435286935, recall=0.3245607165702522, fmeasure=0.31226269642549176), high=Score(precision=0.4082943665709289, recall=0.3685653361846666, fmeasure=0.3528120899259048))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4624878763036394, recall=0.41961544673353895, fmeasure=0.4022900953865722), mid=Score(precision=0.5052432133838384, recall=0.46307653622350475, fmeasure=0.44400308682529527), high=Score(precision=0.5471356710436213, recall=0.5044243935599448, fmeasure=0.4843952122064865))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4639572226435738, recall=0.4214161660930977, fmeasure=0.4035597207903089), mid=Score(precision=0.504129505298623, recall=0.46092620480759144, fmeasure=0.44403127704909584), high=Score(precision=0.5453995644367888, recall=0.5052154913163864, fmeasure=0.48649255313141065))</td>\n",
       "      <td>10.552500</td>\n",
       "      <td>0.376089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.144900</td>\n",
       "      <td>0.853865</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4542477292009462, recall=0.4171691782814367, fmeasure=0.3976227347380225), mid=Score(precision=0.4971924415453827, recall=0.46034558561658945, fmeasure=0.4384566795574827), high=Score(precision=0.5370468190918558, recall=0.5012662589681192, fmeasure=0.4781711850094104))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.31449520427489175, recall=0.2831816132068332, fmeasure=0.2707646130268802), mid=Score(precision=0.3546036706349207, recall=0.32222655464761985, fmeasure=0.306562853337545), high=Score(precision=0.4036117345328282, recall=0.363625262219874, fmeasure=0.34717191446570483))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.44760405522275937, recall=0.4095233921731736, fmeasure=0.39187349422983936), mid=Score(precision=0.4881533190053411, recall=0.45240163411777246, fmeasure=0.4316484497794069), high=Score(precision=0.5345901000602749, recall=0.4990859518195207, fmeasure=0.4739019643993727))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4466944822640596, recall=0.4115436731486262, fmeasure=0.39072957203467984), mid=Score(precision=0.48876469925091226, recall=0.4537524602704812, fmeasure=0.4325185957220694), high=Score(precision=0.5317016831259017, recall=0.49905796610052955, fmeasure=0.47638546063377135))</td>\n",
       "      <td>10.837500</td>\n",
       "      <td>0.368112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.144900</td>\n",
       "      <td>0.847502</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4626227138211054, recall=0.4077453189860239, fmeasure=0.39685693097825275), mid=Score(precision=0.5058827865353601, recall=0.4496073334087472, fmeasure=0.4369790925580939), high=Score(precision=0.5439188368718703, recall=0.49113903918946117, fmeasure=0.47508688490538187))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.315841332972583, recall=0.26747694795075294, fmeasure=0.2619813909550568), mid=Score(precision=0.3588640422077921, recall=0.30679946620698056, fmeasure=0.29967056583612905), high=Score(precision=0.4042520161262349, recall=0.34939064344892623, fmeasure=0.3419685088376495))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4554829743785626, recall=0.3993124189575552, fmeasure=0.39104480218805987), mid=Score(precision=0.4990169692439914, recall=0.44290514362774047, fmeasure=0.4312968624179879), high=Score(precision=0.5428137430329067, recall=0.49013522556443867, fmeasure=0.47573153829392384))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4554864338021048, recall=0.4017470415860973, fmeasure=0.3906798366487377), mid=Score(precision=0.49934997324978936, recall=0.44515038664622475, fmeasure=0.43292187507852364), high=Score(precision=0.5420147336119763, recall=0.4878525438421803, fmeasure=0.4751488175938307))</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>0.358757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.144900</td>\n",
       "      <td>0.853502</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4609003580263691, recall=0.4107442666065498, fmeasure=0.39827335484159415), mid=Score(precision=0.5047963369351238, recall=0.4532554120574932, fmeasure=0.4395224493799659), high=Score(precision=0.5439027376116531, recall=0.4917645561572742, fmeasure=0.4775853383832543))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.31800921006077254, recall=0.2729423318234342, fmeasure=0.26794439203312137), mid=Score(precision=0.3590088557276057, recall=0.3136760363691673, fmeasure=0.3049281031427288), high=Score(precision=0.4039669476356976, recall=0.3555040219589931, fmeasure=0.34362729169777684))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.45471966288919397, recall=0.4042465896182659, fmeasure=0.3930004753028799), mid=Score(precision=0.4975269282392445, recall=0.44516843549670565, fmeasure=0.4338668977609774), high=Score(precision=0.5397582185890089, recall=0.4906569583570875, fmeasure=0.4766035308121368))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.45477486951875723, recall=0.40590952303644035, fmeasure=0.39392953754360216), mid=Score(precision=0.49724948917504064, recall=0.447111247290149, fmeasure=0.43449927871206717), high=Score(precision=0.5425300354312761, recall=0.48994728014504146, fmeasure=0.4794950974774659))</td>\n",
       "      <td>10.575000</td>\n",
       "      <td>0.362664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.144900</td>\n",
       "      <td>0.863468</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.45612284144062626, recall=0.410279397048829, fmeasure=0.397272747971925), mid=Score(precision=0.502437802495707, recall=0.45361073441406763, fmeasure=0.43678141559475653), high=Score(precision=0.5413912600777491, recall=0.4959323806247567, fmeasure=0.47724752218877153))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.31590796018217887, recall=0.2753112784576476, fmeasure=0.2649580832154522), mid=Score(precision=0.3575276112776113, recall=0.3157910699789872, fmeasure=0.3026893074131223), high=Score(precision=0.40513165020743136, recall=0.35831781876230423, fmeasure=0.34271218635651396))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.45528547632412564, recall=0.4049596870466612, fmeasure=0.3917288368288371), mid=Score(precision=0.4957770603579426, recall=0.44607271734460285, fmeasure=0.4305897921376122), high=Score(precision=0.5375634285036857, recall=0.4920989307294668, fmeasure=0.47202734688605713))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.45534053651617984, recall=0.40892030088884357, fmeasure=0.392472177017393), mid=Score(precision=0.49595384476634485, recall=0.4470325173772939, fmeasure=0.4328057438283782), high=Score(precision=0.5408296467625511, recall=0.49228385972156613, fmeasure=0.47399062565718686))</td>\n",
       "      <td>10.585000</td>\n",
       "      <td>0.362885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.144900</td>\n",
       "      <td>0.860124</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.46374114349192463, recall=0.41592613440449244, fmeasure=0.40170030835990383), mid=Score(precision=0.5077423118140032, recall=0.4589182419000498, fmeasure=0.44323914087675365), high=Score(precision=0.5497884059669903, recall=0.500996647283691, fmeasure=0.48157129840472346))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.31698452632437024, recall=0.27663818548256497, fmeasure=0.26659726711679504), mid=Score(precision=0.35798454150016645, recall=0.31703468692556064, fmeasure=0.30503568957730054), high=Score(precision=0.4038408971237097, recall=0.3582491538102086, fmeasure=0.34581026147651606))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.45985268284615705, recall=0.40869882140195096, fmeasure=0.3975532942368149), mid=Score(precision=0.5001095651693079, recall=0.45158596649385396, fmeasure=0.43565157739248606), high=Score(precision=0.5444001022466093, recall=0.4954166556796364, fmeasure=0.47971908609307246))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.45928027738193167, recall=0.41171482297552126, fmeasure=0.39745303201972165), mid=Score(precision=0.5012600580587713, recall=0.45278036214647144, fmeasure=0.4383168960072074), high=Score(precision=0.5445877070233687, recall=0.4957934968825926, fmeasure=0.4803881105982529))</td>\n",
       "      <td>10.530000</td>\n",
       "      <td>0.366789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.112800</td>\n",
       "      <td>0.860172</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.4578330056534559, recall=0.4148064343283636, fmeasure=0.39832972373175135), mid=Score(precision=0.5019242585437438, recall=0.45686792921151326, fmeasure=0.4382850385346374), high=Score(precision=0.5424634843302121, recall=0.4993653986961007, fmeasure=0.47837259654081904))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.3171212569548508, recall=0.2814158741992985, fmeasure=0.2695763248068289), mid=Score(precision=0.359550622988123, recall=0.3221733267679002, fmeasure=0.3076179257692461), high=Score(precision=0.4044426959325396, recall=0.3644972079723455, fmeasure=0.34718131405073005))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.45522675120528994, recall=0.40724780677214234, fmeasure=0.3938986908335898), mid=Score(precision=0.4940002174092247, recall=0.44968216718860315, fmeasure=0.4320172037511903), high=Score(precision=0.5365838974954781, recall=0.4912810042773996, fmeasure=0.47342779055534984))</td>\n",
       "      <td>AggregateScore(low=Score(precision=0.45269595693318104, recall=0.4096675674244187, fmeasure=0.394645077633553), mid=Score(precision=0.49474564467395343, recall=0.45021504536819745, fmeasure=0.4335007607447334), high=Score(precision=0.5379738594789607, recall=0.49593553727662487, fmeasure=0.47628173407207813))</td>\n",
       "      <td>10.602500</td>\n",
       "      <td>0.368273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.3858696251511969, recall=0.30656133605023944, fmeasure=0.2930978773337898), mid=Score(precision=0.4253674649492664, recall=0.3444054404779554, fmeasure=0.3275592529612438), high=Score(precision=0.4677125103654516, recall=0.38500687224265884, fmeasure=0.365721580932506))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.24214207788739042, recall=0.18706447991188888, fmeasure=0.18766513398847134), mid=Score(precision=0.2831912115662116, recall=0.2241876822504651, fmeasure=0.22111990034025386), high=Score(precision=0.32786299013486503, recall=0.2628721757112617, fmeasure=0.2584090826596185))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.3815013556245633, recall=0.2999360985220592, fmeasure=0.2873262573504971), mid=Score(precision=0.4219155149384928, recall=0.3406936470834161, fmeasure=0.32408506544809024), high=Score(precision=0.4674961848608909, recall=0.3839927539767308, fmeasure=0.36424439249106016))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.38022833833343933, recall=0.3007668315991155, fmeasure=0.28725327026465575), mid=Score(precision=0.4210773025993614, recall=0.34306195420129165, fmeasure=0.32470125118523024), high=Score(precision=0.4632209041214096, recall=0.3837490292378207, fmeasure=0.3619812400445019))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4448944972154074, recall=0.366952249041475, fmeasure=0.3615825212274586), mid=Score(precision=0.4856517078713771, recall=0.4073541315329049, fmeasure=0.39992784360286715), high=Score(precision=0.5285165320688299, recall=0.449265006691097, fmeasure=0.43976172801021246))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.28438278544372303, recall=0.22653058957244618, fmeasure=0.22584089190913395), mid=Score(precision=0.32403300865800866, recall=0.2641194340080197, fmeasure=0.2631265365693024), high=Score(precision=0.3705025128517317, recall=0.30538313598234257, fmeasure=0.3028580149433679))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4354552567020398, recall=0.3562285642520104, fmeasure=0.3514073649195632), mid=Score(precision=0.4786662258289096, recall=0.4019534179069576, fmeasure=0.3942764131062766), high=Score(precision=0.5263722404484811, recall=0.44634928671530255, fmeasure=0.43726595892300407))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4354316057920838, recall=0.36217305776968356, fmeasure=0.3535927568015278), mid=Score(precision=0.4789899734660763, recall=0.4030304667618776, fmeasure=0.39511025051717785), high=Score(precision=0.5234440393807581, recall=0.44679042422619447, fmeasure=0.43658954167081543))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4200627592638163, recall=0.38615545648148436, fmeasure=0.36213540606789296), mid=Score(precision=0.4637507777149322, recall=0.4277983257466318, fmeasure=0.4005285653051624), high=Score(precision=0.5065111370196387, recall=0.467163427834517, fmeasure=0.4377027026825564))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.2677809065934067, recall=0.23627452471313407, fmeasure=0.22494662903687943), mid=Score(precision=0.30651807393994895, recall=0.273717863688771, fmeasure=0.260313906679952), high=Score(precision=0.3497433371316185, recall=0.311677049111372, fmeasure=0.2962463114621969))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4110186929951176, recall=0.3791109743830138, fmeasure=0.3536520283319849), mid=Score(precision=0.4564787404180788, recall=0.42152390157594294, fmeasure=0.39459869445330775), high=Score(precision=0.4982534745942374, recall=0.4634312264885589, fmeasure=0.4331629362780169))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.40956634400117836, recall=0.3779011149791976, fmeasure=0.35340049003543145), mid=Score(precision=0.4561680497811013, recall=0.4217313664678223, fmeasure=0.3952183373785083), high=Score(precision=0.49763545404758636, recall=0.46560865483214603, fmeasure=0.4373469955137082))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4453106193387904, recall=0.39392190100134705, fmeasure=0.3787753829984203), mid=Score(precision=0.49012643585989163, recall=0.43476685584471636, fmeasure=0.41872345041152126), high=Score(precision=0.5333260284649989, recall=0.47804952107710436, fmeasure=0.4586638301656301))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.28819420839577103, recall=0.2531287083149487, fmeasure=0.24379964892748984), mid=Score(precision=0.32943316232378733, recall=0.28964504847019046, fmeasure=0.27985467100473327), high=Score(precision=0.37403972581238204, recall=0.3321498944157027, fmeasure=0.320094530687467))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.44019152901326614, recall=0.38504795110029033, fmeasure=0.37109153676901663), mid=Score(precision=0.4836864862057876, recall=0.4290365078363552, fmeasure=0.41469968996702344), high=Score(precision=0.5257079420783465, recall=0.47325724783860046, fmeasure=0.4546909707886545))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4399305032334905, recall=0.3893545091456042, fmeasure=0.3725200049954087), mid=Score(precision=0.4836184213050021, recall=0.43044077120481006, fmeasure=0.41424643276173606), high=Score(precision=0.525666730415214, recall=0.47209663388583933, fmeasure=0.45456824236073357))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4508669381833445, recall=0.38977382709233227, fmeasure=0.38200070766623845), mid=Score(precision=0.49190837552969924, recall=0.4308824222394188, fmeasure=0.4198652041349976), high=Score(precision=0.5370005239093014, recall=0.4728774091045095, fmeasure=0.4604105754991434))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.2952308462370962, recall=0.25117651472121066, fmeasure=0.24700843393561275), mid=Score(precision=0.3391925505050506, recall=0.2900938471466885, fmeasure=0.28672888033464095), high=Score(precision=0.38661351356976353, recall=0.3290757236836538, fmeasure=0.3259688000711312))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.44430419151416406, recall=0.3807097983861289, fmeasure=0.37540757357400195), mid=Score(precision=0.4861313848528922, recall=0.42583367025071517, fmeasure=0.4169105508596428), high=Score(precision=0.5282730220249522, recall=0.46809489734029025, fmeasure=0.45731268683456133))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4416539898418575, recall=0.3821222320043674, fmeasure=0.373003831894518), mid=Score(precision=0.4859275380461041, recall=0.4261297941354337, fmeasure=0.4170826467146459), high=Score(precision=0.5306223212194258, recall=0.4683396560744519, fmeasure=0.4568717037197165))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.43985698550326324, recall=0.39625329763783557, fmeasure=0.3831017434605048), mid=Score(precision=0.48343049842314567, recall=0.43926672699036207, fmeasure=0.4228229129128428), high=Score(precision=0.526859666308977, recall=0.48361080077614416, fmeasure=0.46271221760138825))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.30322354598526485, recall=0.2736156279591297, fmeasure=0.26510875044829646), mid=Score(precision=0.34378770361582867, recall=0.3116683969884738, fmeasure=0.3009702774401807), high=Score(precision=0.38680319628288373, recall=0.3502693365860512, fmeasure=0.34094299377442455))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4339624671437632, recall=0.3903317328104224, fmeasure=0.3755351102083819), mid=Score(precision=0.47735083421480495, recall=0.43529222510352694, fmeasure=0.4186737668849265), high=Score(precision=0.5226187910078075, recall=0.4783145979944922, fmeasure=0.45974306699816353))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4327842451716994, recall=0.39280486469560705, fmeasure=0.3767552967954367), mid=Score(precision=0.4771109300217755, recall=0.43530094826897014, fmeasure=0.4183268625320519), high=Score(precision=0.5206189931443147, recall=0.4781874044419085, fmeasure=0.458885541002324))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.44954798658245343, recall=0.3993765102210907, fmeasure=0.3847317463287094), mid=Score(precision=0.4927776841214341, recall=0.44063891109965286, fmeasure=0.42391693715169754), high=Score(precision=0.5343846081512444, recall=0.48453110102651337, fmeasure=0.463676960483813))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.3032234178148241, recall=0.26470692027104487, fmeasure=0.2578603406656447), mid=Score(precision=0.34316821199633707, recall=0.3029442294770046, fmeasure=0.2930835303495837), high=Score(precision=0.38808602976884204, recall=0.3429886925636225, fmeasure=0.3313641836628815))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4443352538239947, recall=0.3899220916202348, fmeasure=0.37511601046094095), mid=Score(precision=0.48445853503114544, recall=0.43368973937999167, fmeasure=0.41743387303543344), high=Score(precision=0.5312510569444852, recall=0.4787680816868685, fmeasure=0.46188571305985604))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.43896485076402353, recall=0.39058027010563034, fmeasure=0.37450507492829666), mid=Score(precision=0.486132466797908, recall=0.4349747555337993, fmeasure=0.4190333734256221), high=Score(precision=0.5267683308776601, recall=0.47851247948513903, fmeasure=0.4590891386525202))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4449786923860452, recall=0.4012477124320868, fmeasure=0.3869916924992929), mid=Score(precision=0.4888703983924573, recall=0.44379089987583387, fmeasure=0.42657010131687123), high=Score(precision=0.5324522214101257, recall=0.4858802272170914, fmeasure=0.4670408901621352))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.29300253427128437, recall=0.2594138902862056, fmeasure=0.25127902258121687), mid=Score(precision=0.3342766192141192, recall=0.300013887876518, fmeasure=0.2881851552220536), high=Score(precision=0.37738456439393936, recall=0.33954003342429095, fmeasure=0.32647420638657315))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4391754104249509, recall=0.39522424023040265, fmeasure=0.38128262641739313), mid=Score(precision=0.4797792617921295, recall=0.43779796235219987, fmeasure=0.4202279882287337), high=Score(precision=0.5253338502133078, recall=0.4823408269409755, fmeasure=0.46349960114122346))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4371258485234128, recall=0.3972535206995124, fmeasure=0.37987488268842495), mid=Score(precision=0.48140621204775624, recall=0.4389726803041634, fmeasure=0.42225036415376516), high=Score(precision=0.5235859643114238, recall=0.4830477073209685, fmeasure=0.4643781183171954))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.473961947493887, recall=0.4011582665396792, fmeasure=0.39749875099671533), mid=Score(precision=0.5150308285464538, recall=0.4425978405693526, fmeasure=0.4362574105742246), high=Score(precision=0.5551628362191324, recall=0.484745729143011, fmeasure=0.4741847209117008))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.3216744814213564, recall=0.25820508525150493, fmeasure=0.2622894105414284), mid=Score(precision=0.3578174603174603, recall=0.2948969464478647, fmeasure=0.299173572060365), high=Score(precision=0.4027775951479078, recall=0.3364354665934083, fmeasure=0.3369438478927765))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.46545690263066186, recall=0.39554608040546063, fmeasure=0.390142480082393), mid=Score(precision=0.5090220922867983, recall=0.43682183208168895, fmeasure=0.4312399229338409), high=Score(precision=0.5525309493917031, recall=0.4828847720959082, fmeasure=0.47428984732811474))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4661605973887224, recall=0.39497690892286547, fmeasure=0.3889555663624529), mid=Score(precision=0.5094346737821003, recall=0.4376722160291639, fmeasure=0.43189829969785765), high=Score(precision=0.5542627652321127, recall=0.48018281978254423, fmeasure=0.47459512949319055))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.453133573304759, recall=0.40216564778005814, fmeasure=0.3871259161810139), mid=Score(precision=0.4945389467558586, recall=0.4429663863947386, fmeasure=0.42459790692370664), high=Score(precision=0.5347658066351545, recall=0.4838454454019771, fmeasure=0.46259201959680274))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.31500150275072153, recall=0.27768858536866436, fmeasure=0.26536412574170914), mid=Score(precision=0.35338351405538904, recall=0.31618647333652206, fmeasure=0.3006529316933355), high=Score(precision=0.4014272957077645, recall=0.3580753078309763, fmeasure=0.33933018904437684))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.44517765122438824, recall=0.3927977664344959, fmeasure=0.377289559758945), mid=Score(precision=0.4891418030498911, recall=0.43691686142020875, fmeasure=0.4196659326070169), high=Score(precision=0.5350172537582922, recall=0.4809567866628533, fmeasure=0.460825362269528))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.44649127128998445, recall=0.3931777708682148, fmeasure=0.3784037646999634), mid=Score(precision=0.488711664458907, recall=0.43660081746195406, fmeasure=0.419933238643441), high=Score(precision=0.5313062919566134, recall=0.4816921413108322, fmeasure=0.4605315446095441))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.45785545116137966, recall=0.3835319474748802, fmeasure=0.3836420669044032), mid=Score(precision=0.502486795985877, recall=0.42450898708960494, fmeasure=0.42438749530991876), high=Score(precision=0.5446467548842087, recall=0.46718348256788744, fmeasure=0.4640865731577586))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.3015996143613331, recall=0.2501378809727344, fmeasure=0.24855747095350572), mid=Score(precision=0.34130748938561445, recall=0.28854174117024756, fmeasure=0.2867714760890242), high=Score(precision=0.389852125999001, recall=0.3285510274729863, fmeasure=0.3258180785132492))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4537904361569801, recall=0.3752541988652364, fmeasure=0.377804756710345), mid=Score(precision=0.49604597567465203, recall=0.41909406186600284, fmeasure=0.419855575084811), high=Score(precision=0.5415146431642295, recall=0.4629242363543898, fmeasure=0.4631269079835103))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.45417710368675446, recall=0.3764288327027027, fmeasure=0.3783399994305929), mid=Score(precision=0.4958472037562111, recall=0.4208256950092918, fmeasure=0.42049168583587426), high=Score(precision=0.5410843234124942, recall=0.46377861995801595, fmeasure=0.46355982117858335))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.44615833611343725, recall=0.3996232600144963, fmeasure=0.38171104819939844), mid=Score(precision=0.48984043193326277, recall=0.4399856861122446, fmeasure=0.4232911024897985), high=Score(precision=0.5318228692416652, recall=0.48134981764027535, fmeasure=0.46200889000630935))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.3019290419649795, recall=0.2598035786173662, fmeasure=0.2533276901262929), mid=Score(precision=0.33962954927017425, recall=0.2975621959641473, fmeasure=0.28920840228921724), high=Score(precision=0.38784572328712946, recall=0.3400178260256822, fmeasure=0.32961347256358975))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.44045325961314036, recall=0.3903671677541619, fmeasure=0.37573124794787016), mid=Score(precision=0.48137247862431687, recall=0.4327113425843019, fmeasure=0.4169488256022502), high=Score(precision=0.5269481864897764, recall=0.47789326608029775, fmeasure=0.46131652958063857))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4390795979551492, recall=0.3915633844350389, fmeasure=0.3772964091730796), mid=Score(precision=0.4821951466629774, recall=0.4346012444459241, fmeasure=0.41910375490445007), high=Score(precision=0.523053330523643, recall=0.47804841487261096, fmeasure=0.4585671232931552))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4589144496383925, recall=0.41643220308756757, fmeasure=0.40052473982949427), mid=Score(precision=0.5016884265652647, recall=0.459570179902441, fmeasure=0.4397688204316479), high=Score(precision=0.5406453769525, recall=0.5006433897693279, fmeasure=0.47835544181953754))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.3138496279761905, recall=0.2748361807234644, fmeasure=0.2693165633308421), mid=Score(precision=0.35376627886002876, recall=0.3166716950565095, fmeasure=0.30780764150106954), high=Score(precision=0.39836201862373727, recall=0.3589501792021736, fmeasure=0.3511561459435002))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.45047077538474584, recall=0.40969443114910764, fmeasure=0.39202369537873727), mid=Score(precision=0.49304939474332854, recall=0.4523477769760078, fmeasure=0.43399520311542156), high=Score(precision=0.5387345614608021, recall=0.4948912337199696, fmeasure=0.47792251894719634))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4485713133373979, recall=0.40868049729981437, fmeasure=0.39004338831389984), mid=Score(precision=0.4935701513559968, recall=0.45304421564577657, fmeasure=0.4348834093797831), high=Score(precision=0.5329985182862481, recall=0.49775732730499495, fmeasure=0.47484134958944446))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.45313559885784155, recall=0.40818108198541114, fmeasure=0.39115406041657996), mid=Score(precision=0.4990915032679738, recall=0.44901395141982514, fmeasure=0.4296850498611554), high=Score(precision=0.5429398928226591, recall=0.49367168933750044, fmeasure=0.4709547132987814))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.2996202476343101, recall=0.26569579765999246, fmeasure=0.2540614697627098), mid=Score(precision=0.3410925411394162, recall=0.3071524300815706, fmeasure=0.29172549814356674), high=Score(precision=0.3892763437950938, recall=0.35024746402176926, fmeasure=0.33310307956301693))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4494967970142603, recall=0.40038128876356405, fmeasure=0.38310679094234296), mid=Score(precision=0.49124588422198734, recall=0.4427533892270593, fmeasure=0.42486399928457363), high=Score(precision=0.5357187389203932, recall=0.4876426675358737, fmeasure=0.46563035255035834))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4497103340236154, recall=0.40080180060483, fmeasure=0.3842242838904626), mid=Score(precision=0.49158869500597446, recall=0.4435258767758431, fmeasure=0.4249367345358715), high=Score(precision=0.5349043846421143, recall=0.48936326932879237, fmeasure=0.46739368235076134))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.46942715663625617, recall=0.4110178053564668, fmeasure=0.3998163008502162), mid=Score(precision=0.5106483105334209, recall=0.4533496481626904, fmeasure=0.43953959155574596), high=Score(precision=0.5497225719949987, recall=0.4960343961756628, fmeasure=0.4784304573082867))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.31539051452020206, recall=0.2765819189313313, fmeasure=0.2700938913440635), mid=Score(precision=0.3583806367243868, recall=0.3149320599768956, fmeasure=0.3065330565434003), high=Score(precision=0.40407069917929295, recall=0.35606380409631494, fmeasure=0.34382960980661126))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4589235625485626, recall=0.4009234137313931, fmeasure=0.3899796032925009), mid=Score(precision=0.5009472462790479, recall=0.4459101313567593, fmeasure=0.4328036910120333), high=Score(precision=0.5477604624695159, recall=0.48940413541505734, fmeasure=0.47439892964306274))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.45916895993610163, recall=0.40320728808141326, fmeasure=0.3914414028174608), mid=Score(precision=0.5005036258675966, recall=0.44582398478952384, fmeasure=0.43311372855715596), high=Score(precision=0.5430597612099911, recall=0.4914396848201414, fmeasure=0.4763664535716541))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.47477803644986555, recall=0.41631346192918417, fmeasure=0.4011329990786165), mid=Score(precision=0.5158816873485991, recall=0.459293309561158, fmeasure=0.4422733577743264), high=Score(precision=0.5567746362603899, recall=0.5005704230382088, fmeasure=0.48119631915838273))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.32806166012806637, recall=0.2817476338665225, fmeasure=0.2739113440386645), mid=Score(precision=0.3714660218253968, recall=0.32158801667860004, fmeasure=0.311082238008512), high=Score(precision=0.4186764587842713, recall=0.36449215666807167, fmeasure=0.3506786457579862))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.46696307964400785, recall=0.4097478732745868, fmeasure=0.3955690288168695), mid=Score(precision=0.508681268894504, recall=0.45141233071194464, fmeasure=0.43548574055589706), high=Score(precision=0.5539266415977814, recall=0.49346215320443065, fmeasure=0.47876360521783806))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4650049851292496, recall=0.412286892613999, fmeasure=0.39636991632757623), mid=Score(precision=0.5087874826358281, recall=0.45154240174010796, fmeasure=0.43633970963962887), high=Score(precision=0.5534159253634436, recall=0.4951669564112295, fmeasure=0.4777021064607985))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.46786372172047724, recall=0.4126875854134473, fmeasure=0.40139551685627534), mid=Score(precision=0.510682582327803, recall=0.45475458337736446, fmeasure=0.43965473208079464), high=Score(precision=0.5524458997038503, recall=0.4968519664924669, fmeasure=0.4791220629929968))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.31781429135101014, recall=0.2769908126002566, fmeasure=0.26822423298400366), mid=Score(precision=0.35995675505050506, recall=0.31819700390253763, fmeasure=0.30625810183024593), high=Score(precision=0.4055039411976912, recall=0.358819644536747, fmeasure=0.3453551499459212))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4601643405613994, recall=0.40598173978735896, fmeasure=0.39365622135977335), mid=Score(precision=0.5034357763355926, recall=0.44954114131679174, fmeasure=0.43506780169428344), high=Score(precision=0.5472227435350597, recall=0.49438964297754506, fmeasure=0.4774881908307901))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4614744097864965, recall=0.40755190171386313, fmeasure=0.3932710965212926), mid=Score(precision=0.503908769947373, recall=0.4500093855535068, fmeasure=0.43573415576393126), high=Score(precision=0.5479708379294318, recall=0.49391448374215935, fmeasure=0.4794113082092779))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4545374822787506, recall=0.4042518256823088, fmeasure=0.39196740318023626), mid=Score(precision=0.4979636621548386, recall=0.4447568754566119, fmeasure=0.431885495539179), high=Score(precision=0.5385025921229506, recall=0.4857940077481617, fmeasure=0.47148110435543783))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.3147435978084415, recall=0.2713037612633485, fmeasure=0.26654420208649937), mid=Score(precision=0.35692942821067813, recall=0.30997628258763876, fmeasure=0.3033853735109956), high=Score(precision=0.4041847549152236, recall=0.3522769846560195, fmeasure=0.34415642522885476))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4473621363420077, recall=0.3952154843039522, fmeasure=0.3848551893377812), mid=Score(precision=0.4908199191535591, recall=0.4382571772501427, fmeasure=0.4259578392846599), high=Score(precision=0.534444636531769, recall=0.48139847615454506, fmeasure=0.47002761594962245))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4495059530696021, recall=0.3982848464763004, fmeasure=0.38705970063695966), mid=Score(precision=0.49013500011018385, recall=0.43857101760981354, fmeasure=0.42665068613576906), high=Score(precision=0.5325146943130397, recall=0.48323713904011034, fmeasure=0.4693942120800748))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.46990069627574255, recall=0.42842309215772806, fmeasure=0.41015535154493377), mid=Score(precision=0.5136006447596524, recall=0.4679776759056243, fmeasure=0.4494974991831765), high=Score(precision=0.5550030369956842, recall=0.50869343275189, fmeasure=0.48717305465937283))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.32090180089008224, recall=0.28565080907118745, fmeasure=0.2748824980877571), mid=Score(precision=0.3614974435286935, recall=0.3245607165702522, fmeasure=0.31226269642549176), high=Score(precision=0.4082943665709289, recall=0.3685653361846666, fmeasure=0.3528120899259048))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4624878763036394, recall=0.41961544673353895, fmeasure=0.4022900953865722), mid=Score(precision=0.5052432133838384, recall=0.46307653622350475, fmeasure=0.44400308682529527), high=Score(precision=0.5471356710436213, recall=0.5044243935599448, fmeasure=0.4843952122064865))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4639572226435738, recall=0.4214161660930977, fmeasure=0.4035597207903089), mid=Score(precision=0.504129505298623, recall=0.46092620480759144, fmeasure=0.44403127704909584), high=Score(precision=0.5453995644367888, recall=0.5052154913163864, fmeasure=0.48649255313141065))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4542477292009462, recall=0.4171691782814367, fmeasure=0.3976227347380225), mid=Score(precision=0.4971924415453827, recall=0.46034558561658945, fmeasure=0.4384566795574827), high=Score(precision=0.5370468190918558, recall=0.5012662589681192, fmeasure=0.4781711850094104))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.31449520427489175, recall=0.2831816132068332, fmeasure=0.2707646130268802), mid=Score(precision=0.3546036706349207, recall=0.32222655464761985, fmeasure=0.306562853337545), high=Score(precision=0.4036117345328282, recall=0.363625262219874, fmeasure=0.34717191446570483))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.44760405522275937, recall=0.4095233921731736, fmeasure=0.39187349422983936), mid=Score(precision=0.4881533190053411, recall=0.45240163411777246, fmeasure=0.4316484497794069), high=Score(precision=0.5345901000602749, recall=0.4990859518195207, fmeasure=0.4739019643993727))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4466944822640596, recall=0.4115436731486262, fmeasure=0.39072957203467984), mid=Score(precision=0.48876469925091226, recall=0.4537524602704812, fmeasure=0.4325185957220694), high=Score(precision=0.5317016831259017, recall=0.49905796610052955, fmeasure=0.47638546063377135))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4626227138211054, recall=0.4077453189860239, fmeasure=0.39685693097825275), mid=Score(precision=0.5058827865353601, recall=0.4496073334087472, fmeasure=0.4369790925580939), high=Score(precision=0.5439188368718703, recall=0.49113903918946117, fmeasure=0.47508688490538187))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.315841332972583, recall=0.26747694795075294, fmeasure=0.2619813909550568), mid=Score(precision=0.3588640422077921, recall=0.30679946620698056, fmeasure=0.29967056583612905), high=Score(precision=0.4042520161262349, recall=0.34939064344892623, fmeasure=0.3419685088376495))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4554829743785626, recall=0.3993124189575552, fmeasure=0.39104480218805987), mid=Score(precision=0.4990169692439914, recall=0.44290514362774047, fmeasure=0.4312968624179879), high=Score(precision=0.5428137430329067, recall=0.49013522556443867, fmeasure=0.47573153829392384))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4554864338021048, recall=0.4017470415860973, fmeasure=0.3906798366487377), mid=Score(precision=0.49934997324978936, recall=0.44515038664622475, fmeasure=0.43292187507852364), high=Score(precision=0.5420147336119763, recall=0.4878525438421803, fmeasure=0.4751488175938307))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4609003580263691, recall=0.4107442666065498, fmeasure=0.39827335484159415), mid=Score(precision=0.5047963369351238, recall=0.4532554120574932, fmeasure=0.4395224493799659), high=Score(precision=0.5439027376116531, recall=0.4917645561572742, fmeasure=0.4775853383832543))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.31800921006077254, recall=0.2729423318234342, fmeasure=0.26794439203312137), mid=Score(precision=0.3590088557276057, recall=0.3136760363691673, fmeasure=0.3049281031427288), high=Score(precision=0.4039669476356976, recall=0.3555040219589931, fmeasure=0.34362729169777684))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.45471966288919397, recall=0.4042465896182659, fmeasure=0.3930004753028799), mid=Score(precision=0.4975269282392445, recall=0.44516843549670565, fmeasure=0.4338668977609774), high=Score(precision=0.5397582185890089, recall=0.4906569583570875, fmeasure=0.4766035308121368))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.45477486951875723, recall=0.40590952303644035, fmeasure=0.39392953754360216), mid=Score(precision=0.49724948917504064, recall=0.447111247290149, fmeasure=0.43449927871206717), high=Score(precision=0.5425300354312761, recall=0.48994728014504146, fmeasure=0.4794950974774659))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.45612284144062626, recall=0.410279397048829, fmeasure=0.397272747971925), mid=Score(precision=0.502437802495707, recall=0.45361073441406763, fmeasure=0.43678141559475653), high=Score(precision=0.5413912600777491, recall=0.4959323806247567, fmeasure=0.47724752218877153))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.31590796018217887, recall=0.2753112784576476, fmeasure=0.2649580832154522), mid=Score(precision=0.3575276112776113, recall=0.3157910699789872, fmeasure=0.3026893074131223), high=Score(precision=0.40513165020743136, recall=0.35831781876230423, fmeasure=0.34271218635651396))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.45528547632412564, recall=0.4049596870466612, fmeasure=0.3917288368288371), mid=Score(precision=0.4957770603579426, recall=0.44607271734460285, fmeasure=0.4305897921376122), high=Score(precision=0.5375634285036857, recall=0.4920989307294668, fmeasure=0.47202734688605713))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.45534053651617984, recall=0.40892030088884357, fmeasure=0.392472177017393), mid=Score(precision=0.49595384476634485, recall=0.4470325173772939, fmeasure=0.4328057438283782), high=Score(precision=0.5408296467625511, recall=0.49228385972156613, fmeasure=0.47399062565718686))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.46374114349192463, recall=0.41592613440449244, fmeasure=0.40170030835990383), mid=Score(precision=0.5077423118140032, recall=0.4589182419000498, fmeasure=0.44323914087675365), high=Score(precision=0.5497884059669903, recall=0.500996647283691, fmeasure=0.48157129840472346))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.31698452632437024, recall=0.27663818548256497, fmeasure=0.26659726711679504), mid=Score(precision=0.35798454150016645, recall=0.31703468692556064, fmeasure=0.30503568957730054), high=Score(precision=0.4038408971237097, recall=0.3582491538102086, fmeasure=0.34581026147651606))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.45985268284615705, recall=0.40869882140195096, fmeasure=0.3975532942368149), mid=Score(precision=0.5001095651693079, recall=0.45158596649385396, fmeasure=0.43565157739248606), high=Score(precision=0.5444001022466093, recall=0.4954166556796364, fmeasure=0.47971908609307246))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.45928027738193167, recall=0.41171482297552126, fmeasure=0.39745303201972165), mid=Score(precision=0.5012600580587713, recall=0.45278036214647144, fmeasure=0.4383168960072074), high=Score(precision=0.5445877070233687, recall=0.4957934968825926, fmeasure=0.4803881105982529))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.4578330056534559, recall=0.4148064343283636, fmeasure=0.39832972373175135), mid=Score(precision=0.5019242585437438, recall=0.45686792921151326, fmeasure=0.4382850385346374), high=Score(precision=0.5424634843302121, recall=0.4993653986961007, fmeasure=0.47837259654081904))\" of type <class 'str'> for key \"eval/rouge1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.3171212569548508, recall=0.2814158741992985, fmeasure=0.2695763248068289), mid=Score(precision=0.359550622988123, recall=0.3221733267679002, fmeasure=0.3076179257692461), high=Score(precision=0.4044426959325396, recall=0.3644972079723455, fmeasure=0.34718131405073005))\" of type <class 'str'> for key \"eval/rouge2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.45522675120528994, recall=0.40724780677214234, fmeasure=0.3938986908335898), mid=Score(precision=0.4940002174092247, recall=0.44968216718860315, fmeasure=0.4320172037511903), high=Score(precision=0.5365838974954781, recall=0.4912810042773996, fmeasure=0.47342779055534984))\" of type <class 'str'> for key \"eval/rougeL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"AggregateScore(low=Score(precision=0.45269595693318104, recall=0.4096675674244187, fmeasure=0.394645077633553), mid=Score(precision=0.49474564467395343, recall=0.45021504536819745, fmeasure=0.4335007607447334), high=Score(precision=0.5379738594789607, recall=0.49593553727662487, fmeasure=0.47628173407207813))\" of type <class 'str'> for key \"eval/rougeLsum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2500, training_loss=0.3231654083251953, metrics={'train_runtime': 7954.2094, 'train_samples_per_second': 10.058, 'train_steps_per_second': 0.314, 'total_flos': 4.60894548860928e+16, 'train_loss': 0.3231654083251953, 'epoch': 25.0})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T02:52:33.440048Z",
     "iopub.status.busy": "2023-07-29T02:52:33.439377Z",
     "iopub.status.idle": "2023-07-29T02:52:33.450703Z",
     "shell.execute_reply": "2023-07-29T02:52:33.449679Z",
     "shell.execute_reply.started": "2023-07-29T02:52:33.440013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 0, 'text': \"He Tackles A Nurse At The Hospital Then You See What's On The Floor Next To Them  Male Nurse Breaks Down When His Friend Reveals He Can Give Him A KidneyWhen you think about your good friends, many things come to mind how bland life would be without them, how they make you laugh and smile when you need it, and how they are there to support you in any situation You may even ask yourself the question — what would I do for them in return? For 24yearold Graham McMillan, the answer is simple there is simply no limit to what he would do for his friends So, when his buddy Danny Kolzow, a 23yearold nurse at Baylor All Saints in Fort Worth, TX, found himself in need of a kidney, McMillan didn’t hesitate to find out if he could donate one of his As it turned out, he was a match He decided to surprise his friend with the good news, and did so in the most incredible way In this emotional clip, McMillan walks into the hospital where Kolzow works He has balloons and a sign in hand that reads, Heard urine need of a kidney, want mine? It seems like the young man is quite the jokester The moment Kolzow sees him, he understandably breaks down into tears He can barely believe his good luck not only does he get a kidney, but he knows that he also has a great friend who will be by his side through thick and thin The gift of life and the gift of friendship are both priceless\"}\n"
     ]
    }
   ],
   "source": [
    "print(test_data[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T02:52:49.270011Z",
     "iopub.status.busy": "2023-07-29T02:52:49.269505Z",
     "iopub.status.idle": "2023-07-29T02:53:40.211770Z",
     "shell.execute_reply": "2023-07-29T02:53:40.209694Z",
     "shell.execute_reply.started": "2023-07-29T02:52:49.269957Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28/2670597998.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch_input = {k: torch.tensor(v).to(model.device) for k, v in batch_input.items()}\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_28/2670597998.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  output = [torch.tensor(o).to(model.device) for o in output]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 0, spoiler: a match\n",
      "id: 1, spoiler: Giving at the expense of your own wellbeing damages your chance of longterm success\n",
      "id: 2, spoiler: access to better medical care, leisure time, healthier food\n",
      "id: 3, spoiler: Braconid\n",
      "id: 4, spoiler: Cured egg yolks\n",
      "id: 5, spoiler: John Williams\n",
      "id: 6, spoiler: 1 Take a long, warm shower with sweetsmelling essential oils\n",
      "id: 7, spoiler: a stranger accidentally put Hailey in harm's way by stopping to pet Flynn\n",
      "id: 8, spoiler: Lord Ivar Mountbatten\n",
      "id: 9, spoiler: going so hardcore that I made myself really unhappy\n",
      "id: 10, spoiler: Who is watching your kids?\n",
      "id: 11, spoiler: inauthentic\n",
      "id: 12, spoiler: Celia Cruz\n",
      "id: 13, spoiler: I've got three more years on my contract with United and the desire to win more\n",
      "id: 14, spoiler: their lives are claustrophobic and squalid\n",
      "id: 15, spoiler: 117 billion\n",
      "id: 16, spoiler: how the Chihiro's parents turned into pigs\n",
      "id: 17, spoiler: Gulf Futurism\n",
      "id: 18, spoiler: 1 Get an education\n",
      "id: 19, spoiler: New York\n",
      "id: 20, spoiler: Michael Sam\n",
      "id: 21, spoiler: drunk or Danish\n",
      "id: 22, spoiler: With Swoggi being so confident that you will get these discounts that they provide voucher\n",
      "id: 23, spoiler: longline yellow raincoat\n",
      "id: 24, spoiler: raise awareness about a very important issue\n",
      "id: 25, spoiler: HamillHimself can I go to comic con as Luke Skywalker even though I\n",
      "id: 26, spoiler: the men had just left Officer Smith’s funeral\n",
      "id: 27, spoiler: Most Americans think climate change, and more frequent and severe natural disasters are linked\n",
      "id: 28, spoiler: Despite losing big to Hillary Clinton in diverse, urban areas of south Florida, Trump dominated\n",
      "id: 29, spoiler: Y Combinator\n",
      "id: 30, spoiler: 1 Iceland\n",
      "id: 31, spoiler: If he could talk, this dog would be saying, I’m not mad\n",
      "id: 32, spoiler: Tesco\n",
      "id: 33, spoiler: either the NES Classic Edition is not available for preorder or\n",
      "id: 34, spoiler: Price of college textbooks\n",
      "id: 35, spoiler: He belts out a few of his favorite Broadway tunes\n",
      "id: 36, spoiler: My laziness serves as a filter Something has to be really good before I'll decide\n",
      "id: 37, spoiler: Austin\n",
      "id: 38, spoiler: Most patients with ALS—also known as Lou Gehrig's disease, for the famous\n",
      "id: 39, spoiler: YInMn blue\n",
      "id: 40, spoiler: blue wavelength light\n",
      "id: 41, spoiler: a large green bottle on the red planet's surface\n",
      "id: 42, spoiler: 'Parenthood'\n",
      "id: 43, spoiler: increases temps mean molecules move faster, resulting in enzymes speeding up metabolism and cells\n",
      "id: 44, spoiler: Five raccoons were trapped inside the Coonskin Park trash receptacle\n",
      "id: 45, spoiler: Jason Aldean\n",
      "id: 46, spoiler: Harry pocketed it\n",
      "id: 47, spoiler: at least an hour\n",
      "id: 48, spoiler: I’m always listening to gospel music\n",
      "id: 49, spoiler: Expo markers are expensive\n",
      "id: 50, spoiler: Rodgers earned the role on his talent alone\n",
      "id: 51, spoiler: Gamechanging DLC, it seems, will remain free\n",
      "id: 52, spoiler: 1 Readers wanted to read about it\n",
      "id: 53, spoiler: leafy greens\n",
      "id: 54, spoiler: Pennsylvania\n",
      "id: 55, spoiler: plastic debris\n",
      "id: 56, spoiler: Among those who are divorced or widowed, age made a big difference in desire to\n",
      "id: 57, spoiler: Amber Galloway Gallego is not your everyday American Sign Language ASL interpreter\n",
      "id: 58, spoiler: playing dead\n",
      "id: 59, spoiler: Miley Cyrus\n",
      "id: 60, spoiler: The items on the lengthy checklist include childhood favorites, such as going on a bike or\n",
      "id: 61, spoiler: Simply use the Lucky Egg to gain double XP for the next 30 minutes, or use\n",
      "id: 62, spoiler: didn't wash their hands\n",
      "id: 63, spoiler: Jussie Smollett\n",
      "id: 64, spoiler: Trump is viewed as fundamentally unfit for the job by an unusually large percentage of Republican voters\n",
      "id: 65, spoiler: spoke a picture of your boarding pass and post it to Facebook\n",
      "id: 66, spoiler: Delaware loophole\n",
      "id: 67, spoiler: Kevin Hart\n",
      "id: 68, spoiler: HBO signed a deal with Amazon to make its archive of television programs available for streaming\n",
      "id: 69, spoiler: 25,000 per month\n",
      "id: 70, spoiler: new home button\n",
      "id: 71, spoiler: Vermont\n",
      "id: 72, spoiler: Dress for the job you want\n",
      "id: 73, spoiler: 1 Museum of Modern Art\n",
      "id: 74, spoiler: You need to eat cupfuls of chickpeas\n",
      "id: 75, spoiler: Bolivia's San Pedro Prison\n",
      "id: 76, spoiler: a moon\n",
      "id: 77, spoiler: Tokyo\n",
      "id: 78, spoiler: we're not certain how well the photosharing app can convey enough information to convince\n",
      "id: 79, spoiler: Donald Trump continues to pay the price for his racist and divisive rabblerousing\n",
      "id: 80, spoiler: MS Dhoni\n",
      "id: 81, spoiler: tumor in her brain\n",
      "id: 82, spoiler: heavyontop style\n",
      "id: 83, spoiler: plastic surgery\n",
      "id: 84, spoiler: Neuphoric AntiAging Cream\n",
      "id: 85, spoiler: going allout in a metcon workout can help you improve your work capacity, making\n",
      "id: 86, spoiler: Katy Perry\n",
      "id: 87, spoiler: The Netherlands\n",
      "id: 88, spoiler: Mzznaki Tetteh\n",
      "id: 89, spoiler: World War I\n",
      "id: 90, spoiler: a piece of foam with a photo of the thing I wanted printed on it\n",
      "id: 91, spoiler: One tablespoon has a whopping 37 grams of sugar\n",
      "id: 92, spoiler: Katar Cole\n",
      "id: 93, spoiler: Bugatti Type 57S\n",
      "id: 94, spoiler: Make America Great Again is a great slogan I would like to meet him\n",
      "id: 95, spoiler: Peter Pilotto\n",
      "id: 96, spoiler:  irregular working hours and work stress\n",
      "id: 97, spoiler: 'Hey Trump, f you'\n",
      "id: 98, spoiler: Nebraska allocates its electoral college votes not in the usual winnertakeall\n",
      "id: 99, spoiler: decision to cancel the Paris Climate Plan\n",
      "id: 100, spoiler: 1 Adventurous Christmas Chile\n",
      "id: 101, spoiler: bigger presence\n",
      "id: 102, spoiler: A new survey says that, not taking into account sleeping time, Thai people spend the\n",
      "id: 103, spoiler: game's online multiplayer unplayable\n",
      "id: 104, spoiler: raw apple and raw lettuce\n",
      "id: 105, spoiler:  severe allergic reaction that John had experienced called anaphylaxis\n",
      "id: 106, spoiler: fettuccine Alfredo\n",
      "id: 107, spoiler: serious heart condition\n",
      "id: 108, spoiler: Delores Curtis\n",
      "id: 109, spoiler: fire authorities in Western Australia say no properties were lost\n",
      "id: 110, spoiler: Unconditional — they can do anything they want with it\n",
      "id: 111, spoiler: The logic of the drugs war only leads one way the police get smarter, so the\n",
      "id: 112, spoiler: Gulls and some other birds will steal food right from the clutches of other\n",
      "id: 113, spoiler: the title page\n",
      "id: 114, spoiler: Shamus Beaglehole\n",
      "id: 115, spoiler: After getting my DNA report I learned that there are a number of genealogy sites,\n",
      "id: 116, spoiler: Wolverampton\n",
      "id: 117, spoiler: This stunning colourful igloo\n",
      "id: 118, spoiler: The film is shot and cut with a nearmaddening degree of patience, its\n",
      "id: 119, spoiler: Ruby Tuesday RT\n",
      "id: 120, spoiler: negative yields\n",
      "id: 121, spoiler: Towels\n",
      "id: 122, spoiler: J Crew\n",
      "id: 123, spoiler: Andy Stern\n",
      "id: 124, spoiler: the main character almost never has a mother\n",
      "id: 125, spoiler: In an explicit 2000 Playboy video\n",
      "id: 126, spoiler: for a watch\n",
      "id: 127, spoiler: Its stomach was full of gas so it was all bloated up\n",
      "id: 128, spoiler: Destiny\n",
      "id: 129, spoiler: no piece by piece upgrading\n",
      "id: 130, spoiler: The new Visa cards provide members with 4 cash back on up to 7,000 of\n",
      "id: 131, spoiler: Online gaming eventually gave him a sense of purpose\n",
      "id: 132, spoiler: Howard has been told he resembles the infamous dictator since 2011, when Kim took power\n",
      "id: 133, spoiler: Apple Logo\n",
      "id: 134, spoiler: Ammon Bundy\n",
      "id: 135, spoiler: frostbite\n",
      "id: 136, spoiler: The latest addition to this troubling trend – the rumor that actress Jennifer Lawrence is being cast\n",
      "id: 137, spoiler: Christine Tink Newman\n",
      "id: 138, spoiler: use of condoms on the bed and flashing instead of giving a tip\n",
      "id: 139, spoiler: Bad languageill thoughtsrude ideasnegative radical views\n",
      "id: 140, spoiler: José José\n",
      "id: 141, spoiler: 682 billion\n",
      "id: 142, spoiler: the year that was in good news\n",
      "id: 143, spoiler: more and more people are being born without wisdom teeth, or have their wisdom teeth erupt\n",
      "id: 144, spoiler: The apex court on Monday granted her permission to terminate her pregnancy\n",
      "id: 145, spoiler: 02 percentage points ahead of Clinton\n",
      "id: 146, spoiler: Wax inside a whale’s ear stores all sorts of useful information on the\n",
      "id: 147, spoiler: rejecting all the larger vessels with those of smaller sizes\n",
      "id: 148, spoiler: She replied simply by saying she had a house closeby  Have you ever met the\n",
      "id: 149, spoiler: Sunday, May 8\n",
      "id: 150, spoiler: I think it depends on the attitude you take towards it\n",
      "id: 151, spoiler: The Rock\n",
      "id: 152, spoiler: Jackson Vroman\n",
      "id: 153, spoiler: 1 Ideas Have Consequences\n",
      "id: 154, spoiler:  prototype imaging system that’s able to read pages of a book without opening it\n",
      "id: 155, spoiler: Katherine Heigl's behavior on set has become notoriously difficult\n",
      "id: 156, spoiler: Nuts\n",
      "id: 157, spoiler: potatoes\n",
      "id: 158, spoiler: Stop using a heavy coverage foundation\n",
      "id: 159, spoiler: Taran Killam\n",
      "id: 160, spoiler: Idaho\n",
      "id: 161, spoiler: readers of fiction are more empathetic towards others\n",
      "id: 162, spoiler: Katrina Henry\n",
      "id: 163, spoiler: your favorite, thoughtful, wordy rapper could put out a song with your least favorite\n",
      "id: 164, spoiler: 77\n",
      "id: 165, spoiler: produce your synaptic connections\n",
      "id: 166, spoiler: If the IOC does ban Russia, that’s enough medals to throw any Olympic\n",
      "id: 167, spoiler: looks just like a penis\n",
      "id: 168, spoiler: 1 Don't touch her bump\n",
      "id: 169, spoiler: being a single mom to daughter Jessica\n",
      "id: 170, spoiler: 725,759\n",
      "id: 171, spoiler: Laws that maintain the legal drinking age at 21 save lives on the road, and\n",
      "id: 172, spoiler: Oregon\n",
      "id: 173, spoiler: almost every space pops with color\n",
      "id: 174, spoiler: advisorial capacity\n",
      "id: 175, spoiler: 'Dumb and Dumber' Sequel\n",
      "id: 176, spoiler: never taking things for granted and helping spread awareness of children’s cancer\n",
      "id: 177, spoiler: Valve announced it would begin sending requests to cease operations to gambling websites that use Steam\n",
      "id: 178, spoiler: cinnamon\n",
      "id: 179, spoiler: Greg Puciato\n",
      "id: 180, spoiler:  ravenous bear broke into a Lyons, Colorado, bakery and ate 24 pies\n",
      "id: 181, spoiler: bag container formed of white solid bleached sulfate paper\n",
      "id: 182, spoiler: But it now seems that by cutting a small cross in the base of each sprout\n",
      "id: 183, spoiler: Instant Skin Quencher\n",
      "id: 184, spoiler: Jimmy Smits\n",
      "id: 185, spoiler: novelty\n",
      "id: 186, spoiler: 1 Stand in front of her with 1 to 15 meters between you\n",
      "id: 187, spoiler: bag of dick tips\n",
      "id: 188, spoiler: 1 Beyond Good  Evil\n",
      "id: 189, spoiler: Step back from the Queen's Guard and thrust his ratherdeadly gun complete with rather\n",
      "id: 190, spoiler: One of the men then allegedly told her that he would force her to go and grabbed\n",
      "id: 191, spoiler: Laura Bush\n",
      "id: 192, spoiler: Michael Brain\n",
      "id: 193, spoiler: pizza\n",
      "id: 194, spoiler: The inaudience culprit appeared to respond, and Timberlake continued Oh you wanted me\n",
      "id: 195, spoiler: Depending on your priorities, it might be\n",
      "id: 196, spoiler: Colorado\n",
      "id: 197, spoiler: Initial jobless claims unexpectedly fell\n",
      "id: 198, spoiler: It simply couldn't make enough toys to satiate demand in North America, and needed\n",
      "id: 199, spoiler: I’m not killing off Harrison Ford\n",
      "id: 200, spoiler: new generation epassport featuring enhanced security features such as biometric details may soon be\n",
      "id: 201, spoiler: It will be a continuation of the first season’s story\n",
      "id: 202, spoiler: John Slattery\n",
      "id: 203, spoiler: black bag, hidden inside\n",
      "id: 204, spoiler: He ended up in the hills above Whittier, along Turnbull Canyon Road\n",
      "id: 205, spoiler: Tulsiram Manere\n",
      "id: 206, spoiler: Ailish Sheehan\n",
      "id: 207, spoiler: Count each small win\n",
      "id: 208, spoiler: Chicago\n",
      "id: 209, spoiler: An image is sexually objectifying if yes is the answer to any of the following questions\n",
      "id: 210, spoiler: Nellie Bly\n",
      "id: 211, spoiler: French fry\n",
      "id: 212, spoiler: several stalagmite rings were older than any known cave painting\n",
      "id: 213, spoiler: she got distracted by her own ‘erotic thoughts’\n",
      "id: 214, spoiler: Sarah Gailey\n",
      "id: 215, spoiler: 3 is greater than 2\n",
      "id: 216, spoiler: Eatsa\n",
      "id: 217, spoiler: 10,527,843,932\n",
      "id: 218, spoiler: using this also changes the appearance of your cell phone\n",
      "id: 219, spoiler: Many Young Americans Blame Colleges For Rising Student Debt\n",
      "id: 220, spoiler: Praise be to Allah that he became a martyr\n",
      "id: 221, spoiler: Will or won’t they divorce?\n",
      "id: 222, spoiler: Chien Chihcheng\n",
      "id: 223, spoiler: Boone Police Department charged the women with seven counts of misdemeanor graffiti and one count of\n",
      "id: 224, spoiler: Emily Gardner\n",
      "id: 225, spoiler: Menelik Watson\n",
      "id: 226, spoiler: I Miss You\n",
      "id: 227, spoiler: heavy proteins, healthy fats like nuts and avocado, carbs, fruits, veggies and cheese\n",
      "id: 228, spoiler: Ana Ana\n",
      "id: 229, spoiler: He was all whiny last week\n",
      "id: 230, spoiler: breaking protocol in placing the murderer’s body\n",
      "id: 231, spoiler: pears\n",
      "id: 232, spoiler: Blake McIver\n",
      "id: 233, spoiler: it is now legal to hunt for catfish with pitchforks or spears\n",
      "id: 234, spoiler: lack of understanding\n",
      "id: 235, spoiler: twerking\n",
      "id: 236, spoiler: st wrong words St, st, st\n",
      "id: 237, spoiler: Caitlyn Cannon\n",
      "id: 238, spoiler: big belly rub\n",
      "id: 239, spoiler: Amy Schumer\n",
      "id: 240, spoiler: A right triangle has a hypotenuse equal to 10 and an altitude to the hypot\n",
      "id: 241, spoiler: splitters between Scotland and large parts of England who voted to stay and other parts of\n",
      "id: 242, spoiler: having purpose\n",
      "id: 243, spoiler: completely bald\n",
      "id: 244, spoiler: Emperor Palpatine's granddaughter\n",
      "id: 245, spoiler: Lisa Brown\n",
      "id: 246, spoiler: With the reported 115 million raised from the Ice Bucket Challenge, the ALS Association funded six\n",
      "id: 247, spoiler: These small circles are called Venus Holes and are formed on the lower back of women\n",
      "id: 248, spoiler: The technique, which is a form of acupuncture, is done by lighting flammable\n",
      "id: 249, spoiler: More than 18 hours a day\n",
      "id: 250, spoiler: The silver birches' branches and leaves sagged at night they reached their lowest\n",
      "id: 251, spoiler: Khan\n",
      "id: 252, spoiler: Berlin\n",
      "id: 253, spoiler: Chocolate crinkles baked inhouse daily\n",
      "id: 254, spoiler: Exhale completely through your mouth, making a whoosh sound as you do so\n",
      "id: 255, spoiler: A retired police officer who carried a young girl to safety nearly 20 years ago was reunited\n",
      "id: 256, spoiler: The tab needs to be separated from the chopsticks and then it doubles up as a\n",
      "id: 257, spoiler: egg cartons and plastic ice cube trays make great organizational tools for jewelry, cuff\n",
      "id: 258, spoiler: An investigation found that Baylor University had mishandled sexual assault accusations against its football players\n",
      "id: 259, spoiler: trim your pubic hair\n",
      "id: 260, spoiler: A good candidate with flaws\n",
      "id: 261, spoiler: packed with nutrients that are beneficial and healthy for you\n",
      "id: 262, spoiler: Ben Bernanke\n",
      "id: 263, spoiler: Jordan Klepper\n",
      "id: 264, spoiler: accessibility is very limited\n",
      "id: 265, spoiler: sleep deprivation\n",
      "id: 266, spoiler: Feb 24\n",
      "id: 267, spoiler: In very small amounts say, a few teaspoons\n",
      "id: 268, spoiler: talking about it with their partners\n",
      "id: 269, spoiler: polymyalgia rheumatica\n",
      "id: 270, spoiler: After Fowler’s blast, Kyle Schwarber hit a slow grounder to the\n",
      "id: 271, spoiler: You can eat a cheeseburger with your knee as you put on makeup with your\n",
      "id: 272, spoiler: use as a drink coaster\n",
      "id: 273, spoiler: buying a pet as for someone you care about\n",
      "id: 274, spoiler: Minnesota\n",
      "id: 275, spoiler: Her\n",
      "id: 276, spoiler: a mutation to a separate, nearby gene called HERC2\n",
      "id: 277, spoiler: Dawn Grace\n",
      "id: 278, spoiler: blond\n",
      "id: 279, spoiler: THE MUSIC\n",
      "id: 280, spoiler: Adding it to the cooking process makes the starch granules resistant to the action of digestive\n",
      "id: 281, spoiler: knead their paws into you\n",
      "id: 282, spoiler: spy camera hooks\n",
      "id: 283, spoiler: Palm Springs\n",
      "id: 284, spoiler: Louisville\n",
      "id: 285, spoiler: racial\n",
      "id: 286, spoiler: Men, however, just reach behind their neck and yank their shirt off\n",
      "id: 287, spoiler: The castle at Winterfell was adorned with the gruesome Bolton sigil\n",
      "id: 288, spoiler: lime green\n",
      "id: 289, spoiler: Aaron Judge\n",
      "id: 290, spoiler: Thiruvananthapuram, India\n",
      "id: 291, spoiler: chocolate\n",
      "id: 292, spoiler: 1 Ecuador\n",
      "id: 293, spoiler: Not getting enough sleep may cause changes to gut bacteria\n",
      "id: 294, spoiler: There were many plot twists and updates that gave the newly released Beauty and Beast a completely\n",
      "id: 295, spoiler: an acoustic version\n",
      "id: 296, spoiler: moral\n",
      "id: 297, spoiler: Buffy the Vampire Slayer\n",
      "id: 298, spoiler: Mr Burger offering free burgers if you change your last name\n",
      "id: 299, spoiler: potential cancer\n",
      "id: 300, spoiler: Peter Facinelli\n",
      "id: 301, spoiler: Chris Pratt\n",
      "id: 302, spoiler:  Compliance officer\n",
      "id: 303, spoiler: Lawyer Media TV and radio\n",
      "id: 304, spoiler: Rosemary\n",
      "id: 305, spoiler: 1,080 slightly above average\n",
      "id: 306, spoiler: Play Music All Access streaming service\n",
      "id: 307, spoiler: CHILI PEPPERS Capsaicin\n",
      "id: 308, spoiler: Intrepid\n",
      "id: 309, spoiler: morning after you wake up\n",
      "id: 310, spoiler: UC, Los Angeles\n",
      "id: 311, spoiler: The chances that a stranger will abduct and kill or not return a child\n",
      "id: 312, spoiler: capture the pigeon\n",
      "id: 313, spoiler: Chal Na Katrina\n",
      "id: 314, spoiler: Feb 24 at 9 pm\n",
      "id: 315, spoiler: seven hours\n",
      "id: 316, spoiler: by watching the trailer for GBF\n",
      "id: 317, spoiler: Pika Pika Pikachoose\n",
      "id: 318, spoiler: pussy\n",
      "id: 319, spoiler: he added Congress also be giving him the funding to build the wall as well\n",
      "id: 320, spoiler: she may get to add both to her impeccable track record of war, bloodshed and\n",
      "id: 321, spoiler: Lawrence Phillips\n",
      "id: 322, spoiler: Carrer Avinyó\n",
      "id: 323, spoiler: Nick Johnson\n",
      "id: 324, spoiler: a 74yearold man with a bad limp knocked on the window\n",
      "id: 325, spoiler: Choice\n",
      "id: 326, spoiler: superfetation\n",
      "id: 327, spoiler: Colin Quinn\n",
      "id: 328, spoiler: text messages\n",
      "id: 329, spoiler:  fossil\n",
      "id: 330, spoiler: 1,700\n",
      "id: 331, spoiler: 1 CocaCola Memorabilia\n",
      "id: 332, spoiler: The evacuation of civilians and opposition fighters from eastern Aleppo have been suspended after rebels opened fire\n",
      "id: 333, spoiler: lost and hidden city of Skara Brae\n",
      "id: 334, spoiler: Sir Bradley Wiggins\n",
      "id: 335, spoiler: playing the game without ever firing a gun\n",
      "id: 336, spoiler: the more the Cowboys run the ball, the better the chance for his survival\n",
      "id: 337, spoiler: Pikaqiu\n",
      "id: 338, spoiler: Whitney Thompson\n",
      "id: 339, spoiler: cosmic and geophysical forces tend to zero because of their slow nature or rarity,\n",
      "id: 340, spoiler: This is a work of fiction\n",
      "id: 341, spoiler: It could represent the danger of a snake or another predator, Mugford continued I suspect\n",
      "id: 342, spoiler: diet beverages do not beat water\n",
      "id: 343, spoiler: Captain Phillips\n",
      "id: 344, spoiler: man spins around and starts laughing and playing with him like they're bezzie mates\n",
      "id: 345, spoiler: a rag\n",
      "id: 346, spoiler: Back The Blue tshirts\n",
      "id: 347, spoiler: Houston\n",
      "id: 348, spoiler: a card that read, Do not open until your 1st disagreement\n",
      "id: 349, spoiler: swiping a chip card instead of inserting it into slot\n",
      "id: 350, spoiler: Elle\n",
      "id: 351, spoiler: there is no evidence that not washing jeans is hazardous to your health\n",
      "id: 352, spoiler: Trump snorted too much adderall TrumpSniffle\n",
      "id: 353, spoiler: coconut oil\n",
      "id: 354, spoiler: chockfull of nutrients and electrolytes like potassium\n",
      "id: 355, spoiler: Imagine going for a job interview and the woman says she will email u in a few\n",
      "id: 356, spoiler: Chris Crocker\n",
      "id: 357, spoiler: Men are more likely to have a heart attack after a snowfall, and it's\n",
      "id: 358, spoiler: little Aubrey wrapped in motorcycle gloves, next to a colorful, shiny motorcycle helmet\n",
      "id: 359, spoiler: A number 7 with medium fries and a Coke\n",
      "id: 360, spoiler: Minnesota\n",
      "id: 361, spoiler: TURN AROUND and exit the building, the sign read Your son will learn to\n",
      "id: 362, spoiler: Singleplayer lag\n",
      "id: 363, spoiler: taking her own necklace and bracelet\n",
      "id: 364, spoiler: Cecily Strong\n",
      "id: 365, spoiler: You like the best of things but you can easily compromise\n",
      "id: 366, spoiler: Arizona\n",
      "id: 367, spoiler: woefully misaligned with the windows\n",
      "id: 368, spoiler: Springfield, Oregon\n",
      "id: 369, spoiler: Norah had given birth to nine tiny puppies\n",
      "id: 370, spoiler: not against crossconsole support and open to the idea of allowing PlayStation 4 players to play\n",
      "id: 371, spoiler: Lead, as Superman fans know, can block the superhero’s Xray vision\n",
      "id: 372, spoiler: Postmicturition convulsion syndrome\n",
      "id: 373, spoiler: giantuan milelong asteroid\n",
      "id: 374, spoiler: Where do you see yourself in five years?\n",
      "id: 375, spoiler: Dumb British blond fucks 15 million people at once\n",
      "id: 376, spoiler: Pat Patterson\n",
      "id: 377, spoiler: He sees something he doesn’t particularly care if it’s true or\n",
      "id: 378, spoiler: Yvette Nicole Brown\n",
      "id: 379, spoiler: Florida\n",
      "id: 380, spoiler: Hagrid couldn't produce a Patronus\n",
      "id: 381, spoiler: Jason Kander looks to be running very strongly in the exit polls\n",
      "id: 382, spoiler: 53 seconds\n",
      "id: 383, spoiler: Where's Rudy?\n",
      "id: 384, spoiler: these antibodies could be used to treat many diseases\n",
      "id: 385, spoiler: BOOM – Portugal\n",
      "id: 386, spoiler: white pepper\n",
      "id: 387, spoiler: prostate and anal play\n",
      "id: 388, spoiler: Banking on bad movies\n",
      "id: 389, spoiler: Klefki\n",
      "id: 390, spoiler: loves each other too much\n",
      "id: 391, spoiler: Hillary Clinton\n",
      "id: 392, spoiler: concrete ready to be sold\n",
      "id: 393, spoiler: rebalancing its services sector\n",
      "id: 394, spoiler:  deadly water hemlock\n",
      "id: 395, spoiler: showed by how hardworking she is\n",
      "id: 396, spoiler: Christopher Suprun\n",
      "id: 397, spoiler: vegan plant based diet nothing processed\n",
      "id: 398, spoiler: on 16 October 2016, WikiLeaks posted a series of cryptic numeric tweets, leading many onlook\n",
      "id: 399, spoiler: Richard Belzer\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Function to generate spoilers using the trained model and tokenizer\n",
    "def generate_spoilers(encoded_input, batch_size=1):\n",
    "    with torch.no_grad():\n",
    "        num_samples = len(encoded_input[\"input_ids\"])\n",
    "        decoded_spoilers = []\n",
    "\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            batch_input = {k: v[i:i+batch_size] for k, v in encoded_input.items()}\n",
    "            batch_input = {k: torch.tensor(v).to(model.device) for k, v in batch_input.items()}\n",
    "            output = model.generate(**batch_input)\n",
    "            \n",
    "            # Convert output to a list of tensors\n",
    "            output = [torch.tensor(o).to(model.device) for o in output]\n",
    "\n",
    "            # Perform batch decoding\n",
    "            batch_decoded = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "            decoded_spoilers.extend(batch_decoded)\n",
    "\n",
    "    return decoded_spoilers\n",
    "\n",
    "# Generate spoilers for the test_data using the trained model\n",
    "test_texts = test_data[\"train\"][\"text\"]\n",
    "encoded_input = tokenizer(test_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "batch_size = 4\n",
    "decoded_test_preds = generate_spoilers(encoded_input, batch_size=batch_size)\n",
    "# decoded_test_preds = generate_spoilers(encoded_input)\n",
    "\n",
    "# Print the generated spoilers along with their corresponding ids\n",
    "for spoiler, sample_id in zip(decoded_test_preds, test_data[\"train\"][\"id\"]):\n",
    "    print(f\"id: {sample_id}, spoiler: {spoiler}\")\n",
    "    \n",
    "# Create a DataFrame to store the spoilers and their IDs\n",
    "spoilers_df = pd.DataFrame({\"id\": test_data[\"train\"][\"id\"], \"spoiler\": decoded_test_preds})\n",
    "\n",
    "# Strip leading and trailing whitespaces in the \"spoiler\" column\n",
    "spoilers_df[\"spoiler\"] = spoilers_df[\"spoiler\"].str.strip()\n",
    "\n",
    "# Check for any other representations of null spoilers (e.g., empty strings or NaN)\n",
    "null_spoilers = spoilers_df[spoilers_df[\"spoiler\"].isna() | (spoilers_df[\"spoiler\"] == \"\")]\n",
    "\n",
    "if not null_spoilers.empty:\n",
    "    print(\"Null spoilers found. Replacing alternative representations...\")\n",
    "    print(null_spoilers)\n",
    "    spoilers_df.replace({\"\": np.nan}, inplace=True)  # Replace empty strings with NaN\n",
    "    spoilers_df[\"spoiler\"].fillna(\"No Spoilers Generated\", inplace=True)\n",
    "\n",
    "    # Print rows with null spoilers\n",
    "    print(spoilers_df[spoilers_df[\"spoiler\"].isnull()])\n",
    "    \n",
    "# Save the DataFrame to a CSV file\n",
    "spoilers_df.to_csv(\"generated_spoilers_bart_base_25.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-29T02:52:33.423091Z",
     "iopub.status.busy": "2023-07-29T02:52:33.422613Z",
     "iopub.status.idle": "2023-07-29T02:52:33.431824Z",
     "shell.execute_reply": "2023-07-29T02:52:33.430874Z",
     "shell.execute_reply.started": "2023-07-29T02:52:33.423052Z"
    }
   },
   "outputs": [],
   "source": [
    "### print the number of trainable parameters in the tranformers model\n",
    "# from transformers import AutoModel, AutoTokenizer, MODEL_NAMES_MAPPING\n",
    "\n",
    "# # Get a list of all available transformer model names\n",
    "# all_model_names = list(MODEL_NAMES_MAPPING.keys())\n",
    "\n",
    "# for model_name in all_model_names:\n",
    "#     try:\n",
    "#         # Load the model\n",
    "#         model_class = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "#         # Count the number of trainable parameters\n",
    "#         num_trainable_params = sum(p.numel() for p in model_class.parameters() if p.requires_grad)\n",
    "\n",
    "#         print(f\"Model: {model_name}\")\n",
    "#         print(f\"Number of trainable parameters: {num_trainable_params}\")\n",
    "#         print(\"=\" * 50)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error loading model {model_name}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
